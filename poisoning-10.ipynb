{"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPCIjXAk2e5D4qsQgwvtvxY"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.15","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{"id":"fs42wweDPw2t","executionInfo":{"status":"ok","timestamp":1732040976233,"user_tz":-180,"elapsed":447,"user":{"displayName":"Roger Nick Anaedevha","userId":"11403452854921994388"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# -*- coding: utf-8 -*-\n\"\"\"\nIntegrated DQN-Actor-Critic Architecture for Poisoning Attack Detection\nAuthor: Your Name\nDate: 2024\n\"\"\"\n\n\"\"\"# Cell 1: Imports and Mathematical Framework\n\n## Mathematical Framework for DQN-Actor-Critic Based Poisoning Detection\n\n1. Feature Space Definition:\n   F = {f âˆˆ â„áµˆ | f is a network flow feature vector}\n   where d is the dimension of extracted features\n\n2. Data Distribution:\n   P(x) = Normal network traffic distribution\n   Q(x) = Poisoned traffic distribution\n   KL(P||Q) = Measure of distribution divergence\n\n3. Attack Space:\n   A = {a | a is a poisoning attack vector}\n   Impact(a) = Î£ ||f_original - f_poisoned||â‚‚\n\n4. Detection Functions:\n   DQN: Q(s,a) = ð”¼[R + Î³ max Q(s',a') | s,a]\n   Actor: Ï€(a|s) = P(action=a | state=s)\n   Critic: V(s) = ð”¼[Î£ Î³áµ—R_t | sâ‚€=s]\n\n5. Combined Detection Score:\n   D(x) = Î±Â·Q(x) + (1-Î±)Â·Ï€(x) + Î²Â·KL(P||Q_x)\n   where Q_x is the estimated distribution at point x\n\"\"\"","metadata":{"id":"eMjQlShIb6Dr"}},{"cell_type":"markdown","source":"## GPU verification","metadata":{"id":"N88B-9zoRAT2"}},{"cell_type":"code","source":"def check_gpu():\n    \"\"\"Check and setup GPU if available\"\"\"\n    if torch.cuda.is_available():\n        # Print GPU info\n        print(f\"CUDA is available:\")\n        print(f\"- GPU Device: {torch.cuda.get_device_name(0)}\")\n        print(f\"- CUDA Version: {torch.version.cuda}\")\n        print(f\"- Memory Available: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f}GB\")\n\n        # Set device\n        device = torch.device(\"cuda:0\")\n\n        # Enable optimizations\n        torch.backends.cudnn.benchmark = True\n        torch.backends.cuda.matmul.allow_tf32 = True\n        torch.backends.cudnn.allow_tf32 = True\n\n        return device\n    else:\n        print(\"No GPU detected. Using CPU.\")\n        return torch.device(\"cpu\")","metadata":{"id":"-t3ODEIIRCjT","executionInfo":{"status":"ok","timestamp":1732040977533,"user_tz":-180,"elapsed":468,"user":{"displayName":"Roger Nick Anaedevha","userId":"11403452854921994388"}},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Installs","metadata":{}},{"cell_type":"code","source":"# Usage in notebook\n!pip install torch_xla\n!pip install cloud-tpu-client\n!pip install cloud-tpu-client==0.10 torch_xla==2.0 torch==2.0.0 torchvision==0.15.1 -f https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-2.0-cp310-cp310-linux_x86_64.whl\n","metadata":{"execution":{"iopub.status.idle":"2024-11-19T23:11:48.271733Z","shell.execute_reply.started":"2024-11-19T23:11:41.250016Z","shell.execute_reply":"2024-11-19T23:11:48.270760Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch_xla in /usr/local/lib/python3.10/site-packages (2.4.0+libtpu)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/site-packages (from torch_xla) (6.0.2)\nRequirement already satisfied: cloud-tpu-client>=0.10.0 in /usr/local/lib/python3.10/site-packages (from torch_xla) (0.10)\nRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/site-packages (from torch_xla) (2.1.0)\nRequirement already satisfied: oauth2client in /usr/local/lib/python3.10/site-packages (from cloud-tpu-client>=0.10.0->torch_xla) (4.1.3)\nRequirement already satisfied: google-api-python-client==1.8.0 in /usr/local/lib/python3.10/site-packages (from cloud-tpu-client>=0.10.0->torch_xla) (1.8.0)\nRequirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.10/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla) (1.16.0)\nRequirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.10/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla) (3.0.1)\nRequirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.10/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla) (0.22.0)\nRequirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.10/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla) (0.2.0)\nRequirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.10/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla) (1.34.1)\nRequirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.10/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla) (2.35.0)\nRequirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/site-packages (from oauth2client->cloud-tpu-client>=0.10.0->torch_xla) (0.4.1)\nRequirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/site-packages (from oauth2client->cloud-tpu-client>=0.10.0->torch_xla) (4.9)\nRequirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/site-packages (from oauth2client->cloud-tpu-client>=0.10.0->torch_xla) (0.6.1)\nRequirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/site-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla) (3.20.3)\nRequirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.10/site-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla) (2.32.3)\nRequirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.10/site-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla) (1.65.0)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/site-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla) (5.5.0)\nRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/site-packages (from httplib2<1dev,>=0.9.2->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla) (3.1.4)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla) (2024.8.30)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla) (2.2.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla) (3.10)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nRequirement already satisfied: cloud-tpu-client in /usr/local/lib/python3.10/site-packages (0.10)\nRequirement already satisfied: google-api-python-client==1.8.0 in /usr/local/lib/python3.10/site-packages (from cloud-tpu-client) (1.8.0)\nRequirement already satisfied: oauth2client in /usr/local/lib/python3.10/site-packages (from cloud-tpu-client) (4.1.3)\nRequirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.10/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.16.0)\nRequirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.10/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (0.2.0)\nRequirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.10/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (0.22.0)\nRequirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.10/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.34.1)\nRequirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.10/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (3.0.1)\nRequirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.10/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (2.35.0)\nRequirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/site-packages (from oauth2client->cloud-tpu-client) (4.9)\nRequirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/site-packages (from oauth2client->cloud-tpu-client) (0.4.1)\nRequirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/site-packages (from oauth2client->cloud-tpu-client) (0.6.1)\nRequirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/site-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.20.3)\nRequirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.10/site-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (1.65.0)\nRequirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.10/site-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.32.3)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/site-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (5.5.0)\nRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/site-packages (from httplib2<1dev,>=0.9.2->google-api-python-client==1.8.0->cloud-tpu-client) (3.1.4)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2024.8.30)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.2.3)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Importing Liberaries","metadata":{}},{"cell_type":"code","source":"import os\nos.environ['XLA_USE_BF16'] = \"1\"\nos.environ['XLA_TENSOR_ALLOCATOR_MAXSIZE'] = '100000000'\n\nimport requests\nrequests.get('http://metadata.google.internal/computeMetadata/v1/instance/name', headers={'Metadata-Flavor': 'Google'})","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Standard imports\n\nimport gc\nimport time\nimport random\nimport logging\nimport traceback\nfrom typing import Dict, List, Tuple\nfrom collections import deque, defaultdict\n\n# Data processing\nimport numpy as np\nimport pandas as pd\nimport scipy.stats\nfrom sklearn.model_selection import train_test_split\n\n# Deep Learning\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.tensorboard import SummaryWriter\n\n# Machine Learning\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom tensorflow.keras.utils import Sequence\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom typing import Dict, Any, List, Union\n\n# Utilities\nimport psutil\nfrom tqdm import tqdm\nimport contextlib\nfrom torch.nn.functional import sigmoid\n\nimport torch.cuda\nimport torch.backends.cudnn\n\nimport tensorflow as tf\nimport torch_xla\nimport torch_xla.core.xla_model as xm\nimport torch_xla.distributed.parallel_loader as pl\nimport torch_xla.distributed.xla_multiprocessing as xmp\n\n","metadata":{"id":"ZczGsNejsD_Z","executionInfo":{"status":"ok","timestamp":1732040986608,"user_tz":-180,"elapsed":9077,"user":{"displayName":"Roger Nick Anaedevha","userId":"11403452854921994388"}},"execution":{"iopub.status.busy":"2024-11-19T23:11:48.272866Z","iopub.execute_input":"2024-11-19T23:11:48.273130Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"WARNING: Logging before InitGoogle() is written to STDERR\nE0000 00:00:1732057941.579875      38 common_lib.cc:798] Could not set metric server port: INVALID_ARGUMENT: Could not find SliceBuilder port 8471 in any of the 0 ports provided in `tpu_process_addresses`=\"local\"\n=== Source Location Trace: ===\nlearning/45eac/tfrc/runtime/common_lib.cc:479\nD1119 23:12:21.587977505      38 config.cc:196]                        gRPC EXPERIMENT call_status_override_on_cancellation   OFF (default:OFF)\nD1119 23:12:21.587992022      38 config.cc:196]                        gRPC EXPERIMENT call_v3                                OFF (default:OFF)\nD1119 23:12:21.587995420      38 config.cc:196]                        gRPC EXPERIMENT canary_client_privacy                  ON  (default:ON)\nD1119 23:12:21.587997840      38 config.cc:196]                        gRPC EXPERIMENT capture_base_context                   ON  (default:ON)\nD1119 23:12:21.588000225      38 config.cc:196]                        gRPC EXPERIMENT client_idleness                        ON  (default:ON)\nD1119 23:12:21.588002539      38 config.cc:196]                        gRPC EXPERIMENT client_privacy                         ON  (default:ON)\nD1119 23:12:21.588004857      38 config.cc:196]                        gRPC EXPERIMENT dapper_request_wire_size               OFF (default:OFF)\nD1119 23:12:21.588007017      38 config.cc:196]                        gRPC EXPERIMENT empty_experiment                       OFF (default:OFF)\nD1119 23:12:21.588009174      38 config.cc:196]                        gRPC EXPERIMENT event_engine_client                    OFF (default:OFF)\nD1119 23:12:21.588011324      38 config.cc:196]                        gRPC EXPERIMENT event_engine_dns                       ON  (default:ON)\nD1119 23:12:21.588013495      38 config.cc:196]                        gRPC EXPERIMENT event_engine_listener                  ON  (default:ON)\nD1119 23:12:21.588015742      38 config.cc:196]                        gRPC EXPERIMENT free_large_allocator                   OFF (default:OFF)\nD1119 23:12:21.588017899      38 config.cc:196]                        gRPC EXPERIMENT google_no_envelope_resolver            OFF (default:OFF)\nD1119 23:12:21.588020072      38 config.cc:196]                        gRPC EXPERIMENT http2_stats_fix                        OFF (default:OFF)\nD1119 23:12:21.588022236      38 config.cc:196]                        gRPC EXPERIMENT keepalive_fix                          OFF (default:OFF)\nD1119 23:12:21.588024372      38 config.cc:196]                        gRPC EXPERIMENT keepalive_server_fix                   ON  (default:ON)\nD1119 23:12:21.588026655      38 config.cc:196]                        gRPC EXPERIMENT loas_do_not_prefer_rekey_next_protocol OFF (default:OFF)\nD1119 23:12:21.588028841      38 config.cc:196]                        gRPC EXPERIMENT loas_prod_to_cloud_prefer_pfs_ciphers  OFF (default:OFF)\nD1119 23:12:21.588031030      38 config.cc:196]                        gRPC EXPERIMENT monitoring_experiment                  ON  (default:ON)\nD1119 23:12:21.588033247      38 config.cc:196]                        gRPC EXPERIMENT multiping                              OFF (default:OFF)\nD1119 23:12:21.588035407      38 config.cc:196]                        gRPC EXPERIMENT peer_state_based_framing               OFF (default:OFF)\nD1119 23:12:21.588037597      38 config.cc:196]                        gRPC EXPERIMENT pending_queue_cap                      ON  (default:ON)\nD1119 23:12:21.588039831      38 config.cc:196]                        gRPC EXPERIMENT pick_first_happy_eyeballs              ON  (default:ON)\nD1119 23:12:21.588042018      38 config.cc:196]                        gRPC EXPERIMENT promise_based_client_call              OFF (default:OFF)\nD1119 23:12:21.588044120      38 config.cc:196]                        gRPC EXPERIMENT promise_based_inproc_transport         OFF (default:OFF)\nD1119 23:12:21.588046255      38 config.cc:196]                        gRPC EXPERIMENT promise_based_server_call              OFF (default:OFF)\nD1119 23:12:21.588048470      38 config.cc:196]                        gRPC EXPERIMENT registered_method_lookup_in_transport  ON  (default:ON)\nD1119 23:12:21.588050664      38 config.cc:196]                        gRPC EXPERIMENT rfc_max_concurrent_streams             ON  (default:ON)\nD1119 23:12:21.588052907      38 config.cc:196]                        gRPC EXPERIMENT round_robin_delegate_to_pick_first     ON  (default:ON)\nD1119 23:12:21.588056267      38 config.cc:196]                        gRPC EXPERIMENT rstpit                                 OFF (default:OFF)\nD1119 23:12:21.588058605      38 config.cc:196]                        gRPC EXPERIMENT schedule_cancellation_over_write       OFF (default:OFF)\nD1119 23:12:21.588060934      38 config.cc:196]                        gRPC EXPERIMENT server_privacy                         ON  (default:ON)\nD1119 23:12:21.588063264      38 config.cc:196]                        gRPC EXPERIMENT tcp_frame_size_tuning                  OFF (default:OFF)\nD1119 23:12:21.588065409      38 config.cc:196]                        gRPC EXPERIMENT tcp_rcv_lowat                          OFF (default:OFF)\nD1119 23:12:21.588067540      38 config.cc:196]                        gRPC EXPERIMENT trace_record_callops                   OFF (default:OFF)\nD1119 23:12:21.588069687      38 config.cc:196]                        gRPC EXPERIMENT unconstrained_max_quota_buffer_size    OFF (default:OFF)\nD1119 23:12:21.588071752      38 config.cc:196]                        gRPC EXPERIMENT v3_backend_metric_filter               OFF (default:OFF)\nD1119 23:12:21.588073914      38 config.cc:196]                        gRPC EXPERIMENT v3_channel_idle_filters                ON  (default:ON)\nD1119 23:12:21.588076219      38 config.cc:196]                        gRPC EXPERIMENT v3_compression_filter                  ON  (default:ON)\nD1119 23:12:21.588078643      38 config.cc:196]                        gRPC EXPERIMENT v3_server_auth_filter                  OFF (default:OFF)\nD1119 23:12:21.588080760      38 config.cc:196]                        gRPC EXPERIMENT work_serializer_clears_time_cache      OFF (default:OFF)\nD1119 23:12:21.588082863      38 config.cc:196]                        gRPC EXPERIMENT work_serializer_dispatch               OFF (default:OFF)\nD1119 23:12:21.588085023      38 config.cc:196]                        gRPC EXPERIMENT write_size_cap                         ON  (default:ON)\nD1119 23:12:21.588087238      38 config.cc:196]                        gRPC EXPERIMENT write_size_policy                      ON  (default:ON)\nD1119 23:12:21.588089440      38 config.cc:196]                        gRPC EXPERIMENT wrr_delegate_to_pick_first             ON  (default:ON)\nI1119 23:12:21.588259172      38 ev_epoll1_linux.cc:123]               grpc epoll fd: 60\nD1119 23:12:21.588271736      38 ev_posix.cc:113]                      Using polling engine: epoll1\nD1119 23:12:21.598839148      38 lb_policy_registry.cc:46]             registering LB policy factory for \"priority_experimental\"\nD1119 23:12:21.598849947      38 lb_policy_registry.cc:46]             registering LB policy factory for \"outlier_detection_experimental\"\nD1119 23:12:21.598857405      38 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_target_experimental\"\nD1119 23:12:21.598860537      38 lb_policy_registry.cc:46]             registering LB policy factory for \"pick_first\"\nD1119 23:12:21.598863745      38 lb_policy_registry.cc:46]             registering LB policy factory for \"round_robin\"\nD1119 23:12:21.598866423      38 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_round_robin\"\nD1119 23:12:21.598893113      38 lb_policy_registry.cc:46]             registering LB policy factory for \"grpclb\"\nD1119 23:12:21.598906002      38 dns_resolver_plugin.cc:43]            Using EventEngine dns resolver\nD1119 23:12:21.598924180      38 lb_policy_registry.cc:46]             registering LB policy factory for \"rls_experimental\"\nD1119 23:12:21.598946440      38 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_manager_experimental\"\nD1119 23:12:21.598954609      38 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_impl_experimental\"\nD1119 23:12:21.598957742      38 lb_policy_registry.cc:46]             registering LB policy factory for \"cds_experimental\"\nD1119 23:12:21.598961862      38 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_override_host_experimental\"\nD1119 23:12:21.598965064      38 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_wrr_locality_experimental\"\nD1119 23:12:21.598968021      38 lb_policy_registry.cc:46]             registering LB policy factory for \"ring_hash_experimental\"\nD1119 23:12:21.598971336      38 certificate_provider_registry.cc:33]  registering certificate provider factory for \"file_watcher\"\nD1119 23:12:21.598999765      38 channel_init.cc:157]                  Filter server-auth not registered, but is referenced in the after clause of grpc-server-authz when building channel stack SERVER_CHANNEL\nI1119 23:12:21.600775314      38 ev_epoll1_linux.cc:359]               grpc epoll fd: 62\nI1119 23:12:21.618219856      38 tcp_socket_utils.cc:689]              Disabling AF_INET6 sockets because ::1 is not available.\nI1119 23:12:21.622167181     198 socket_utils_common_posix.cc:452]     Disabling AF_INET6 sockets because ::1 is not available.\nI1119 23:12:21.622223162     198 socket_utils_common_posix.cc:379]     TCP_USER_TIMEOUT is available. TCP_USER_TIMEOUT will be used thereafter\nE1119 23:12:21.630870090      38 oauth2_credentials.cc:238]            oauth_fetch: UNKNOWN:C-ares status is not ARES_SUCCESS qtype=A name=metadata.google.internal. is_balancer=0: Domain name not found {grpc_status:2, created_time:\"2024-11-19T23:12:21.630855655+00:00\"}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Add TPU call","metadata":{}},{"cell_type":"code","source":"def setup_tpu_colab():\n    \"\"\"Setup TPU for Kaggle/Colab\"\"\"\n    import requests\n    from requests.exceptions import ConnectionError\n    \n    # Check if TPU is available\n    try:\n        # Get TPU core count\n        tpu_env = os.environ.get('TPU_NAME')\n        if tpu_env:\n            url = f'http://{os.environ[\"COLAB_TPU_ADDR\"]}/requestversion/tpu_worker_state'\n            timeout = 60  # seconds\n            try:\n                response = requests.get(url, timeout=timeout)\n                if response.ok:\n                    print(\"TPU available and responding\")\n                    return True\n            except ConnectionError:\n                print(\"Failed to connect to TPU\")\n                return False\n    except Exception as e:\n        print(f\"Error checking TPU: {str(e)}\")\n        return False\n    \n    return False\n\ndef initialize_tpu():\n    \"\"\"Initialize TPU with error handling\"\"\"\n    try:\n        # Clear any previous TPU memory\n        if hasattr(torch_xla, 'core'):\n            torch_xla.core.xla_model.clear_replicated()\n        \n        # Get TPU device\n        device = xm.xla_device()\n        print(f\"TPU Device initialized: {device}\")\n        \n        # Test device\n        test_tensor = torch.randn(2, 2).to(device)\n        print(\"TPU test successful\")\n        \n        return device\n    except Exception as e:\n        print(f\"Failed to initialize TPU: {str(e)}\")\n        print(\"Falling back to CPU/GPU\")\n        return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Label Handling","metadata":{"id":"pnEBLV4Dk6T-"}},{"cell_type":"code","source":"# At start of notebook\n!nvidia-smi\nprint(f\"CUDA Available: {torch.cuda.is_available()}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1732040986608,"user":{"displayName":"Roger Nick Anaedevha","userId":"11403452854921994388"},"user_tz":-180},"id":"3iT3EB2ukM9v","outputId":"e36936cf-9cf5-4613-8003-619b0e9ad0d0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LabelHandler:\n    \"\"\"Handle both binary and multi-class labels for poisoning detection\"\"\"\n    def __init__(self):\n        self.label_mapping = {}  # Store original label meanings\n        self.attack_types = {}   # Store attack type categories\n        self.binary_mapping = {} # Map between binary and multi-class\n\n    def process_labels(self, labels: np.ndarray, label_names: List[str] = None) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"Process labels to maintain both binary and multi-class information\n\n        Args:\n            labels: Original multi-class labels\n            label_names: Optional list of label names/descriptions\n\n        Returns:\n            Tuple of (binary_labels, multi_class_labels)\n        \"\"\"\n        unique_labels = np.unique(labels)\n\n        # Store mapping if not already created\n        if not self.label_mapping:\n            self.label_mapping = {\n                idx: name if label_names is not None and idx < len(label_names) else f\"Class_{idx}\"\n                for idx in unique_labels\n            }\n\n            # Create binary mapping (0 for normal, 1 for any attack)\n            self.binary_mapping = {\n                idx: 0 if idx == 0 else 1  # Assuming 0 is normal traffic\n                for idx in unique_labels\n            }\n\n            # Store attack types separately\n            self.attack_types = {\n                idx: label\n                for idx, label in self.label_mapping.items()\n                if idx != 0  # Exclude normal traffic\n            }\n\n        # Create both label versions\n        binary_labels = np.array([self.binary_mapping[l] for l in labels])\n        multi_labels = labels.copy()\n\n        return binary_labels, multi_labels\n\n    def get_attack_info(self, attack_id: int) -> Dict[str, Union[str, bool, int]]:\n        \"\"\"Get information about a specific attack type\"\"\"\n        if attack_id not in self.label_mapping:\n            return {\n                'attack_name': f'Unknown_Attack_{attack_id}',\n                'is_attack': True,\n                'attack_id': attack_id,\n                'binary_class': self.binary_mapping.get(attack_id, 1)\n            }\n\n        return {\n            'attack_name': self.label_mapping[attack_id],\n            'is_attack': self.binary_mapping.get(attack_id, 1) == 1,\n            'attack_id': attack_id,\n            'binary_class': self.binary_mapping.get(attack_id, 1)\n        }\n\n    def get_attack_stats(self, multi_labels: np.ndarray) -> Dict[str, Dict[str, Union[int, float, bool]]]:\n        \"\"\"Get statistics about attack distribution\"\"\"\n        unique, counts = np.unique(multi_labels, return_counts=True)\n        total = len(multi_labels)\n\n        stats = {}\n        for u, c in zip(unique, counts):\n            attack_info = self.get_attack_info(u)\n            stats[attack_info['attack_name']] = {\n                'count': int(c),\n                'percentage': float(c/total),\n                'is_attack': attack_info['is_attack']\n            }\n\n        return stats\n\n    def print_distribution(self, labels: np.ndarray):\n        \"\"\"Print distribution of attacks in dataset\"\"\"\n        stats = self.get_attack_stats(labels)\n\n        print(\"\\nAttack Distribution:\")\n        print(\"-\" * 50)\n        print(f\"{'Attack Type':<30} {'Count':>8} {'Percentage':>12}\")\n        print(\"-\" * 50)\n\n        for attack_name, info in stats.items():\n            print(f\"{attack_name:<30} {info['count']:>8} {info['percentage']:>11.2f}%\")\n\n    def __str__(self) -> str:\n        return f\"LabelHandler with {len(self.attack_types)} attack types\"\n\n    def __repr__(self) -> str:\n        return f\"LabelHandler(n_attacks={len(self.attack_types)}, n_labels={len(self.label_mapping)})\"\n\n","metadata":{"id":"lfMDodREk8aD","executionInfo":{"status":"ok","timestamp":1732040987166,"user_tz":-180,"elapsed":565,"user":{"displayName":"Roger Nick Anaedevha","userId":"11403452854921994388"}},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## System setup","metadata":{"id":"F6DJ7Ruik_Qg"}},{"cell_type":"code","source":"# System setup function\ndef setup_system():\n    \"\"\"Setup system checks and cleanup before training\"\"\"\n    print(\"\\n=== System Setup ===\")\n\n    # Clear memory\n    gc.collect()\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n        print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n        print(f\"CUDA Device: {torch.cuda.get_device_name(0)}\")\n        print(f\"CUDA Memory: {torch.cuda.get_device_properties(0).total_memory/1e9:.2f}GB\")\n        print(f\"CUDA Capability: {torch.cuda.get_device_capability()}\")\n    else:\n        print(\"Using CPU for training\")\n\n    # Check available memory\n    process = psutil.Process()\n    print(f\"Initial memory usage: {process.memory_info().rss/1024/1024:.2f}MB\")\n\n    # Initialize logging\n    logging.basicConfig(\n        level=logging.INFO,\n        format='%(asctime)s - %(levelname)s - %(message)s',\n        handlers=[\n            logging.FileHandler('training.log'),\n            logging.StreamHandler()\n        ]\n    )\n\n    # Verify system requirements\n    memory_gb = psutil.virtual_memory().total / (1024**3)\n    if memory_gb < 8:  # Minimum 8GB required\n        raise RuntimeError(f\"Insufficient memory: {memory_gb:.1f}GB < 8GB required\")\n\n    # Set random seeds for reproducibility\n    random.seed(42)\n    np.random.seed(42)\n    torch.manual_seed(42)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(42)\n\n    print(\"System setup completed successfully\")\n    return True\n\n# Memory monitoring class\nclass MemoryMonitor:\n    \"\"\"Monitor system memory usage during training\"\"\"\n    def __init__(self, log_interval=60):  # Log every 60 seconds\n        self.log_interval = log_interval\n        self.last_log_time = time.time()\n\n        # Setup logging\n        logging.basicConfig(\n            filename='memory_usage.log',\n            level=logging.INFO,\n            format='%(asctime)s - %(message)s'\n        )\n\n    def check_memory(self):\n        current_time = time.time()\n        if current_time - self.last_log_time >= self.log_interval:\n            process = psutil.Process()\n            memory_info = process.memory_info()\n            system_memory = psutil.virtual_memory()\n\n            logging.info(\n                f\"Memory Usage - RSS: {memory_info.rss/1024/1024:.2f}MB, \"\n                f\"VMS: {memory_info.vms/1024/1024:.2f}MB, \"\n                f\"System Memory Used: {system_memory.percent}%\"\n            )\n\n            self.last_log_time = current_time\n            return system_memory.percent > 90  # Warning threshold\n        return False\n\nclass GPUMemoryManager:\n    @staticmethod\n    def print_memory_stats():\n        \"\"\"Print memory usage for either GPU or CPU\"\"\"\n        if torch.cuda.is_available():\n            print(\"\\nGPU Memory Usage:\")\n            print(f\"Allocated: {torch.cuda.memory_allocated()/1e9:.2f}GB\")\n            print(f\"Cached: {torch.cuda.memory_reserved()/1e9:.2f}GB\")\n        else:\n            process = psutil.Process()\n            print(\"\\nCPU Memory Usage:\")\n            print(f\"RSS: {process.memory_info().rss/1e9:.2f}GB\")\n            print(f\"VMS: {process.memory_info().vms/1e9:.2f}GB\")\n\n    @staticmethod\n    def clear_memory():\n        \"\"\"Clear memory cache\"\"\"\n        gc.collect()\n        if torch.cuda.is_available():\n            torch.cuda.empty_cache()\n\n    @staticmethod\n    def get_memory_usage():\n        \"\"\"Get current memory usage as percentage\"\"\"\n        if torch.cuda.is_available():\n            return torch.cuda.memory_allocated() / torch.cuda.get_device_properties(0).total_memory\n        else:\n            process = psutil.Process()\n            return process.memory_percent()\n\n","metadata":{"id":"UTqhJQ6e8JUb","executionInfo":{"status":"ok","timestamp":1732040987167,"user_tz":-180,"elapsed":12,"user":{"displayName":"Roger Nick Anaedevha","userId":"11403452854921994388"}},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model configuration","metadata":{"id":"7aeQrTt-cQDC"}},{"cell_type":"code","source":"class ModelConfig:\n    def __init__(self):\n        # Check TPU availability\n        if setup_tpu_colab():\n            self.device = initialize_tpu()\n            self.use_tpu = True\n            # TPU-specific settings\n            self.batch_size = 1024  # TPU prefers larger batches\n            self.num_workers = 8\n            self.use_amp = False  # TPU has its own optimization\n        else:\n            self.use_tpu = False\n            self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n            # Regular settings\n            self.batch_size = 512 if torch.cuda.is_available() else 128\n            self.num_workers = 4 if torch.cuda.is_available() else 2\n            self.use_amp = torch.cuda.is_available()\n        \n        print(f\"Using device: {self.device}\")\n        print(f\"Batch size: {self.batch_size}\")\n        \n    \"\"\"Configuration for the DQN-Actor-Critic model and training process\"\"\"\n    def __init__(self):\n        # Force CUDA device if available\n        if torch.cuda.is_available():\n            print(f\"CUDA is available. Using GPU: {torch.cuda.get_device_name(0)}\")\n            self.device = torch.device(\"cuda:0\")\n        else:\n            print(\"CUDA is not available. Using CPU.\")\n            self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n        # Model Architecture\n        self.feature_dim = 128\n        self.hidden_dim = 256\n        self.num_actions = 2\n        self.num_heads = 4  # For attention mechanism\n        self.dropout_rate = 0.2\n\n        # Training Parameters\n        self.learning_rate = 1e-4\n        self.batch_size = 256\n        self.num_epochs = 100\n        self.sequence_length = 10\n        self.gamma = 0.99  # Discount factor\n\n        # DQN Specific\n        self.epsilon_start = 1.0\n        self.epsilon_end = 0.01\n        self.epsilon_decay = 0.995\n\n        # Actor-Critic Specific\n        self.value_loss_coef = 0.5\n        self.entropy_coef = 0.01\n\n        # Integration Parameters\n        self.dqn_weight = 0.6  # Weight for DQN in combined decisions\n        self.ac_weight = 0.4   # Weight for Actor-Critic in combined decisions\n\n        # Memory and Buffer\n        self.replay_buffer_size = 10000\n        self.min_replay_size = 1000\n\n        # Optimization\n        self.gradient_clip = 1.0\n        self.warmup_steps = 1000\n        self.target_update_freq = 10\n\n        # Early Stopping\n        self.patience = 5\n        self.min_delta = 0.001\n\n        # Directories\n        self.checkpoint_dir = 'checkpoints'\n        self.log_dir = 'logs'\n\n        # Device Specific Optimizations\n        self._setup_device_specific()\n\n    def _setup_device_specific(self):\n        \"\"\"Setup device-specific optimizations\"\"\"\n        if self.device.type == \"cuda\":\n            # GPU settings\n            self.use_amp = True  # Enable automatic mixed precision\n            self.batch_size = 512  # Larger batch size for GPU\n            self.num_workers = 4\n\n            # Enable TF32 for better performance on Ampere GPUs\n            torch.backends.cuda.matmul.allow_tf32 = True\n            torch.backends.cudnn.allow_tf32 = True\n            torch.backends.cudnn.benchmark = True  # Enable cudnn autotuner\n        else:\n\n            # CPU settings\n            self.use_amp = False\n            self.batch_size = 128\n            self.num_workers = min(2, os.cpu_count())\n            self.pin_memory = False\n\n        # Enable Intel MKL optimizations if available\n        if hasattr(torch, 'set_num_threads'):\n            torch.set_num_threads(self.num_workers)\n        if hasattr(torch, 'set_num_interop_threads'):\n            torch.set_num_interop_threads(self.num_workers)\n\n    def print_config(self):\n        \"\"\"Print the current configuration\"\"\"\n        print(\"\\nModel Configuration:\")\n        print(f\"- Device: {self.device}\")\n        print(f\"- Feature Dimension: {self.feature_dim}\")\n        print(f\"- Hidden Dimension: {self.hidden_dim}\")\n        print(f\"- Batch Size: {self.batch_size}\")\n        print(f\"- Learning Rate: {self.learning_rate}\")\n        print(f\"- Number of Epochs: {self.num_epochs}\")\n        print(f\"- DQN Weight: {self.dqn_weight}\")\n        print(f\"- Actor-Critic Weight: {self.ac_weight}\")\n        if self.device.type == \"cuda\":\n            print(f\"- AMP Enabled: {self.use_amp}\")\n            print(f\"- CUDA Capability: {torch.cuda.get_device_capability()}\")\n\n\n","metadata":{"id":"PRwDyLgdcJc_","executionInfo":{"status":"ok","timestamp":1732040987167,"user_tz":-180,"elapsed":12,"user":{"displayName":"Roger Nick Anaedevha","userId":"11403452854921994388"}},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Loading and Preprocessing","metadata":{"id":"PN4r4SVOcaOb"}},{"cell_type":"code","source":"## DATASET SPECIFIC PROCESSOR\n\nclass DatasetSpecificProcessor:\n    \"\"\"Processes features specific to each dataset type\"\"\"\n    def __init__(self, dataset_type: str):\n        self.dataset_type = dataset_type.lower()\n        self.protocol_features = {}\n        self.temporal_windows = {}\n        self.flow_statistics = {}\n\n    def process_features(self, data: pd.DataFrame) -> pd.DataFrame:\n        \"\"\"Process features based on dataset type\"\"\"\n        # Ensure data is properly formatted as DataFrame with string column names\n        if not isinstance(data, pd.DataFrame):\n            data = pd.DataFrame(data)\n\n        # Convert numeric column indices to string names if needed\n        if all(isinstance(col, int) for col in data.columns):\n            data.columns = [f'feature_{i}' for i in range(len(data.columns))]\n\n        if self.dataset_type == 'cic':\n            return self._process_cic_features(data)\n        elif self.dataset_type == 'ton':\n            return self._process_ton_features(data)\n        elif self.dataset_type == 'cse':\n            return self._process_cse_features(data)\n        else:\n            raise ValueError(f\"Unknown dataset type: {self.dataset_type}\")\n\n    def _process_cic_features(self, data: pd.DataFrame) -> pd.DataFrame:\n        \"\"\"Process CIC-IoT specific features\"\"\"\n        processed_data = data.copy()\n\n        # Find protocol-related columns (case insensitive)\n        protocol_columns = [\n            col for col in processed_data.columns\n            if isinstance(col, str) and 'protocol' in col.lower()\n        ]\n\n        # Process protocol features if any exist\n        if protocol_columns:\n            # One-hot encoding for protocol columns\n            processed_data = pd.get_dummies(\n                processed_data,\n                columns=protocol_columns,\n                prefix=['protocol']\n            )\n\n        # Calculate packet and connection rates for numeric columns\n        numeric_cols = processed_data.select_dtypes(include=[np.number]).columns\n        if 'packet_count' in numeric_cols and 'duration' in numeric_cols:\n            processed_data['packet_rate'] = (\n                processed_data['packet_count'] /\n                processed_data['duration'].clip(lower=1e-6)\n            )\n\n        if 'connection_count' in numeric_cols and 'duration' in numeric_cols:\n            processed_data['connection_rate'] = (\n                processed_data['connection_count'] /\n                processed_data['duration'].clip(lower=1e-6)\n            )\n\n        return processed_data\n\n    def _process_ton_features(self, data: pd.DataFrame) -> pd.DataFrame:\n        \"\"\"Process TON-IoT specific features\"\"\"\n        processed_data = data.copy()\n        window_size = 10\n\n        # Process numeric features\n        numeric_cols = processed_data.select_dtypes(include=[np.number]).columns\n        for col in numeric_cols:\n            # Calculate temporal mean and variance safely\n            try:\n                processed_data[f'{col}_temporal_mean'] = processed_data[col].rolling(\n                    window=window_size, min_periods=1\n                ).mean()\n                processed_data[f'{col}_temporal_var'] = processed_data[col].rolling(\n                    window=window_size, min_periods=1\n                ).var()\n            except Exception as e:\n                print(f\"Warning: Could not process column {col}: {str(e)}\")\n\n        # Find and process service-related columns\n        service_columns = [\n            col for col in processed_data.columns\n            if isinstance(col, str) and 'service' in col.lower()\n        ]\n\n        if service_columns:\n            for service in service_columns:\n                try:\n                    # Convert to numeric if needed\n                    if not pd.api.types.is_numeric_dtype(processed_data[service]):\n                        processed_data[service] = pd.to_numeric(\n                            processed_data[service], errors='coerce'\n                        )\n                    # Calculate service rate\n                    processed_data[f'{service}_rate'] = processed_data[service].rolling(\n                        window=window_size, min_periods=1\n                    ).mean()\n                except Exception as e:\n                    print(f\"Warning: Could not process service column {service}: {str(e)}\")\n\n        return processed_data\n\n    def _process_cse_features(self, data: pd.DataFrame) -> pd.DataFrame:\n        \"\"\"Process CSE-CIC specific features\"\"\"\n        processed_data = data.copy()\n        window_size = 10\n\n        # Process numeric features only\n        numeric_cols = processed_data.select_dtypes(include=[np.number]).columns\n\n        # Process flow-based features\n        if 'bytes_transferred' in numeric_cols and 'duration' in numeric_cols:\n            processed_data['flow_byte_rate'] = (\n                processed_data['bytes_transferred'] /\n                processed_data['duration'].clip(lower=1e-6)\n            )\n\n        # Process packet statistics\n        if 'packet_size' in numeric_cols:\n            processed_data['packet_size_mean'] = processed_data['packet_size'].rolling(\n                window=window_size, min_periods=1\n            ).mean()\n            processed_data['packet_size_std'] = processed_data['packet_size'].rolling(\n                window=window_size, min_periods=1\n            ).std()\n\n        # Process flow statistics\n        if 'flow_duration' in numeric_cols:\n            processed_data['flow_rate'] = 1.0 / processed_data['flow_duration'].clip(lower=1e-6)\n            processed_data['flow_rate_mean'] = processed_data['flow_rate'].rolling(\n                window=window_size, min_periods=1\n            ).mean()\n\n        return processed_data\n\n\nclass PoisoningFeatureExtractor:\n    \"\"\"Extracts poisoning-specific features\"\"\"\n    def __init__(self, window_size: int = 100):\n        self.window_size = window_size\n        self.feature_history = deque(maxlen=window_size)\n        self.distribution_history = deque(maxlen=window_size)\n\n    def extract_poisoning_features(self, data: pd.DataFrame) -> Dict[str, np.ndarray]:\n        \"\"\"Extract all poisoning-specific features\"\"\"\n        # Ensure data is properly formatted\n        if not isinstance(data, pd.DataFrame):\n            data = pd.DataFrame(data)\n\n        features = {}\n\n        try:\n            # Extract distribution drift features\n            features.update(self._detect_distribution_drift(data))\n\n            # Extract temporal consistency features\n            features.update(self._check_temporal_consistency(data))\n\n            # Extract protocol behavior features\n            features.update(self._analyze_protocol_behavior(data))\n\n            # Extract traffic pattern anomaly features\n            features.update(self._detect_traffic_anomalies(data))\n\n        except Exception as e:\n            print(f\"Warning: Error extracting poisoning features: {str(e)}\")\n            # Return default features if extraction fails\n            features = {\n                'distribution_drift': np.array([0.0]),\n                'temporal_consistency': np.array([0.0]),\n                'protocol_frequency': np.array([0.0]),\n                'traffic_anomaly': np.array([0.0])\n            }\n\n        return features\n\n    def _detect_distribution_drift(self, data: pd.DataFrame) -> Dict[str, float]:\n        \"\"\"Detect distribution shifts with improved stability\"\"\"\n        numeric_data = data.select_dtypes(include=[np.number])\n        eps = 1e-8  # Numerical stability constant\n\n        if len(self.feature_history) > 0:\n            try:\n                # Compute means with stability\n                previous_mean = np.nanmean([x.mean() for x in self.feature_history], axis=0)\n                current_mean = numeric_data.mean()\n\n                # Compute covariance with stability\n                previous_data = np.hstack([x.values for x in self.feature_history])\n                previous_cov = np.cov(previous_data.T) + eps * np.eye(previous_data.shape[1])\n                current_cov = numeric_data.cov() + eps * np.eye(numeric_data.shape[1])\n\n                # Calculate drift score\n                mean_diff = np.linalg.norm(current_mean - previous_mean)\n                cov_diff = np.linalg.norm(current_cov - previous_cov, ord='fro')\n                drift_score = (mean_diff + cov_diff) / (1 + eps)\n\n            except Exception as e:\n                print(f\"Warning: Error computing drift score: {str(e)}\")\n                drift_score = 0.0\n        else:\n            drift_score = 0.0\n\n        self.feature_history.append(numeric_data)\n        return {'distribution_drift': drift_score}\n\n\n    def _check_temporal_consistency(self, data: pd.DataFrame) -> Dict[str, float]:\n        \"\"\"Check temporal consistency of features\"\"\"\n        numeric_data = data.select_dtypes(include=[np.number])\n        consistency_score = 0.0\n\n        if len(self.feature_history) > 0:\n            previous_data = self.feature_history[-1]\n            common_cols = set(numeric_data.columns) & set(previous_data.columns)\n\n            if common_cols:\n                consistency_score = np.mean([\n                    np.abs(numeric_data[col] - previous_data[col]).mean()\n                    for col in common_cols\n                ])\n\n        return {'temporal_consistency': consistency_score}\n\n    def _analyze_protocol_behavior(self, data: pd.DataFrame) -> Dict[str, np.ndarray]:\n        \"\"\"Analyze protocol behavior patterns\"\"\"\n        protocol_columns = [\n            col for col in data.columns\n            if isinstance(col, str) and 'protocol' in col.lower()\n        ]\n\n        if protocol_columns:\n            protocol_freqs = data[protocol_columns].mean()\n            return {'protocol_frequency': protocol_freqs.values}\n        return {'protocol_frequency': np.array([0.0])}\n\n    def _detect_traffic_anomalies(self, data: pd.DataFrame) -> Dict[str, np.ndarray]:\n        \"\"\"Detect anomalies in traffic patterns\"\"\"\n        numeric_data = data.select_dtypes(include=[np.number])\n        if 'packet_count' in numeric_data.columns:\n            expected_count = numeric_data['packet_count'].mean()\n            observed_counts = numeric_data['packet_count']\n\n            anomaly_scores = np.abs(\n                (observed_counts - expected_count) /\n                np.maximum(expected_count, 1e-6)\n            )\n            return {'traffic_anomaly': anomaly_scores.values}\n        return {'traffic_anomaly': np.array([0.0])}\n\n\nclass PoisoningGenerator:\n    \"\"\"Generates synthetic poisoning samples\"\"\"\n    def __init__(self, epsilon: float = 0.1, flip_rate: float = 0.1):\n        self.epsilon = epsilon\n        self.flip_rate = flip_rate\n\n    def generate_gradient_based_poisoning(self, data: torch.Tensor, loss_fn: callable) -> torch.Tensor:\n        \"\"\"Generate gradient-based poisoning samples\"\"\"\n        data.requires_grad = True\n        loss = loss_fn(data)\n        gradient = torch.autograd.grad(loss, data)[0]\n        poisoned_data = data + self.epsilon * torch.sign(gradient)\n        return poisoned_data.detach()\n\n    def generate_label_flipping_attacks(self, labels: np.ndarray) -> np.ndarray:\n        \"\"\"Generate label flipping attacks\"\"\"\n        flipped_labels = labels.copy()\n        flip_mask = np.random.random(len(labels)) < self.flip_rate\n        flipped_labels[flip_mask] = 1 - labels[flip_mask]\n        return flipped_labels\n\n    def generate_backdoor_triggers(self, data: np.ndarray, trigger_pattern: np.ndarray) -> np.ndarray:\n        \"\"\"Generate backdoor triggers\"\"\"\n        poisoned_data = data.copy()\n        backdoor_mask = np.random.random(len(data)) < self.flip_rate\n        poisoned_data[backdoor_mask] += trigger_pattern\n        return poisoned_data\n\n    def generate_clean_label_poisoning(self, data: np.ndarray, boundary_shift: np.ndarray) -> np.ndarray:\n        \"\"\"Generate clean label poisoning\"\"\"\n        poisoned_data = data.copy()\n        poison_mask = np.random.random(len(data)) < self.flip_rate\n        poisoned_data[poison_mask] += boundary_shift\n        return poisoned_data\n\n\n## DATASET LOADER\n\nclass EnhancedDatasetLoader:\n    \"\"\"Enhanced dataset loader with dataset-specific processing and poisoning detection\"\"\"\n    def __init__(self, dataset_type: str, config: ModelConfig = None):\n        self.dataset_type = dataset_type.lower()\n        self.config = config or ModelConfig()\n\n        # Label column mappings\n        self.label_columns = {\n            'cic': 'Label',\n            'ton': 'label',\n            'cse': ' Label'  # Note the space before Label for CSE dataset\n        }\n\n        # Initialize processors\n        self.feature_scaler = StandardScaler()\n        self.label_encoder = LabelEncoder()\n        self.label_handler = LabelHandler()\n        self.dataset_processor = DatasetSpecificProcessor(self.dataset_type)\n        self.poisoning_extractor = PoisoningFeatureExtractor()\n        self.poisoning_generator = PoisoningGenerator()\n        self.data_stabilizer = DataStabilizer()\n\n        # Add clip values\n        self.max_value = 1e10\n        self.min_value = -1e10\n\n        # Validation thresholds\n        self.validation_thresholds = {\n            'mean_threshold': 0.1,\n            'std_threshold': 0.1,\n            'correlation_threshold': 0.95,\n            'min_class_ratio': 0.01\n        }\n\n        # Statistics tracking\n        self.stats = defaultdict(list)\n        self.feature_columns = None\n        self.removed_columns = set()\n\n        print(f\"\\nInitialized Enhanced Dataset Loader for {self.dataset_type.upper()}\")\n\n    def _get_label_column(self, chunk: pd.DataFrame) -> str:\n        \"\"\"Get appropriate label column based on dataset type and available columns\"\"\"\n        # First try the predefined mapping\n        default_label = self.label_columns.get(self.dataset_type)\n        if default_label in chunk.columns:\n            return default_label\n\n        # Try common variations\n        common_labels = ['Label', 'label', ' Label', 'type', 'class']\n        for label in common_labels:\n            if label in chunk.columns:\n                return label\n\n        # If still not found, look for any column containing 'label' (case insensitive)\n        label_cols = [col for col in chunk.columns if 'label' in col.lower()]\n        if label_cols:\n            return label_cols[0]\n\n        raise ValueError(f\"No label column found for {self.dataset_type} dataset\")\n\n    def _process_chunk(self, chunk: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"Process data chunk with appropriate label handling\"\"\"\n        try:\n            # Get label column\n            label_col = self._get_label_column(chunk)\n            print(f\"Found label column: {label_col}\")\n\n            if label_col not in chunk.columns:\n                raise ValueError(f\"Label column '{label_col}' not found\")\n\n            # Convert numeric columns\n            feature_cols = [col for col in chunk.columns if col != label_col]\n            numeric_chunk = pd.DataFrame()\n\n            for col in feature_cols:\n                try:\n                    numeric_chunk[col] = pd.to_numeric(chunk[col], errors='coerce')\n                except Exception as e:\n                    print(f\"Warning: Could not convert column {col}: {str(e)}\")\n                    numeric_chunk[col] = 0\n\n            # Handle missing values\n            numeric_chunk = numeric_chunk.fillna(0)\n\n            # Extract features and preprocess\n            features = self._preprocess_features(numeric_chunk.values)\n            labels = chunk[label_col].values\n\n            # Verify data\n            if features is None or len(features) == 0:\n                raise ValueError(\"No valid features extracted from chunk\")\n\n            return features, labels\n\n        except Exception as e:\n            print(f\"Error processing chunk: {str(e)}\")\n            return None, None\n\n\n    def _preprocess_features(self, features: np.ndarray) -> np.ndarray:\n        \"\"\"Preprocess features to handle infinities and large values\"\"\"\n        try:\n            if features is None or len(features) == 0:\n                return None\n\n            # Replace inf values\n            features = np.nan_to_num(features, nan=0.0, posinf=self.max_value, neginf=self.min_value)\n\n            # Clip extreme values\n            features = np.clip(features, self.min_value, self.max_value)\n\n            # Check for invalid values\n            if not np.all(np.isfinite(features)):\n                print(\"Warning: Invalid values found after preprocessing\")\n                features = np.nan_to_num(features, nan=0.0)\n\n            return features\n\n        except Exception as e:\n            print(f\"Error preprocessing features: {str(e)}\")\n            return None\n\n    def load_and_process_dataset(self, file_path: str) -> Tuple[np.ndarray, np.ndarray, np.ndarray, Dict]:\n        \"\"\"Load and process dataset with enhanced error handling\"\"\"\n        try:\n            print(f\"\\nProcessing {self.dataset_type.upper()} dataset: {file_path}\")\n\n            if not os.path.exists(file_path):\n                raise FileNotFoundError(f\"Dataset file not found: {file_path}\")\n\n            chunks = []\n            labels = []\n            poisoning_features = defaultdict(list)\n\n            # Read and process chunks\n            for chunk in pd.read_csv(file_path, chunksize=10000):\n                features, chunk_labels = self._process_chunk(chunk)\n\n                if features is not None and len(features) > 0:\n                    try:\n                        processed_chunk = self.dataset_processor.process_features(pd.DataFrame(features))\n                        processed_features = self._preprocess_features(processed_chunk.values)\n\n                        if processed_features is not None and len(processed_features) > 0:\n                            chunks.append(processed_features)\n                            labels.extend(chunk_labels)\n\n                            try:\n                                poison_features = self.poisoning_extractor.extract_poisoning_features(processed_chunk)\n                                for key, value in poison_features.items():\n                                    if value is not None and len(value) > 0:\n                                        poisoning_features[key].append(value)\n                            except Exception as e:\n                                print(f\"Warning: Error extracting poisoning features: {str(e)}\")\n\n                    except Exception as e:\n                        print(f\"Warning: Error processing chunk features: {str(e)}\")\n\n            if not chunks:\n                raise ValueError(\"No valid data chunks processed\")\n\n            # Combine and process data\n            X = np.vstack(chunks)\n            y = np.array(labels)\n\n            # Scale features\n            X_scaled = self.feature_scaler.fit_transform(X)\n\n            # Process labels\n            y_encoded = self.label_encoder.fit_transform(y)\n            binary_labels, multi_labels = self.label_handler.process_labels(y_encoded)\n\n            # Combine poisoning features\n            combined_poison_features = {}\n            for key, values in poisoning_features.items():\n                if values:\n                    try:\n                        combined_poison_features[key] = np.concatenate(values)\n                    except Exception as e:\n                        print(f\"Warning: Could not combine poisoning features for {key}: {str(e)}\")\n                        combined_poison_features[key] = np.zeros(len(X))\n\n            # Generate synthetic poisoning samples\n            poisoned_samples = self._generate_poisoning_samples(X_scaled, binary_labels)\n\n            print(\"\\nDataset Processing Complete:\")\n            print(f\"- Total samples: {len(y)}\")\n            print(f\"- Feature dimensions: {X_scaled.shape[1]}\")\n            print(f\"- Poisoning features extracted: {list(combined_poison_features.keys())}\")\n\n            return X_scaled, binary_labels, multi_labels, {\n                'poisoning_features': combined_poison_features,\n                'poisoned_samples': poisoned_samples,\n                'validation_stats': self._validate_data_quality(X_scaled, binary_labels, multi_labels)\n            }\n\n        except Exception as e:\n            print(f\"Error processing dataset: {str(e)}\")\n            traceback.print_exc()\n            raise\n\n\n    def _validate_data_quality(self, X: np.ndarray, binary_labels: np.ndarray, multi_labels: np.ndarray) -> Dict:\n        \"\"\"Validate data quality and compute statistics\"\"\"\n        validation_stats = {\n            'feature_stats': {\n                'mean': np.mean(X, axis=0),\n                'std': np.std(X, axis=0)\n            },\n            'class_distribution': {\n                'binary': np.bincount(binary_labels),\n                'multi': np.bincount(multi_labels)\n            },\n            'missing_values': np.isnan(X).sum(),\n            'feature_correlations': np.corrcoef(X.T)\n        }\n        return validation_stats\n\n    def _generate_poisoning_samples(self, X: np.ndarray, y: np.ndarray) -> Dict[str, np.ndarray]:\n        \"\"\"Generate synthetic poisoning samples\"\"\"\n        X_tensor = torch.FloatTensor(X)\n\n        def dummy_loss(x):\n            return torch.mean(x ** 2)\n\n        poisoned_samples = {\n            'gradient_based': self.poisoning_generator.generate_gradient_based_poisoning(\n                X_tensor, dummy_loss\n            ).numpy(),\n            'label_flipping': self.poisoning_generator.generate_label_flipping_attacks(y),\n            'backdoor': self.poisoning_generator.generate_backdoor_triggers(\n                X, np.random.normal(0, 0.1, X.shape[1])\n            ),\n            'clean_label': self.poisoning_generator.generate_clean_label_poisoning(\n                X, np.random.normal(0, 0.1, X.shape[1])\n            )\n        }\n\n        return poisoned_samples\n\n\nclass DatasetStatistics:\n    \"\"\"Track and analyze dataset statistics\"\"\"\n    def __init__(self):\n        self.stats = defaultdict(list)\n\n    def update(self, batch_stats: Dict):\n        \"\"\"Update statistics with batch information\"\"\"\n        for k, v in batch_stats.items():\n            self.stats[k].append(v)\n\n    def get_summary(self) -> Dict:\n        \"\"\"Get summary statistics\"\"\"\n        summary = {}\n        for k, v in self.stats.items():\n            if isinstance(v[0], (int, float, np.number)):\n                summary[k] = {\n                    'mean': np.mean(v),\n                    'std': np.std(v),\n                    'min': np.min(v),\n                    'max': np.max(v)\n                }\n        return summary\n\nclass BatchGenerator:\n    \"\"\"Generate training batches with augmentation\"\"\"\n    def __init__(self, X: np.ndarray, y: np.ndarray, batch_size: int,\n                 shuffle: bool = True):\n        self.X = X\n        self.y = y\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.n_samples = len(X)\n        self.indices = np.arange(self.n_samples)\n\n    def __len__(self):\n        return int(np.ceil(self.n_samples / self.batch_size))\n\n    def __iter__(self):\n        if self.shuffle:\n            np.random.shuffle(self.indices)\n\n        for start_idx in range(0, self.n_samples, self.batch_size):\n            end_idx = min(start_idx + self.batch_size, self.n_samples)\n            batch_indices = self.indices[start_idx:end_idx]\n\n            yield (\n                self.X[batch_indices],\n                self.y[batch_indices]\n            )\n\n","metadata":{"id":"B8MUhliccWV7","executionInfo":{"status":"ok","timestamp":1732040987167,"user_tz":-180,"elapsed":11,"user":{"displayName":"Roger Nick Anaedevha","userId":"11403452854921994388"}},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## neural network Component","metadata":{"id":"IYzwmqAftpWQ"}},{"cell_type":"code","source":"# Feature Extraction\nclass FeatureExtractor(nn.Module):\n    \"\"\"Enhanced feature extraction with attention\"\"\"\n    def __init__(self, input_dim: int, hidden_dims: List[int], dropout_rate: float = 0.2):\n        super().__init__()\n        self.input_dim = input_dim\n        layers = []\n        prev_dim = input_dim\n\n        for dim in hidden_dims:\n            layers.extend([\n                nn.Linear(prev_dim, dim),\n                nn.LayerNorm(dim),\n                nn.ReLU(),\n                nn.Dropout(dropout_rate)\n            ])\n            prev_dim = dim\n\n        self.feature_layers = nn.Sequential(*layers)\n        print(f\"Feature extractor created with input dim: {input_dim}\")\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        if x.dim() == 1:\n            x = x.unsqueeze(0)\n        elif x.dim() > 2:\n            x = x.view(x.size(0), -1)\n\n        return self.feature_layers(x)\n\nclass DataStabilizer:\n    \"\"\"Handle numerical stability in data processing\"\"\"\n    def __init__(self, eps=1e-8):\n        self.eps = eps\n\n    def stabilize_array(self, arr):\n        \"\"\"Stabilize numpy array by handling zeros and infinities\"\"\"\n        # Replace infinities with large finite numbers\n        arr = np.nan_to_num(arr, nan=0.0, posinf=1e10, neginf=-1e10)\n        return arr\n\n    def safe_divide(self, numerator, denominator):\n        \"\"\"Safe division avoiding divide by zero\"\"\"\n        return numerator / (denominator + self.eps)\n\n    def normalize_features(self, features):\n        \"\"\"Normalize features with numerical stability\"\"\"\n        mean = np.mean(features, axis=0)\n        std = np.std(features, axis=0) + self.eps\n        return (features - mean) / std\n\n    def stabilize_gradients(self, tensor):\n        \"\"\"Stabilize gradients for tensor operations\"\"\"\n        if torch.is_tensor(tensor):\n            return torch.clamp(tensor, min=-1e6, max=1e6)\n        return tensor\n\n\n\n# DQN Component\nclass DQNStream(nn.Module):\n    \"\"\"DQN stream with LSTM and attention\"\"\"\n    def __init__(self, feature_dim: int, hidden_dim: int, num_actions: int,\n                 num_heads: int = 4):\n        super().__init__()\n        self.lstm = nn.LSTM(feature_dim, hidden_dim, batch_first=True)\n        self.attention = nn.MultiheadAttention(hidden_dim, num_heads)\n\n        self.value_head = nn.Sequential(\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, num_actions)\n        )\n\n        self.advantage_head = nn.Sequential(\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, num_actions)\n        )\n\n    def forward(self, features: torch.Tensor, hidden=None) -> Tuple[torch.Tensor, Tuple]:\n        # LSTM processing\n        lstm_out, hidden = self.lstm(features, hidden)\n\n        # Self-attention\n        attn_out, _ = self.attention(lstm_out, lstm_out, lstm_out)\n\n        # Combine LSTM and attention\n        combined = lstm_out + attn_out\n        last_hidden = combined[:, -1, :]\n\n        # Dueling DQN architecture\n        values = self.value_head(last_hidden)\n        advantages = self.advantage_head(last_hidden)\n\n        # Combine value and advantage\n        q_values = values + (advantages - advantages.mean(dim=1, keepdim=True))\n\n        return q_values, hidden\n\n# Actor-Critic Component\nclass ActorCriticStream(nn.Module):\n    \"\"\"Actor-Critic stream with shared features\"\"\"\n    def __init__(self, feature_dim: int, hidden_dim: int, num_actions: int):\n        super().__init__()\n\n        # Shared layers\n        self.shared_layer = nn.Sequential(\n            nn.Linear(feature_dim, hidden_dim),\n            nn.ReLU(),\n            nn.LayerNorm(hidden_dim)\n        )\n\n        # Actor (policy) network\n        self.actor = nn.Sequential(\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, num_actions),\n            nn.Softmax(dim=-1)\n        )\n\n        # Critic (value) network\n        self.critic = nn.Sequential(\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, 1)\n        )\n\n    def forward(self, features: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n        shared_features = self.shared_layer(features)\n\n        # Get policy distribution and state value\n        action_probs = self.actor(shared_features)\n        state_value = self.critic(shared_features)\n\n        return action_probs, state_value\n\n# Combined Architecture\nclass DualStreamDetector(nn.Module):\n    \"\"\"Integrated DQN and Actor-Critic architecture\"\"\"\n    def __init__(self, input_dim: int, feature_dim: int, hidden_dim: int,\n                 num_actions: int, num_heads: int = 4):\n        super().__init__()\n\n        # Components\n        self.feature_extractor = FeatureExtractor(input_dim, [hidden_dim, feature_dim])\n        self.dqn_stream = DQNStream(feature_dim, hidden_dim, num_actions, num_heads)\n        self.ac_stream = ActorCriticStream(feature_dim, hidden_dim, num_actions)\n\n        # Integration layer\n        self.fusion_layer = nn.Sequential(\n            nn.Linear(num_actions * 2, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, num_actions)\n        )\n\n    def forward(self, x: torch.Tensor, hidden=None) -> Dict[str, torch.Tensor]:\n        # Extract features\n        features = self.feature_extractor(x)\n\n        # DQN stream\n        q_values, new_hidden = self.dqn_stream(features.unsqueeze(1), hidden)\n\n        # Actor-Critic stream\n        action_probs, state_value = self.ac_stream(features)\n\n        # Combine outputs\n        combined = torch.cat([q_values, action_probs], dim=-1)\n        final_output = self.fusion_layer(combined)\n\n        return {\n            'q_values': q_values,\n            'action_probs': action_probs,\n            'state_value': state_value,\n            'final_output': final_output,\n            'hidden': new_hidden\n        }\n\n","metadata":{"id":"G5pSRuhft2dJ","executionInfo":{"status":"ok","timestamp":1732040987167,"user_tz":-180,"elapsed":10,"user":{"displayName":"Roger Nick Anaedevha","userId":"11403452854921994388"}},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Poisoning Detection System (Base and Enhanced)","metadata":{"id":"AZPmBeAkt5WG"}},{"cell_type":"code","source":"class DynamicThresholdManager:\n    \"\"\"Manages dynamic thresholds for poisoning detection\"\"\"\n    def __init__(self, initial_threshold=0.5, adaptation_rate=0.01):\n        self.threshold = initial_threshold\n        self.adaptation_rate = adaptation_rate\n        self.historical_predictions = deque(maxlen=1000)\n        self.confidence_history = deque(maxlen=1000)\n\n    def update_threshold(self, current_confidence: float, prediction_correct: bool):\n        self.historical_predictions.append(prediction_correct)\n        self.confidence_history.append(current_confidence)\n\n        recent_accuracy = np.mean(self.historical_predictions)\n        confidence_variance = np.std(self.confidence_history)\n\n        if recent_accuracy < 0.9:\n            self.threshold += self.adaptation_rate * (1 - recent_accuracy)\n        else:\n            self.threshold -= self.adaptation_rate * confidence_variance\n\n        self.threshold = np.clip(self.threshold, 0.3, 0.9)\n        return self.threshold\n\n## GRADUAL POISONING DETECTOR\n\ndef sigmoid(x):\n    \"\"\"Numpy implementation of sigmoid function\"\"\"\n    return 1 / (1 + np.exp(-x))\n\nclass GradualPoisoningDetector:\n    def __init__(self, window_size=100):  # Add this\n        self.window_size = window_size\n        self.feature_history = deque(maxlen=window_size)\n        self.distribution_history = deque(maxlen=window_size)\n\n    def analyze_gradual_changes(self, current_features: np.ndarray) -> Dict[str, float]:\n        \"\"\"Analyze gradual changes with numerical stability\"\"\"\n        try:\n            self.feature_history.append(current_features)\n\n            if len(self.feature_history) < 2:\n                return {\n                    'gradual_poison_probability': 0.0,\n                    'change_consistency': 0.0,\n                    'change_trend': 0.0\n                }\n\n            # Calculate distribution with eps for numerical stability\n            eps = 1e-8\n            current_dist = np.histogram(current_features, bins=20)[0] + eps\n            self.distribution_history.append(current_dist)\n\n            if len(self.distribution_history) >= 2:\n                # Use stable calculation methods\n                distribution_changes = np.diff([dist for dist in self.distribution_history], axis=0)\n\n                # Add small epsilon to avoid division by zero\n                abs_changes = np.abs(distribution_changes) + eps\n                mean_change = np.mean(abs_changes)\n                std_change = np.std(abs_changes) + eps\n\n                # Calculate gradual score with safety checks\n                gradual_score = np.clip(\n                    mean_change * std_change * len(self.distribution_history),\n                    -100, 100\n                )\n\n                # Calculate trend safely\n                time_points = np.arange(len(distribution_changes))\n                if len(time_points) > 1:\n                    try:\n                        avg_changes = np.mean(distribution_changes, axis=1)\n                        trend = np.polyfit(time_points, avg_changes, 1)[0]\n                    except:\n                        trend = 0.0\n                else:\n                    trend = 0.0\n\n                return {\n                    'gradual_poison_probability': float(sigmoid(gradual_score)),\n                    'change_consistency': float(mean_change),\n                    'change_trend': float(trend)\n                }\n\n            return {\n                'gradual_poison_probability': 0.0,\n                'change_consistency': 0.0,\n                'change_trend': 0.0\n            }\n\n        except Exception as e:\n            print(f\"Warning: Error in gradual change analysis: {str(e)}\")\n            return {\n                'gradual_poison_probability': 0.0,\n                'change_consistency': 0.0,\n                'change_trend': 0.0\n            }\n\n\n    def reset(self):\n        \"\"\"Reset detector state\"\"\"\n        self.feature_history.clear()\n        self.distribution_history.clear()\n\n    def get_window_stats(self) -> Dict[str, float]:\n        \"\"\"Get statistics about the current detection window\"\"\"\n        return {\n            'window_size': len(self.feature_history),\n            'max_window': self.window_size,\n            'distribution_samples': len(self.distribution_history)\n        }\n\n\n## DATA AUGUMENTATION\n\nclass DataAugmentation:\n    \"\"\"Data augmentation techniques for poisoning detection\"\"\"\n    def __init__(self, noise_std=0.01, swap_prob=0.1):\n        self.noise_std = noise_std\n        self.swap_prob = swap_prob\n\n    def augment(self, data: torch.Tensor) -> torch.Tensor:\n        augmented = data.clone()\n\n        # Add Gaussian noise\n        if random.random() < self.swap_prob:\n            noise = torch.randn_like(augmented) * self.noise_std\n            augmented += noise\n\n        # Feature permutation\n        if random.random() < self.swap_prob:\n            idx = torch.randperm(augmented.size(1))\n            augmented = augmented[:, idx]\n\n        return augmented\n\n\n# Metrics Tracking\nclass PoisoningDetectionMetrics:\n    \"\"\"Track detection metrics and performance\"\"\"\n    def __init__(self, label_handler=None):  # Make label_handler optional\n        self.detection_history = []\n        self.distribution_stats = []\n        self.dqn_metrics = defaultdict(list)\n        self.ac_metrics = defaultdict(list)\n        self.label_handler = label_handler  # Store label_handler\n\n    def update_metrics(self, features: np.ndarray, prediction: float,\n                      true_label: int, dqn_values: np.ndarray = None,\n                      ac_probs: np.ndarray = None):\n        \"\"\"Update all metrics\"\"\"\n        # Store detection results\n        self.detection_history.append({\n            'prediction': prediction,\n            'true_label': true_label,\n            'feature_stats': {\n                'mean': np.mean(features, axis=0),\n                'std': np.std(features, axis=0),\n                'kurtosis': scipy.stats.kurtosis(features, axis=0),\n                'skewness': scipy.stats.skew(features, axis=0)\n            }\n        })\n\n        # Track DQN metrics\n        if dqn_values is not None:\n            self.dqn_metrics['q_values'].append(np.mean(dqn_values))\n            self.dqn_metrics['q_std'].append(np.std(dqn_values))\n\n        # Track Actor-Critic metrics\n        if ac_probs is not None:\n            self.ac_metrics['policy_entropy'].append(\n                -np.sum(ac_probs * np.log(ac_probs + 1e-10))\n            )\n\n    def compute_metrics(self) -> Dict[str, float]:\n        \"\"\"Compute comprehensive metrics\"\"\"\n        if not self.detection_history:\n            return {}\n\n        # Extract predictions and true labels\n        predictions = [d['prediction'] for d in self.detection_history]\n        true_labels = [d['true_label'] for d in self.detection_history]\n\n        # Convert predictions to class indices if they're probabilities\n        pred_indices = []\n        for pred in predictions:\n            if isinstance(pred, np.ndarray) and pred.ndim > 0:\n                # If prediction is a probability array, get the argmax\n                pred_indices.append(np.argmax(pred))\n            else:\n                # If prediction is already a single value\n                pred_indices.append(pred)\n\n        metrics = {\n            'accuracy': np.mean([p == t for p, t in zip(pred_indices, true_labels)]),\n            'detection_confidence': np.mean([\n                p.max() if isinstance(p, np.ndarray) and p.ndim > 0 else p\n                for p in predictions\n            ]),\n            'false_positive_rate': self._compute_fpr(pred_indices, true_labels)\n        }\n\n        # Add DQN metrics\n        if self.dqn_metrics:\n            metrics.update({\n                'avg_q_value': np.mean(self.dqn_metrics['q_values']),\n                'q_value_std': np.mean(self.dqn_metrics['q_std'])\n            })\n\n        # Add Actor-Critic metrics\n        if self.ac_metrics:\n            metrics.update({\n                'policy_entropy': np.mean(self.ac_metrics['policy_entropy'])\n            })\n\n        return metrics\n\n    def _compute_fpr(self, predictions: List[float], true_labels: List[int]) -> float:\n        \"\"\"Compute False Positive Rate\"\"\"\n        fp = sum(1 for p, t in zip(predictions, true_labels) if p == 1 and t == 0)\n        tn = sum(1 for p, t in zip(predictions, true_labels) if p == 0 and t == 0)\n        return fp / (fp + tn) if (fp + tn) > 0 else 0.0\n\n\n\n# Base Detection System\nclass PoisoningDetectionSystem:\n    \"\"\"Base class for poisoning detection\"\"\"\n    def __init__(self, input_dim: int, config: ModelConfig = None):\n        if config is None:\n            config = ModelConfig()\n\n        self.config = config\n        self.device = config.device\n\n        # Initialize model\n        self.model = DualStreamDetector(\n            input_dim=input_dim,\n            feature_dim=config.feature_dim,\n            hidden_dim=config.hidden_dim,\n            num_actions=config.num_actions\n        ).to(self.device)\n\n        # Optimizer and AMP scaler\n        self.optimizer = torch.optim.Adam(\n            self.model.parameters(),\n            lr=config.learning_rate\n        )\n        self.scaler = torch.cuda.amp.GradScaler() if config.use_amp and self.device.type == \"cuda\" else None\n\n        # Experience replay\n        self.replay_buffer = deque(maxlen=config.replay_buffer_size)\n        self.sequence_length = config.sequence_length\n\n        # Metrics\n        self.training_metrics = defaultdict(list)\n\n    def preprocess_state(self, state: np.ndarray) -> torch.Tensor:\n        \"\"\"Preprocess state for model input\"\"\"\n        try:\n            if isinstance(state, np.ndarray):\n                if state.ndim == 1:\n                    state = state.reshape(1, -1)\n                state_tensor = torch.from_numpy(state).float()\n            else:\n                state_tensor = state.float()\n                if state_tensor.dim() == 1:\n                    state_tensor = state_tensor.unsqueeze(0)\n\n            return state_tensor.to(self.device)\n\n        except Exception as e:\n            print(f\"Error in preprocess_state: {str(e)}\")\n            raise\n\n    def detect(self, state: np.ndarray, evaluate: bool = False) -> Dict[str, np.ndarray]:\n        \"\"\"Detect poisoning attacks\"\"\"\n        with torch.no_grad() if evaluate else torch.enable_grad():\n            processed_state = self.preprocess_state(state)\n            model_output = self.model(processed_state)\n\n            # Get predictions\n            q_values = model_output['q_values']\n            action_probs = model_output['action_probs']\n            detection_prob = F.softmax(model_output['final_output'], dim=-1)\n\n            # Convert to numpy\n            return {\n                'is_poisoning': detection_prob.cpu().numpy(),\n                'q_values': q_values.cpu().numpy(),\n                'action_probs': action_probs.cpu().numpy(),\n                'confidence': model_output['state_value'].cpu().numpy()\n            }\n\nclass PoisoningLoss(nn.Module):\n    def __init__(self, dqn_weight=0.4, policy_weight=0.3, value_weight=0.3, eps=1e-8):\n        super().__init__()\n        self.dqn_weight = dqn_weight\n        self.policy_weight = policy_weight\n        self.value_weight = value_weight\n        self.eps = eps\n\n        self.dqn_criterion = nn.SmoothL1Loss()\n        self.policy_criterion = nn.CrossEntropyLoss()\n        self.value_criterion = nn.MSELoss()\n\n    def forward(self, model_output, targets):\n        # Add numerical stability to outputs\n        q_values = model_output['q_values'].clamp(min=-100, max=100)\n        action_probs = F.softmax(model_output['action_probs'], dim=-1)\n        action_probs = torch.clamp(action_probs, min=self.eps, max=1.0)\n\n        # DQN loss with gradient scaling\n        dqn_loss = self.dqn_criterion(q_values, targets['q_targets'])\n        dqn_loss = torch.where(torch.isfinite(dqn_loss), dqn_loss, torch.zeros_like(dqn_loss))\n\n        # Policy loss with stable log\n        policy_loss = self.policy_criterion(\n            action_probs,\n            targets['actions']\n        )\n\n        # Value loss with bounded predictions\n        value_pred = model_output['state_value'].view(-1).clamp(min=-100, max=100)\n        value_target = targets['returns'].view(-1).clamp(min=-100, max=100)\n        value_loss = self.value_criterion(value_pred, value_target)\n\n        # Detection loss with stable probabilities\n        detection_probs = F.softmax(model_output['final_output'], dim=-1)\n        detection_probs = torch.clamp(detection_probs, min=self.eps, max=1.0)\n        detection_loss = self.policy_criterion(\n            detection_probs,\n            targets['labels']\n        )\n\n        # Combine losses with stability checks\n        total_loss = (\n            self.dqn_weight * torch.nan_to_num(dqn_loss) +\n            self.policy_weight * torch.nan_to_num(policy_loss + detection_loss) +\n            self.value_weight * torch.nan_to_num(value_loss)\n        )\n\n        return {\n            'total_loss': total_loss,\n            'dqn_loss': dqn_loss.item(),\n            'policy_loss': policy_loss.item(),\n            'value_loss': value_loss.item(),\n            'detection_loss': detection_loss.item()\n        }\n\n\n\nclass PoisoningDataAugmentation:\n    \"\"\"Advanced data augmentation techniques specifically for poisoning detection\"\"\"\n    def __init__(self,\n                 noise_std=0.01,\n                 feature_swap_prob=0.1,\n                 feature_scale_range=(0.95, 1.05),\n                 temporal_shift_prob=0.1,\n                 max_shift=3):\n        self.noise_std = noise_std\n        self.feature_swap_prob = feature_swap_prob\n        self.feature_scale_range = feature_scale_range\n        self.temporal_shift_prob = temporal_shift_prob\n        self.max_shift = max_shift\n\n    def augment(self, data: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Apply various augmentation techniques to the input data\n\n        Args:\n            data: Input tensor of shape (batch_size, feature_dim) or (batch_size, sequence_length, feature_dim)\n\n        Returns:\n            Augmented tensor of the same shape\n        \"\"\"\n        augmented = data.clone()\n\n        # Add Gaussian noise\n        if random.random() < self.feature_swap_prob:\n            noise = torch.randn_like(augmented) * self.noise_std\n            augmented += noise\n\n        # Random feature scaling\n        if random.random() < self.feature_swap_prob:\n            scale_factors = torch.FloatTensor(augmented.shape[-1]).uniform_(*self.feature_scale_range)\n            if augmented.dim() == 3:  # Sequential data\n                scale_factors = scale_factors.unsqueeze(0).unsqueeze(0)\n            else:  # Single timestep data\n                scale_factors = scale_factors.unsqueeze(0)\n            augmented *= scale_factors.to(augmented.device)\n\n        # Feature permutation\n        if random.random() < self.feature_swap_prob:\n            feat_idx = torch.randperm(augmented.shape[-1])\n            if augmented.dim() == 3:\n                augmented = augmented[:, :, feat_idx]\n            else:\n                augmented = augmented[:, feat_idx]\n\n        # Temporal shift for sequential data\n        if augmented.dim() == 3 and random.random() < self.temporal_shift_prob:\n            shift = random.randint(-self.max_shift, self.max_shift)\n            augmented = torch.roll(augmented, shifts=shift, dims=1)\n\n        # Ensure values stay within reasonable bounds\n        augmented = torch.clamp(augmented, min=-10, max=10)\n\n        return augmented\n\n    def augment_batch(self, data: torch.Tensor, labels: torch.Tensor = None) -> tuple:\n        \"\"\"\n        Augment a batch of data with optional label preservation\n\n        Args:\n            data: Input tensor\n            labels: Optional label tensor\n\n        Returns:\n            Tuple of (augmented_data, labels)\n        \"\"\"\n        augmented_data = self.augment(data)\n\n        if labels is not None:\n            return augmented_data, labels\n        return augmented_data\n\n    @staticmethod\n    def mix_samples(data: torch.Tensor, labels: torch.Tensor, alpha: float = 0.2) -> tuple:\n        \"\"\"\n        Implement mixup augmentation for robust learning\n\n        Args:\n            data: Input tensor\n            labels: Label tensor\n            alpha: Mixup interpolation strength\n\n        Returns:\n            Tuple of (mixed_data, mixed_labels)\n        \"\"\"\n        if alpha > 0:\n            lam = np.random.beta(alpha, alpha)\n        else:\n            lam = 1\n\n        batch_size = data.size(0)\n        index = torch.randperm(batch_size).to(data.device)\n\n        mixed_data = lam * data + (1 - lam) * data[index]\n        mixed_labels = lam * labels + (1 - lam) * labels[index]\n\n        return mixed_data, mixed_labels\n\n\n# ENHANCED DETECTION SYSTEM\n\nclass EnhancedPoisoningDetectionSystem(PoisoningDetectionSystem):\n    def __init__(self, input_dim: int, config: ModelConfig = None, label_handler: LabelHandler = None):\n        super().__init__(input_dim, config)\n\n        # Initialize device\n        self.device = config.device if config is not None else torch.device(\"cpu\")\n\n        # Move model to correct device immediately after creation\n        self.model = self.model.to(self.device)\n\n        # Initialize components\n        self.label_handler = label_handler\n        self.metrics_tracker = PoisoningDetectionMetrics(label_handler)\n        self.threshold_manager = DynamicThresholdManager()\n        self.gradual_detector = GradualPoisoningDetector()\n        self.pattern_memory = deque(maxlen=1000)\n\n        # Add missing components that caused errors\n        self.data_stabilizer = DataStabilizer()\n        self.criterion = PoisoningLoss()  # Initialize loss function\n        self.data_augmentation = PoisoningDataAugmentation()  # Initialize data augmentation\n\n        # Modify optimizer\n        self.optimizer = torch.optim.Adam(\n            self.model.parameters(),\n            lr=1e-4,\n            eps=1e-8  # Increased epsilon for optimizer stability\n        )\n\n        # Print initialization info\n        print(\"\\nEnhanced Detection System Initialized:\")\n        print(f\"- Input dimension: {input_dim}\")\n        print(f\"- Number of attack types: {len(label_handler.attack_types) if label_handler else 'N/A'}\")\n        print(f\"- Binary classification: Normal vs Attack\")\n        print(f\"- Using label handler: {label_handler is not None}\")\n        print(f\"- Device: {self.device}\")\n\n        if self.device.type == \"cuda\":\n            print(f\"- GPU Memory Usage: {torch.cuda.memory_allocated()/1e9:.2f}GB\")\n\n\n\n    # Add this method to EnhancedPoisoningDetectionSystem\n    def preprocess_batch(self, states, binary_labels, multi_labels):\n        \"\"\"Preprocess batch data with stability checks\"\"\"\n        # Stabilize states\n        states = self.data_stabilizer.stabilize_array(states)\n\n        # Convert to tensors with proper dtype\n        states_tensor = torch.FloatTensor(states).to(self.device)\n        binary_labels_tensor = torch.LongTensor(binary_labels).to(self.device)\n\n        # Gradient scaling for large values\n        if states_tensor.abs().max() > 1e3:\n            states_tensor = F.normalize(states_tensor, dim=1)\n\n        return states_tensor, binary_labels_tensor\n\n        # Loss function\n        self.criterion = PoisoningLoss()\n\n        # Data augmentation\n        self.data_augmentation = PoisoningDataAugmentation()\n\n        # Print initialization info\n        print(\"\\nEnhanced Detection System Initialized:\")\n        print(f\"- Input dimension: {input_dim}\")\n        print(f\"- Number of attack types: {len(label_handler.attack_types) if label_handler else 'N/A'}\")\n        print(f\"- Binary classification: Normal vs Attack\")\n        print(f\"- Using label handler: {label_handler is not None}\")\n        print(f\"- Device: {self.device}\")\n\n        if self.device.type == \"cuda\":\n            print(f\"- GPU Memory Usage: {torch.cuda.memory_allocated()/1e9:.2f}GB\")\n\n\n    def _check_label_handler(self):\n        \"\"\"Verify label handler is available when needed\"\"\"\n        if self.label_handler is None:\n            raise ValueError(\"Label handler is required for multi-class attack analysis\")\n        return True\n\n    def get_attack_info(self, attack_id: int) -> Dict:\n        \"\"\"Get information about a specific attack type\"\"\"\n        self._check_label_handler()\n        return self.label_handler.get_attack_info(attack_id)\n\n\n    def detect(self, state: np.ndarray, evaluate: bool = False,\n              labels: np.ndarray = None) -> Dict[str, np.ndarray]:\n        \"\"\"Enhanced detection with multiple analysis streams\"\"\"\n        with torch.no_grad() if evaluate else torch.enable_grad():\n\n            with torch.amp.autocast('cuda') if self.scaler else contextlib.nullcontext():\n                # Process state\n                processed_state = self.preprocess_state(state)\n                if not evaluate and random.random() < 0.3:\n                    processed_state = self.data_augmentation.augment(processed_state)\n\n                # Model forward pass\n                model_output = self.model(processed_state)\n                combined_output = model_output['final_output']\n                detection_prob = F.softmax(combined_output, dim=-1)\n\n                # Get numpy state for gradual analysis\n                numpy_state = state.cpu().numpy() if torch.is_tensor(state) else state\n\n                try:\n                    # Analyze gradual changes with error handling\n                    gradual_analysis = self.gradual_detector.analyze_gradual_changes(numpy_state)\n                except Exception as e:\n                    print(f\"Warning: Error in gradual analysis: {str(e)}\")\n                    gradual_analysis = {\n                        'gradual_poison_probability': 0.0,\n                        'change_consistency': 0.0,\n                        'change_trend': 0.0\n                    }\n\n                # Update threshold\n                current_threshold = self.threshold_manager.update_threshold(\n                    detection_prob.detach().mean().item(),\n                    detection_prob.detach().argmax().item() == 1\n                )\n\n                # Combine detections\n                enhanced_prob = (\n                    detection_prob.detach().cpu().numpy() * self.config.dqn_weight +\n                    gradual_analysis['gradual_poison_probability'] * self.config.ac_weight\n                )\n\n                # Update pattern memory\n                self.pattern_memory.append({\n                    'features': state.detach().cpu().numpy() if torch.is_tensor(state) else state,\n                    'basic_detection': detection_prob.detach().cpu().numpy(),\n                    'gradual_score': gradual_analysis['gradual_poison_probability']\n                })\n\n                sequence_analysis = self._analyze_sequential_patterns()\n\n                return {\n                    'is_poisoning': enhanced_prob,\n                    'q_values': model_output['q_values'].detach().cpu().numpy(),\n                    'action_probs': model_output['action_probs'].detach().cpu().numpy(),\n                    'confidence': model_output['state_value'].detach().cpu().numpy(),\n                    'gradual_metrics': gradual_analysis,\n                    'sequence_metrics': sequence_analysis,\n                    'threshold': current_threshold,\n                    'detection_metrics': self.metrics_tracker.compute_metrics()\n                }\n\n    def _analyze_sequential_patterns(self) -> Dict[str, float]:\n        \"\"\"Analyze temporal patterns in detection history\"\"\"\n        try:\n            if len(self.pattern_memory) < 2:\n                return {\n                    'sequence_score': 0.0,\n                    'pattern_consistency': 0.0,\n                    'temporal_correlation': 0.0\n                }\n\n            # Get recent patterns and ensure they're the same shape\n            recent_patterns = list(self.pattern_memory)[-10:]\n            features_list = []\n\n            # Handle variable-sized features\n            base_shape = None\n            for pattern in recent_patterns:\n                features = pattern['features']\n                if isinstance(features, torch.Tensor):\n                    features = features.cpu().numpy()\n\n                # If this is first valid shape, use it as base\n                if base_shape is None and features is not None:\n                    base_shape = features.shape\n\n                # Only include features matching base shape\n                if base_shape is not None and features is not None and features.shape == base_shape:\n                    features_list.append(features)\n\n            # If we don't have enough valid patterns, return default values\n            if len(features_list) < 2:\n                return {\n                    'sequence_score': 0.0,\n                    'pattern_consistency': 0.0,\n                    'temporal_correlation': 0.0\n                }\n\n            # Calculate metrics only on valid patterns\n            try:\n                # Convert to numpy array and calculate differences\n                features_array = np.stack(features_list)\n                feature_evolution = np.diff(features_array, axis=0)\n\n                # Calculate pattern metrics\n                pattern_consistency = np.mean(np.abs(feature_evolution), axis=0)\n\n                # Get detection scores\n                detection_scores = [\n                    float(np.mean(p['basic_detection']))\n                    for p in recent_patterns[-len(features_list):]\n                ]\n\n                gradual_scores = [\n                    float(p['gradual_score'])\n                    for p in recent_patterns[-len(features_list):]\n                ]\n\n                # Calculate correlation if we have enough samples\n                if len(detection_scores) > 1:\n                    temporal_correlation = np.corrcoef(\n                        detection_scores,\n                        gradual_scores\n                    )[0, 1]\n                    if np.isnan(temporal_correlation):\n                        temporal_correlation = 0.0\n                else:\n                    temporal_correlation = 0.0\n\n                sequence_score = float(sigmoid(temporal_correlation * np.mean(pattern_consistency)))\n\n                return {\n                    'sequence_score': sequence_score,\n                    'pattern_consistency': float(np.mean(pattern_consistency)),\n                    'temporal_correlation': float(temporal_correlation)\n                }\n\n            except Exception as e:\n                print(f\"Warning: Error in sequence analysis calculations: {str(e)}\")\n                return {\n                    'sequence_score': 0.0,\n                    'pattern_consistency': 0.0,\n                    'temporal_correlation': 0.0\n                }\n\n        except Exception as e:\n            print(f\"Warning: Error in sequence pattern analysis: {str(e)}\")\n            return {\n                'sequence_score': 0.0,\n                'pattern_consistency': 0.0,\n                'temporal_correlation': 0.0\n            }\n\n\n    def train(self, batch_size: int) -> Dict[str, float]:\n        \"\"\"Train the model using experiences from the replay buffer\"\"\"\n        try:\n            if len(self.replay_buffer) < batch_size:\n                return {'status': 'insufficient_samples'}\n\n            # Sample and prepare batch\n            indices = np.random.choice(len(self.replay_buffer), batch_size, replace=False)\n            batch = [self.replay_buffer[i] for i in indices]\n\n            # Unpack and move to device\n            states, binary_labels, multi_labels, predictions, next_states, dones = zip(*batch)\n\n            states = torch.FloatTensor(np.array(states)).to(self.device)\n            binary_labels = torch.LongTensor(np.array(binary_labels)).to(self.device)\n            next_states = torch.FloatTensor(np.array(next_states)).to(self.device)\n            dones = torch.FloatTensor(np.array(dones)).to(self.device)\n\n\n            # Validate tensor shapes\n            if states.dim() != 2 or next_states.dim() != 2:\n                raise ValueError(f\"Invalid state tensor dimensions: states={states.shape}, next_states={next_states.shape}\")\n            if binary_labels.dim() != 1:\n                raise ValueError(f\"Invalid labels tensor dimension: {binary_labels.shape}\")\n\n        except Exception as e:\n            print(f\"Error converting to tensors: {str(e)}\")\n            print(f\"States shape: {np.array(states).shape if isinstance(states, (list, np.ndarray)) else 'invalid'}\")\n            print(f\"Labels shape: {np.array(binary_labels).shape if isinstance(binary_labels, (list, np.ndarray)) else 'invalid'}\")\n            return {'error': 'tensor_conversion', 'details': str(e)}\n\n        # Zero gradients\n        self.optimizer.zero_grad()\n\n        # Compute outputs and loss\n        try:\n          with torch.amp.autocast('cuda') if self.scaler else contextlib.nullcontext():\n            # Forward pass\n              outputs = self.model(states)\n              next_outputs = self.model(next_states)\n\n                    # Prepare targets for DQN\n              next_q_values = next_outputs['q_values'].detach()\n              q_targets = outputs['q_values'].clone().detach()\n              for i in range(batch_size):\n                  if not dones[i]:\n                     q_targets[i, binary_labels[i]] = self.config.gamma * next_q_values[i].max()\n\n                    # Prepare targets for actor-critic\n              returns = torch.zeros_like(outputs['state_value'])\n              for i in range(batch_size):\n                  returns[i] = outputs['state_value'][i] + \\\n                              (1 - dones[i]) * self.config.gamma * next_outputs['state_value'][i].detach()\n\n                    # Compute loss\n              targets = {\n                  'q_targets': q_targets,\n                  'actions': binary_labels,\n                  'returns': returns,\n                  'labels': binary_labels\n              }\n\n              loss_dict = self.criterion(outputs, targets)\n              total_loss = loss_dict['total_loss']\n\n                    # Check for invalid loss values\n              if torch.isnan(total_loss) or torch.isinf(total_loss):\n                raise ValueError(f\"Invalid loss value: {total_loss.item()}\")\n\n        except Exception as e:\n            print(f\"Error in forward pass or loss computation: {str(e)}\")\n            print(f\"Model outputs shape: {outputs['q_values'].shape if 'q_values' in outputs else 'invalid'}\")\n            return {'error': 'forward_pass', 'details': str(e)}\n\n              # Backward pass with AMP if available\n        try:\n            if self.scaler:\n              self.scaler.scale(total_loss).backward()\n              self.scaler.step(self.optimizer)\n              self.scaler.update()\n            else:\n                total_loss.backward()\n                      # Clip gradients\n                torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config.gradient_clip)\n                self.optimizer.step()\n        except Exception as e:\n                  print(f\"Error in backward pass or optimization: {str(e)}\")\n                  return {'error': 'backward_pass', 'details': str(e)}\n\n              # Return metrics\n        try:\n            metrics = {\n                 'status': 'success',\n                 'total_loss': total_loss.item(),\n                 'dqn_loss': loss_dict['dqn_loss'],\n                 'policy_loss': loss_dict['policy_loss'],\n                 'value_loss': loss_dict['value_loss'],\n                 'detection_loss': loss_dict['detection_loss']\n            }\n            return metrics\n\n        except Exception as e:\n            print(f\"Error computing metrics: {str(e)}\")\n            return {'error': 'metrics_computation', 'details': str(e)}\n\n        except Exception as e:\n            print(f\"Unexpected error during training step: {str(e)}\")\n            traceback.print_exc()  # Print full traceback for debugging\n            return {\n                  'error': 'unexpected',\n                  'details': str(e),\n                  'traceback': traceback.format_exc()\n              }\n\n\n    def _compute_td_error(self, state_values, next_state_values, rewards, dones):\n        \"\"\"Compute TD error for value function updates\"\"\"\n        target_values = rewards + (1 - dones) * self.config.gamma * next_state_values\n        td_error = target_values - state_values\n        return td_error\n\n","metadata":{"id":"QLjWna19uaz0","executionInfo":{"status":"ok","timestamp":1732040987167,"user_tz":-180,"elapsed":10,"user":{"displayName":"Roger Nick Anaedevha","userId":"11403452854921994388"}},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Multi - Dataset Generator","metadata":{"id":"GXSc9hVk1UzJ"}},{"cell_type":"code","source":"class MultiDatasetGenerator(Sequence):\n    \"\"\"Generate batches from multiple datasets with iteration control\"\"\"\n    def __init__(self, datasets: Dict[str, Tuple[np.ndarray, np.ndarray, np.ndarray]],\n                 batch_size=256, shuffle=True, num_workers=0):\n        # Initialize dataset parameters\n        self.datasets = datasets\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.num_workers = num_workers\n\n        # Initialize indices for each dataset\n        self.indices = {k: np.arange(len(v[0])) for k, v in datasets.items()}\n\n        # Calculate weights for dataset sampling\n        total_samples = sum(len(v[0]) for v in datasets.values())\n        self.dataset_weights = {k: len(v[0])/total_samples for k, v in datasets.items()}\n\n        # Initialize iteration control\n        self.current_epoch_iterations = 0\n        self.max_epoch_iterations = 1000  # Maximum iterations per epoch\n\n        print(f\"Initialized MultiDatasetGenerator with {len(datasets)} datasets\")\n        for k, v in datasets.items():\n            print(f\"- {k}: {len(v[0])} samples\")\n\n    def __iter__(self):\n        \"\"\"Reset iteration state and shuffle if needed\"\"\"\n        self.current_epoch_iterations = 0\n        if self.shuffle:\n            for k in self.indices:\n                np.random.shuffle(self.indices[k])\n        return self\n\n    def __next__(self):\n        \"\"\"Get next batch with iteration limit check\"\"\"\n        if self.current_epoch_iterations >= self.max_epoch_iterations:\n            raise StopIteration\n\n        self.current_epoch_iterations += 1\n\n        # Select dataset and get batch\n        chosen_dataset = np.random.choice(\n            list(self.datasets.keys()),\n            p=list(self.dataset_weights.values())\n        )\n\n        X, binary_labels, multi_labels = self.datasets[chosen_dataset]\n        indices = self.indices[chosen_dataset]\n\n        # Calculate batch indices\n        start_idx = (self.current_epoch_iterations * self.batch_size) % len(indices)\n        batch_indices = indices[start_idx:start_idx + self.batch_size]\n\n        # Return batch data\n        return (\n            X[batch_indices],\n            binary_labels[batch_indices],\n            multi_labels[batch_indices]\n        )\n\n    def __getitem__(self, index):\n        \"\"\"Get specific batch by index\"\"\"\n        # Ensure index is within bounds\n        if index >= self.max_epoch_iterations:\n            raise IndexError(\"Batch index out of range\")\n\n        chosen_dataset = np.random.choice(\n            list(self.datasets.keys()),\n            p=list(self.dataset_weights.values())\n        )\n\n        X, binary_labels, multi_labels = self.datasets[chosen_dataset]\n        indices = self.indices[chosen_dataset]\n\n        start_idx = (index * self.batch_size) % len(indices)\n        batch_indices = indices[start_idx:start_idx + self.batch_size]\n\n        return (\n            X[batch_indices],\n            binary_labels[batch_indices],\n            multi_labels[batch_indices]\n        )\n\n    def __len__(self):\n        \"\"\"Returns precise number of batches per epoch\"\"\"\n        return min(\n            self.max_epoch_iterations,\n            int(np.ceil(sum(len(v[0]) for v in self.datasets.values()) / self.batch_size))\n        )\n\n    def reset(self):\n        \"\"\"Reset iteration state\"\"\"\n        self.current_epoch_iterations = 0\n        if self.shuffle:\n            for k in self.indices:\n                np.random.shuffle(self.indices[k])\n\n    def get_progress(self):\n        \"\"\"Get training progress information\"\"\"\n        return {\n            'current_iteration': self.current_epoch_iterations,\n            'max_iterations': self.max_epoch_iterations,\n            'progress': self.current_epoch_iterations / self.max_epoch_iterations\n        }\n","metadata":{"id":"-lbzUvsC1X7D","executionInfo":{"status":"ok","timestamp":1732040987168,"user_tz":-180,"elapsed":10,"user":{"displayName":"Roger Nick Anaedevha","userId":"11403452854921994388"}},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training Pipeline","metadata":{"id":"AUq4M5tFuhrE"}},{"cell_type":"code","source":"## EARLY STOPPING\n\nclass EarlyStopping:\n    def __init__(self, patience=5, min_delta=0.001, restore_best_weights=True):\n        self.patience = patience\n        self.min_delta = min_delta\n        self.restore_best_weights = restore_best_weights\n        self.best_weights = None\n        self.best_score = None\n        self.counter = 0\n        self.early_stop = False\n        self.min_improvement = 1e-4  # Add this\n        self.max_epochs_without_improvement = 10  # Add this\n        self.epochs_without_improvement = 0  # Add this\n\n    def __call__(self, val_score: float, model=None) -> bool:\n        if self.best_score is None:\n            self.best_score = val_score\n            if self.restore_best_weights and model is not None:\n                self.best_weights = self._get_model_weights(model)\n        elif val_score > self.best_score + self.min_delta:\n            self.best_score = val_score\n            self.epochs_without_improvement = 0\n            if self.restore_best_weights and model is not None:\n                self.best_weights = self._get_model_weights(model)\n        else:\n            self.epochs_without_improvement += 1\n\n        if self.epochs_without_improvement >= self.max_epochs_without_improvement:\n            self.early_stop = True\n            return True\n\n        if abs(val_score - self.best_score) < self.min_improvement:\n            self.counter += 1\n        else:\n            self.counter = 0\n\n        if self.counter >= self.patience:\n            self.early_stop = True\n\n        return self.early_stop\n\n\n    def _get_model_weights(self, model) -> dict:\n        \"\"\"Get a deep copy of model weights\"\"\"\n        return {\n            name: param.cpu().clone().detach()\n            for name, param in model.state_dict().items()\n        }\n\n    def restore_weights(self, model) -> None:\n        \"\"\"Restore model to best weights\"\"\"\n        if self.restore_best_weights and self.best_weights is not None:\n            model.load_state_dict(self.best_weights)\n\n    def reset(self) -> None:\n        \"\"\"Reset early stopping state\"\"\"\n        self.best_score = None\n        self.counter = 0\n        self.early_stop = False\n        self.best_weights = None\n\n    def get_best_score(self) -> float:\n        \"\"\"Return the best score achieved\"\"\"\n        return self.best_score if self.best_score is not None else float('-inf')\n\n    def is_best_epoch(self, val_score: float) -> bool:\n        \"\"\"Check if current epoch achieved best score\"\"\"\n        return self.best_score is None or val_score > self.best_score + self.min_delta\n\n","metadata":{"id":"yfawHal4vC10","executionInfo":{"status":"ok","timestamp":1732040987168,"user_tz":-180,"elapsed":9,"user":{"displayName":"Roger Nick Anaedevha","userId":"11403452854921994388"}},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Single DataSet Trainer","metadata":{}},{"cell_type":"code","source":"## SINGLE DATASET TRAINER\nclass SingleDatasetTrainer:\n    \"\"\"Handles training process for a single dataset\"\"\"\n    def __init__(self, config: ModelConfig, dataset_type: str):\n        self.config = config\n        self.dataset_type = dataset_type.lower()\n        self.device = config.device\n\n        # Initialize components\n        print(f\"\\nInitializing loader for {self.dataset_type.upper()}\")\n        self.loader = EnhancedDatasetLoader(dataset_type=self.dataset_type, config=self.config)\n        self.memory_monitor = MemoryMonitor()\n        self.metrics_tracker = PoisoningDetectionMetrics()\n\n        # Training setup\n        self.writer = SummaryWriter(f'logs/{self.dataset_type}')\n        self.checkpoint_dir = os.path.join(config.checkpoint_dir, self.dataset_type)\n        os.makedirs(self.checkpoint_dir, exist_ok=True)\n\n    def train_on_dataset(self, file_path: str):\n        \"\"\"Complete training process for a single dataset\"\"\"\n        try:\n            print(f\"\\nStarting training process for {self.dataset_type.upper()}\")\n\n            # Verify file exists\n            if not os.path.exists(file_path):\n                raise FileNotFoundError(f\"Dataset file not found: {file_path}\")\n\n            # Load and process dataset\n            X, binary_labels, multi_labels, additional_info = self.loader.load_and_process_dataset(file_path)\n\n            print(\"\\nSplitting data into train and validation sets...\")\n            # Split data with error handling\n            try:\n                # Ensure array types\n                X = np.array(X, dtype=np.float32)\n                binary_labels = np.array(binary_labels, dtype=np.int32)\n\n                X_train, X_val, y_train, y_val = train_test_split(\n                    X, binary_labels,\n                    test_size=0.2,\n                    random_state=42,\n                    stratify=binary_labels  # Ensure balanced split\n                )\n                print(f\"Train set size: {len(X_train)}, Validation set size: {len(X_val)}\")\n\n            except Exception as e:\n                print(f\"Error in data splitting: {str(e)}\")\n                raise\n\n            # Initialize detection system\n            detection_system = EnhancedPoisoningDetectionSystem(\n                input_dim=X.shape[1],\n                config=self.config,\n                label_handler=self.loader.label_handler\n            )\n            print(\"\\nInitialized detection system\")\n\n            # Create data generators\n            train_generator = MultiDatasetGenerator(\n                {self.dataset_type: (X_train, y_train, y_train)},\n                batch_size=self.config.batch_size\n            )\n\n            val_generator = MultiDatasetGenerator(\n                {self.dataset_type: (X_val, y_val, y_val)},\n                batch_size=self.config.batch_size\n            )\n            print(\"Created data generators\")\n\n            # Setup training pipeline\n            pipeline = ComprehensiveTrainingPipeline(\n                detection_system=detection_system,\n                data_generator=train_generator,\n                val_generator=val_generator,\n                config=self.config,\n                label_handler=self.loader.label_handler\n            )\n\n            # Train model\n            print(f\"\\nStarting training on {self.dataset_type.upper()}...\")\n            pipeline.train()\n\n            # Save results\n            self._save_results(detection_system, additional_info)\n\n            return detection_system, self.metrics_tracker\n\n        except Exception as e:\n            print(f\"Error in training process: {str(e)}\")\n            traceback.print_exc()\n            raise\n\n\n    def _save_results(self, detection_system: EnhancedPoisoningDetectionSystem, additional_info: Dict):\n        \"\"\"Save training results and model\"\"\"\n        try:\n            results_path = os.path.join(self.checkpoint_dir, f'{self.dataset_type}_results.pt')\n\n            torch.save({\n                'model_state': detection_system.model.state_dict(),\n                'config': self.config,\n                'metrics': self.metrics_tracker.get_summary(),\n                'poisoning_features': additional_info['poisoning_features'],\n                'validation_stats': additional_info['validation_stats']\n            }, results_path)\n\n            print(f\"\\nResults saved to {results_path}\")\n\n        except Exception as e:\n            print(f\"Error saving results: {str(e)}\")\n            raise\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Compregensive Training Pipeline","metadata":{}},{"cell_type":"code","source":"## COMPREHENSIVE TRAINING PIPELINE\n\nclass ComprehensiveTrainingPipeline:\n    \"\"\"Advanced training pipeline with monitoring and evaluation\"\"\"\n    def __init__(self, detection_system: EnhancedPoisoningDetectionSystem,\n                 data_generator: MultiDatasetGenerator,\n                 val_generator: MultiDatasetGenerator,\n                 config: ModelConfig,\n                 label_handler: LabelHandler):\n        # Core components (keep existing)\n        self.detection_system = detection_system\n        self.data_generator = data_generator\n        self.val_generator = val_generator\n        self.config = config\n        self.label_handler = label_handler\n\n        # Training parameters (keep existing)\n        self.batch_size = config.batch_size\n        self.num_epochs = config.num_epochs\n        self.checkpoint_dir = config.checkpoint_dir\n        self.log_dir = config.log_dir\n\n        # Initialize trackers (keep existing)\n        self._global_step = 0\n        self._epoch = 0\n        self.best_metrics = {\n            'accuracy': 0,\n            'f1_score': 0,\n            'unknown_detection_rate': 0,\n            'per_attack_f1': defaultdict(float)\n        }\n\n        # Setup components (new method)\n        self._setup_components()\n\n    def preprocess_batch(self, states, binary_labels, multi_labels):\n        \"\"\"Preprocess batch data with stability checks\"\"\"\n        try:\n            # Get data stabilizer from detection system\n            data_stabilizer = self.detection_system.data_stabilizer\n\n            # Stabilize states\n            states = data_stabilizer.stabilize_array(states)\n\n            # Convert to tensors with proper dtype\n            states_tensor = torch.FloatTensor(states).to(self.detection_system.device)\n            binary_labels_tensor = torch.LongTensor(binary_labels).to(self.detection_system.device)\n\n            # Gradient scaling for large values\n            if states_tensor.abs().max() > 1e3:\n                states_tensor = F.normalize(states_tensor, dim=1)\n\n            return states_tensor, binary_labels_tensor\n\n        except Exception as e:\n            print(f\"Error in batch preprocessing: {str(e)}\")\n            print(f\"States shape: {states.shape if isinstance(states, np.ndarray) else 'invalid'}\")\n            print(f\"Labels shape: {binary_labels.shape if isinstance(binary_labels, np.ndarray) else 'invalid'}\")\n            raise\n\n\n\n    def _setup_components(self):\n        \"\"\"Initialize training components while preserving existing functionality\"\"\"\n        try:\n            # Create directories\n            os.makedirs(self.checkpoint_dir, exist_ok=True)\n            os.makedirs(self.log_dir, exist_ok=True)\n\n            # Initialize monitoring (preserve existing)\n            self.writer = SummaryWriter(self.log_dir)\n            self.memory_monitor = MemoryMonitor()\n            self.early_stopping = EarlyStopping(\n                patience=self.config.patience,\n                min_delta=self.config.min_delta\n            )\n\n            # Initialize attack-specific monitoring\n            self.attack_metrics = {\n                attack_id: defaultdict(list)\n                for attack_id in self.label_handler.attack_types\n            }\n\n            # Performance tracking (integrates with existing metrics)\n            self.train_losses = []\n            self.val_losses = []\n            self.performance_history = defaultdict(list)\n\n            # Loss function (preserve existing criterion)\n            self.criterion = PoisoningLoss()\n\n            print(f\"\\nPipeline initialized:\")\n            print(f\"- Batch size: {self.batch_size}\")\n            print(f\"- Epochs: {self.num_epochs}\")\n            print(f\"- Checkpoints: {self.checkpoint_dir}\")\n            print(f\"- Logs: {self.log_dir}\")\n            print(f\"- Monitoring {len(self.label_handler.attack_types)} attack types\")\n\n        except Exception as e:\n            print(f\"Error setting up training components: {str(e)}\")\n            raise\n            \n    \n    def train(self):\n        \"\"\"Execute training loop with TPU support\"\"\"\n        try:\n            device = self.detection_system.device\n            print(f\"Training on device: {device}\")\n\n            # TPU specific setup\n            if 'xla' in str(device):\n                # Wrap data loader for TPU\n                train_loader = pl.ParallelLoader(\n                    self.data_generator, [device]\n                ).per_device_loader(device)\n\n                if self.val_generator:\n                    val_loader = pl.ParallelLoader(\n                        self.val_generator, [device]\n                    ).per_device_loader(device)\n            else:\n                train_loader = self.data_generator\n                val_loader = self.val_generator\n\n        \"\"\"Execute training loop with comprehensive monitoring and proper stopping conditions\"\"\"\n\n            # Add convergence tracking\n            plateau_counter = 0\n            last_loss = float('inf')\n            min_loss_change = 1e-5\n            plateau_patience = 5\n            max_iterations = 1000  # Maximum iterations per epoch\n\n            for epoch in range(self.num_epochs):\n                print(f\"\\nEpoch {epoch + 1}/{self.num_epochs}\")\n                print(\"=\" * 50)\n\n                self._epoch = epoch\n                self.detection_system.model.train()\n                epoch_metrics = defaultdict(list)\n                epoch_start_time = time.time()\n\n                n_batches = len(self.data_generator)\n                iteration_counter = 0\n\n                with tqdm(total=n_batches, desc=f\"Training\") as pbar:\n                    for batch_idx, (states, binary_labels, multi_labels) in enumerate(self.data_generator):\n                        # Check iteration limit\n                        if iteration_counter >= max_iterations:\n                            print(f\"\\nReached maximum iterations ({max_iterations}) for epoch {epoch + 1}\")\n                            break\n\n                        # Train batch\n                        batch_metrics = self._train_batch(states, binary_labels, multi_labels)\n\n                        if batch_metrics:\n                            # Check for convergence\n                            current_loss = batch_metrics.get('total_loss', float('inf'))\n                            if abs(current_loss - last_loss) < min_loss_change:\n                                plateau_counter += 1\n                            else:\n                                plateau_counter = 0\n                            last_loss = current_loss\n\n                            # Check plateau condition\n                            if plateau_counter >= plateau_patience:\n                                print(f\"\\nTraining converged (loss plateau reached)\")\n                                return\n\n                            # Filter and update metrics\n                            numeric_metrics = {\n                                k: v for k, v in batch_metrics.items()\n                                if isinstance(v, (int, float, np.number))\n                            }\n\n                            for k, v in numeric_metrics.items():\n                                epoch_metrics[k].append(float(v))\n\n                            # Update progress bar\n                            avg_metrics = {\n                                k: np.mean(v) for k, v in epoch_metrics.items()\n                            }\n                            pbar.set_postfix(avg_metrics)\n                            pbar.update(1)\n\n                        iteration_counter += 1\n\n                        # Memory check\n                        if self.memory_monitor.check_memory():\n                            print(\"\\nHigh memory usage detected, breaking epoch\")\n                            break\n\n                # Epoch completion checks\n                avg_loss = np.mean([m.get('total_loss', float('inf')) for m in epoch_metrics.values()])\n                if avg_loss < 1e-4:  # Convergence threshold\n                    print(f\"\\nTraining converged (loss threshold reached)\")\n                    return\n\n                # Run validation and early stopping\n                if self.val_generator and (epoch + 1) % 5 == 0:\n                    val_metrics = self._evaluate(epoch)\n                    if self.early_stopping(val_metrics.get('accuracy', 0), self.detection_system.model):\n                        print(\"\\nEarly stopping triggered\")\n                        return\n\n        except KeyboardInterrupt:\n            print(\"\\nTraining interrupted - saving checkpoint...\")\n            self._save_checkpoint('interrupt')\n        except Exception as e:\n            print(f\"\\nError during training: {str(e)}\")\n            traceback.print_exc()\n            self._save_checkpoint('error')\n            raise\n        if 'xla' in str(device):\n            xm.mark_step()\n\n\n    def _train_batch(self, states, binary_labels, multi_labels):\n        \"\"\"Train a single batch with improved error handling and stability\"\"\"\n        try:\n            # Use preprocessed batch data\n            states_tensor, binary_labels_tensor = self.preprocess_batch(\n                states, binary_labels, multi_labels\n            )\n\n            # Forward pass with stability\n            detection_output = self.detection_system.detect(\n                states_tensor, labels=binary_labels_tensor\n            )\n\n            # Store experience with safe type conversion\n            for i in range(len(states)):\n                try:\n                    self.detection_system.replay_buffer.append((\n                        states[i].astype(np.float32),  # Ensure float32\n                        int(binary_labels[i]),         # Ensure int\n                        int(multi_labels[i]),          # Ensure int\n                        detection_output['is_poisoning'][i],\n                        states[i].astype(np.float32),  # Ensure float32\n                        True\n                    ))\n                except Exception as e:\n                    print(f\"Warning: Error storing experience {i}: {str(e)}\")\n                    continue\n\n            # Train if enough samples\n            if len(self.detection_system.replay_buffer) >= self.batch_size:\n                batch_metrics = self.detection_system.train(self.batch_size)\n\n                # Ensure all metrics are numeric\n                numeric_metrics = {}\n                for k, v in batch_metrics.items():\n                    if isinstance(v, (int, float, np.number)):\n                        numeric_metrics[k] = float(v)\n                    else:\n                        print(f\"Warning: Non-numeric metric encountered: {k} = {v}\")\n\n                return numeric_metrics\n            return None\n\n        except Exception as e:\n            print(f\"Error in batch training:\")\n            print(f\"States shape: {states.shape}\")\n            print(f\"Binary Labels shape: {binary_labels.shape}\")\n            print(f\"Multi Labels shape: {multi_labels.shape}\")\n            raise e\n\n\n    def _update_best_metrics(self, val_metrics: Dict[str, float], epoch: int):\n        \"\"\"Update best metrics if current results are better\"\"\"\n        try:\n            for metric_name, value in val_metrics.items():\n                if isinstance(value, (int, float)):\n                    if metric_name not in self.best_metrics or value > self.best_metrics[metric_name]:\n                        self.best_metrics[metric_name] = value\n                        print(f\"New best {metric_name}: {value:.4f}\")\n        except Exception as e:\n            print(f\"Warning: Error updating best metrics: {str(e)}\")\n\n    def _log_metrics(self, metrics: Dict[str, float]):\n        \"\"\"Log metrics to tensorboard and update history\n\n        Args:\n            metrics: Dictionary containing metric names and values\n        \"\"\"\n        try:\n            # Log to tensorboard\n            for name, value in metrics.items():\n                self.writer.add_scalar(\n                    f'metrics/{name}',\n                    value,\n                    self._global_step\n                )\n\n                # Update history\n                self.performance_history[name].append(value)\n\n            # Update global step\n            self._global_step += 1\n\n        except Exception as e:\n            print(f\"Warning: Error logging metrics: {str(e)}\")\n\n    def _log_attack_metrics(self, attack_id: int, predictions: np.ndarray, labels: np.ndarray):\n        \"\"\"Log metrics for specific attack type\"\"\"\n        try:\n            attack_info = self.label_handler.get_attack_info(attack_id)\n            # Convert predictions to class indices if needed\n            if len(predictions.shape) > 1:\n                pred_indices = predictions.argmax(axis=1)\n            else:\n                pred_indices = predictions\n\n            metrics = {\n                'precision': precision_score(labels, pred_indices, average='binary'),\n                'recall': recall_score(labels, pred_indices, average='binary'),\n                'f1': f1_score(labels, pred_indices, average='binary'),\n                'accuracy': accuracy_score(labels, pred_indices)\n            }\n\n            # Log to tensorboard\n            for name, value in metrics.items():\n                self.writer.add_scalar(\n                    f'attack_metrics/{attack_info[\"attack_name\"]}/{name}',\n                    value,\n                    self._global_step\n                )\n\n                # Store in attack metrics\n                self.attack_metrics[attack_id][name].append(value)\n\n        except Exception as e:\n            print(f\"Warning: Error logging attack metrics: {str(e)}\")\n\n    def _log_batch_metrics(self, batch_metrics: Dict[str, float]):\n        \"\"\"Log batch-level training metrics\"\"\"\n        try:\n            # Add batch metrics to history\n            for name, value in batch_metrics.items():\n                if name == 'total_loss':\n                    self.train_losses.append(value)\n                self.writer.add_scalar(f'batch/{name}', value, self._global_step)\n\n        except Exception as e:\n            print(f\"Warning: Error logging batch metrics: {str(e)}\")\n\n    def _log_epoch_metrics(self, epoch: int, metrics: Dict[str, float]):\n        \"\"\"Log epoch-level metrics\"\"\"\n        try:\n            # Compute epoch averages\n            epoch_metrics = {}\n            for name, values in metrics.items():\n                if values:  # Check if list is not empty\n                    epoch_metrics[f'epoch_{name}'] = np.mean(values)\n\n            # Log to tensorboard\n            for name, value in epoch_metrics.items():\n                self.writer.add_scalar(f'epoch/{name}', value, epoch)\n\n            return epoch_metrics\n\n        except Exception as e:\n            print(f\"Warning: Error logging epoch metrics: {str(e)}\")\n            return {}\n\n    def _evaluate(self, epoch: int) -> Dict[str, float]:\n        \"\"\"Evaluate model performance with per-attack metrics\"\"\"\n        self.detection_system.model.eval()\n        all_metrics = {}\n        per_attack_metrics = defaultdict(list)\n\n        try:\n            # Get validation data\n            eval_data, eval_binary_labels, eval_multi_labels = next(iter(self.val_generator))\n\n            # Calculate overall metrics\n            metrics = evaluate_model(\n                self.detection_system,\n                eval_data,\n                eval_binary_labels\n            )\n\n            # Calculate per-attack metrics\n            for attack_id in self.label_handler.attack_types:\n                attack_mask = eval_multi_labels == attack_id\n                if np.any(attack_mask):\n                    attack_metrics = evaluate_model(\n                        self.detection_system,\n                        eval_data[attack_mask],\n                        eval_binary_labels[attack_mask]\n                    )\n                    attack_name = self.label_handler.get_attack_info(attack_id)['attack_name']\n                    per_attack_metrics[attack_name] = attack_metrics\n\n            # Test unknown attack detection\n            unknown_metrics = test_unknown_attack_detection(\n                self.detection_system,\n                eval_data\n            )\n\n            # Combine all metrics\n            all_metrics.update(metrics)\n            all_metrics.update(unknown_metrics)\n            all_metrics['per_attack'] = per_attack_metrics\n\n            # Log per-attack metrics to tensorboard\n            self._log_per_attack_metrics(per_attack_metrics, epoch)\n\n        except Exception as e:\n            print(f\"Error during evaluation: {e}\")\n\n        return all_metrics\n\n    def _log_per_attack_metrics(self, per_attack_metrics: Dict, epoch: int):\n        \"\"\"Log per-attack metrics to tensorboard\"\"\"\n        for attack_name, metrics in per_attack_metrics.items():\n            for metric_name, value in metrics.items():\n                self.writer.add_scalar(\n                    f'per_attack/{attack_name}/{metric_name}',\n                    value,\n                    epoch\n                )\n\n    def _save_checkpoint(self, identifier: str):\n        \"\"\"Save model checkpoint with additional metrics\"\"\"\n        path = os.path.join(\n            self.checkpoint_dir,\n            f'checkpoint_{identifier}.pt'\n        )\n\n        checkpoint = {\n            'epoch': self._epoch,\n            'model_state_dict': self.detection_system.model.state_dict(),\n            'optimizer_state_dict': self.detection_system.optimizer.state_dict(),\n            'metrics': self.best_metrics,\n            'global_step': self._global_step,\n            'label_mapping': self.label_handler.label_mapping,  # Save label information\n            'attack_types': self.label_handler.attack_types\n        }\n\n        torch.save(checkpoint, path)\n        print(f\"\\nCheckpoint saved: {path}\")\n\n    def _handle_oom_error(self):\n        \"\"\"Handle out of memory error\"\"\"\n        if torch.cuda.is_available():\n            torch.cuda.empty_cache()\n        self.batch_size = max(32, self.batch_size // 2)\n        print(f\"\\nReducing batch size to: {self.batch_size}\")\n\n    def _check_memory(self):\n        \"\"\"Check memory usage\"\"\"\n        if torch.cuda.is_available():\n            memory_used = torch.cuda.memory_allocated()/1e9\n            if memory_used > 0.9 * torch.cuda.get_device_properties(0).total_memory/1e9:\n                print(f\"\\nHigh GPU memory usage ({memory_used:.2f}GB)\")\n                self._handle_oom_error()\n\n    def _log_training_progress(self, epoch: int, batch_idx: int, metrics: Dict):\n        \"\"\"Log training progress\"\"\"\n        try:\n            # Log to tensorboard\n            step = epoch * len(self.data_generator) + batch_idx\n            for name, value in metrics.items():\n                if isinstance(value, (int, float, np.number)):\n                    self.writer.add_scalar(f'training/{name}', value, step)\n\n            # Update global step\n            self._global_step = step\n\n        except Exception as e:\n            print(f\"Warning: Error logging progress: {str(e)}\")\n\n    def _handle_epoch_completion(self, epoch: int, epoch_metrics: Dict):\n        \"\"\"Handle end of epoch procedures\"\"\"\n        try:\n            # Calculate average metrics\n            avg_metrics = {}\n            for k, v in epoch_metrics.items():\n                if isinstance(v, (list, np.ndarray)) and len(v) > 0:\n                    if all(isinstance(x, (int, float, np.number)) for x in v):\n                        avg_metrics[k] = float(np.mean(v))\n\n            # Print epoch summary\n            print(f\"\\nEpoch {epoch + 1} Complete:\")\n            print(\"-\" * 50)\n            print(\"Training Metrics:\")\n            for name, value in avg_metrics.items():\n                print(f\"- {name}: {value:.4f}\")\n\n            # Log to tensorboard\n            for name, value in avg_metrics.items():\n                self.writer.add_scalar(f'epoch/{name}', value, epoch)\n\n            # Validation if available\n            if self.val_generator and (epoch + 1) % 5 == 0:\n                print(\"\\nRunning Validation...\")\n                val_metrics = self._evaluate(epoch)\n                self._update_best_metrics(val_metrics, epoch)\n\n            # Memory management\n            if self.memory_monitor.check_memory():\n                self._handle_oom_error()\n\n            print(\"\\nCurrent Best Metrics:\")\n            for metric, value in self.best_metrics.items():\n                if isinstance(value, (int, float)):\n                    print(f\"- Best {metric}: {value:.4f}\")\n\n        except Exception as e:\n            print(f\"Warning: Error in epoch completion handling: {str(e)}\")\n            traceback.print_exc()\n\n\n    def _check_convergence(self, current_loss: float, last_loss: float,\n                          plateau_counter: int, min_loss_change: float) -> Tuple[int, bool]:\n        \"\"\"Check if training has converged\"\"\"\n        if abs(current_loss - last_loss) < min_loss_change:\n            plateau_counter += 1\n        else:\n            plateau_counter = 0\n\n        return plateau_counter, plateau_counter >= self.config.patience\n\n    def _should_stop_training(self, iteration_counter: int, max_iterations: int,\n                            avg_loss: float, plateau_counter: int) -> bool:\n        \"\"\"Check if training should stop\"\"\"\n        if iteration_counter >= max_iterations:\n            print(f\"\\nReached maximum iterations ({max_iterations})\")\n            return True\n\n        if avg_loss < 1e-4:\n            print(f\"\\nReached minimum loss threshold\")\n            return True\n\n        if plateau_counter >= self.config.patience:\n            print(f\"\\nLoss plateau reached\")\n            return True\n\n        return False\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset Processor","metadata":{}},{"cell_type":"code","source":"# Initialize\nconfig = ModelConfig()  # Will automatically detect and setup TPU\n\nclass DatasetProcessor:\n    \"\"\"Handles dataset processing and model training\"\"\"\n    def __init__(self, config: ModelConfig):\n        self.config = config\n        self.all_models = {}\n        self.all_metrics = {}\n\n    def process_single_dataset(self, dataset_type: str, data_path: str):\n        \"\"\"Process a single dataset\"\"\"\n        try:\n            # Load dataset using EnhancedDatasetLoader\n            loader = EnhancedDatasetLoader(dataset_type, self.config)\n            X, binary_labels, multi_labels, additional_info = loader.load_and_process_dataset(data_path)\n            print(f\"\\nDataset loaded - Shape: {X.shape}\")\n\n            # Initialize components\n            metrics_tracker = PoisoningDetectionMetrics(loader.label_handler)\n            print(\"Created metrics tracker\")\n\n            # Create train and validation generators\n            split_idx = int(0.8 * len(X))\n            X_train, X_val = X[:split_idx], X[split_idx:]\n            binary_train, binary_val = binary_labels[:split_idx], binary_labels[split_idx:]\n            multi_train, multi_val = multi_labels[:split_idx], multi_labels[split_idx:]\n\n            train_generator = MultiDatasetGenerator(\n                {dataset_type: (X_train, binary_train, multi_train)},\n                batch_size=self.config.batch_size,\n                shuffle=True,\n                num_workers=self.config.num_workers\n            )\n            print(\"Created data generator\")\n\n            val_generator = MultiDatasetGenerator(\n                {dataset_type: (X_val, binary_val, multi_val)},\n                batch_size=self.config.batch_size,\n                shuffle=False,\n                num_workers=self.config.num_workers\n            )\n            print(\"Created validation generator\")\n\n            # Initialize detection system\n            detection_system = EnhancedPoisoningDetectionSystem(\n                input_dim=X.shape[1],\n                config=self.config,\n                label_handler=loader.label_handler\n            )\n            print(\"Initialized detection system\")\n\n            # Setup training pipeline\n            pipeline = ComprehensiveTrainingPipeline(\n                detection_system=detection_system,\n                data_generator=train_generator,\n                val_generator=val_generator,\n                config=self.config,\n                label_handler=loader.label_handler\n            )\n\n            # Train\n            print(\"\\nStarting training...\")\n            pipeline.train()\n\n            # Save additional info from enhanced processing\n            self._save_additional_info(dataset_type, additional_info)\n\n            return detection_system, metrics_tracker\n\n        except Exception as e:\n            print(f\"Error processing dataset: {str(e)}\")\n            traceback.print_exc()\n            return None, None\n\n    def _save_additional_info(self, dataset_type: str, additional_info: Dict):\n        \"\"\"Save additional processing information\"\"\"\n        save_path = os.path.join(\n            self.config.checkpoint_dir,\n            f'{dataset_type}_additional_info.pt'\n        )\n        torch.save(additional_info, save_path)\n        print(f\"\\nSaved additional processing info to {save_path}\")\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"1FFc5L-_OodHnSswXN2I15mAnpzO7YIiV"},"id":"042xtxM5vfni","outputId":"3c52be10-dbf6-4726-f7dd-23d6a1860261","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Main Execution 1","metadata":{}},{"cell_type":"code","source":"def tpu_training_wrapper(func):\n    \"\"\"Wrapper to handle TPU execution modes\"\"\"\n    def wrapper(*args, **kwargs):\n        if xm.xrt_world_size() > 1:\n            # Multi-core TPU execution\n            xmp.spawn(func, args=args, nprocs=8)\n        else:\n            # Single core execution\n            return func(*args, **kwargs)\n    return wrapper\n\n@tpu_training_wrapper\ndef main_single_dataset():\n    \"\"\"Main function to process datasets one at a time with TPU support\"\"\"\n    try:\n        # Setup with TPU awareness\n        device = setup_tpu()  # Use the setup_tpu function we defined earlier\n        config = ModelConfig()\n\n        if not setup_system():\n            raise RuntimeError(\"System setup failed\")\n\n        # Dataset configurations\n        datasets = {\n            'cic': {'path': '/content/CIC_IoT_M3.csv', 'description': 'CIC-IDS Dataset'},\n            'ton': {'path': '/content/UNSW_TON_IoT.csv', 'description': 'TON-IoT Dataset'},\n            'cse': {'path': '/content/CSE-CIC_2018.csv', 'description': 'CSE-CIC Dataset'}\n        }\n\n        # Process one dataset at a time with TPU handling\n        results = {}\n        for dataset_type, info in datasets.items():\n            print(f\"\\n{'='*50}\")\n            print(f\"Processing {dataset_type.upper()} Dataset\")\n            print(f\"{'='*50}\")\n\n            try:\n                trainer = SingleDatasetTrainer(config, dataset_type)\n                \n                # Wrap model training in TPU execution context if using TPU\n                if 'xla' in str(device):\n                    print(\"Using TPU for training\")\n                    with xm.master_print_every_n_sec():\n                        model, metrics = trainer.train_on_dataset(info['path'])\n                else:\n                    model, metrics = trainer.train_on_dataset(info['path'])\n\n                results[dataset_type] = {\n                    'model': model,\n                    'metrics': metrics\n                }\n\n                print(f\"\\nCompleted processing {dataset_type.upper()}\")\n                print(\"Cleaning up memory...\")\n                gc.collect()\n                \n                # TPU-specific cleanup\n                if 'xla' in str(device):\n                    xm.mark_step()\n                    \n                if torch.cuda.is_available():\n                    torch.cuda.empty_cache()\n\n            except Exception as e:\n                print(f\"Error processing {dataset_type} dataset: {str(e)}\")\n                continue\n\n        return results\n\n    except Exception as e:\n        print(f\"Error in main execution: {str(e)}\")\n        traceback.print_exc()\n        return None\n\nif __name__ == \"__main__\":\n    # TPU setup verification\n    import torch_xla.debug.metrics as met\n    \n    try:\n        main_single_dataset()\n        \n        # Print TPU metrics if available\n        if xm.xrt_world_size() > 0:\n            print(\"\\nTPU Metrics:\")\n            print(met.metrics_report())\n    except Exception as e:\n        print(f\"Error in TPU execution: {str(e)}\")\n        traceback.print_exc()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\n---\n\n","metadata":{"id":"ONoygyUIceec"}}]}