% Consolidated Bibliography from Multiple LaTeX Papers
% Generated from: node_v10ca.tex, NotP4_v3c.tex, eT_Paper_v5cg.tex, node_v2ca.tex
% Total entries: 203

\begin{thebibliography}{99}

\bibitem{verizon2024dbir}
Verizon, ``2024 Data Breach Investigations Report,'' Tech. Rep., May 2024.

\bibitem{ibm2024breach}
IBM Security and Ponemon Institute, ``Cost of a Data Breach Report 2024,'' IBM Corporation, 2024.

\bibitem{gama2014survey}
J.~Gama, I.~Žliobaitė, A.~Bifet, M.~Pechenizkiy, and A.~Bouchachia, ``A survey on concept drift adaptation,'' \emph{ACM Comput. Surv.}, vol.~46, no.~4, pp.~1--37, Mar. 2014.

\bibitem{salvi2024tabn}
C.~Salvi, M.~Lemercier, and A.~Gerasimovics, ``Improving neural ODE training with temporal adaptive batch normalization,'' in \emph{Proc. NeurIPS}, 2024, pp.~14523--14538.

\bibitem{xue2024prompted}
H.~Xue, S.~Zha, and H.~Mei, ``PromptCast: A new prompt-based learning paradigm for time series forecasting,'' \emph{IEEE Trans. Knowl. Data Eng.}, early access, 2024.

\bibitem{wei2022chain}
J.~Wei \emph{et al.}, ``Chain-of-thought prompting elicits reasoning in large language models,'' in \emph{Proc. NeurIPS}, 2022, pp.~24824--24837.

\bibitem{chen2018neural}
R.~T.~Q. Chen, Y.~Rubanova, J.~Bettencourt, and D.~K. Duvenaud, ``Neural ordinary differential equations,'' in \emph{Proc. NeurIPS}, 2018, pp.~6571--6583.

\bibitem{pontryagin1962mathematical}
L.~S. Pontryagin, V.~G. Boltyanskii, R.~V. Gamkrelidze, and E.~F. Mishchenko, \emph{The Mathematical Theory of Optimal Processes}. New York: Interscience Publishers, 1962.

\bibitem{dupont2019augmented}
E.~Dupont, A.~Doucet, and Y.~W. Teh, ``Augmented neural ODEs,'' in \emph{Proc. NeurIPS}, 2019, pp.~3134--3144.

\bibitem{onken2021ot}
D.~Onken, S.~W. Fung, X.~Li, and L.~Ruthotto, ``OT-Flow: Fast and accurate continuous normalizing flows via optimal transport,'' in \emph{Proc. AAAI}, 2021, pp.~9223--9232.

\bibitem{lu2018beyond}
Y.~Lu, A.~Zhong, Q.~Li, and B.~Dong, ``Beyond finite layer neural networks: Bridging deep architectures and numerical differential equations,'' in \emph{Proc. ICML}, 2018, pp.~3276--3285.

\bibitem{purohit2024ortho}
A.~Purohit, A.~P. Mathur, and V.~Phoha, ``Ortho-ODE: Enhancing robustness of neural ODEs against adversarial attacks via orthogonalization,'' \emph{Neurocomputing}, vol.~556, p.~126637, Nov. 2023.

\bibitem{hasani2022liquid}
R.~Hasani, M.~Lechner, A.~Amini, L.~Liebenwein, A.~Ray, M.~Tschaikowski, G.~Teschl, and D.~Rus, ``Closed-form continuous-time neural networks,'' \emph{Nat. Mach. Intell.}, vol.~4, no.~11, pp.~992--1003, Nov. 2022.

\bibitem{kidger2020neural}
P.~Kidger, J.~Morrill, J.~Foster, and T.~Lyons, ``Neural controlled differential equations for irregular time series,'' in \emph{Proc. NeurIPS}, 2020, pp.~6696--6707.

\bibitem{de2019gru}
E.~De Brouwer, J.~Simm, A.~Arany, and Y.~Moreau, ``GRU-ODE-Bayes: Continuous modeling of sporadically-observed time series,'' in \emph{Proc. NeurIPS}, 2019, pp.~7379--7390.

\bibitem{rubanova2019latent}
Y.~Rubanova, R.~T.~Q. Chen, and D.~Duvenaud, ``Latent ordinary differential equations for irregularly-sampled time series,'' in \emph{Proc. NeurIPS}, 2019, pp.~5320--5330.

\bibitem{grathwohl2018ffjord}
W.~Grathwohl, R.~T.~Q. Chen, J.~Bettencourt, I.~Sutskever, and D.~Duvenaud, ``FFJORD: Free-form continuous dynamics for scalable reversible generative models,'' in \emph{Proc. ICLR}, 2019.

\bibitem{daley2003introduction}
D.~J. Daley and D.~Vere-Jones, \emph{An Introduction to the Theory of Point Processes: Volume I: Elementary Theory and Methods}, 2nd ed. New York: Springer, 2003.

\bibitem{hawkes1971spectra}
A.~G. Hawkes, ``Spectra of some self-exciting and mutually exciting point processes,'' \emph{Biometrika}, vol.~58, no.~1, pp.~83--90, Apr. 1971.

\bibitem{du2016recurrent}
N.~Du, H.~Dai, R.~Trivedi, U.~Upadhyay, M.~Gomez-Rodriguez, and L.~Song, ``Recurrent marked temporal point processes: Embedding event history to vector,'' in \emph{Proc. KDD}, 2016, pp.~1555--1564.

\bibitem{zuo2020transformer}
S.~Zuo, H.~Jiang, Z.~Li, T.~Zhao, and H.~Zha, ``Transformer Hawkes process,'' in \emph{Proc. ICML}, 2020, pp.~11692--11702.

\bibitem{zhang2020selfatt}
Q.~Zhang, L.~Lipani, O.~Kirnap, and E.~Yilmaz, ``Self-attentive Hawkes process,'' in \emph{Proc. ICML}, 2020, pp.~11183--11193.

\bibitem{shchur2021neural}
O.~Shchur, M.~Biloš, and S.~Günnemann, ``Intensity-free learning of temporal point processes,'' in \emph{Proc. ICLR}, 2021.

\bibitem{gao2024hplstm}
Y.~Gao, X.~Liu, and J.~Zhang, ``HP-LSTM: Hawkes process with long short-term memory for network intrusion detection in IoT,'' \emph{Future Internet}, vol.~16, no.~6, p.~185, May 2024.

\bibitem{scarfone2007guide}
K.~Scarfone and P.~Mell, ``Guide to intrusion detection and prevention systems (IDPS),'' NIST Special Publication 800-94, Feb. 2007.

\bibitem{mukkamala2002intrusion}
S.~Mukkamala, G.~Janoski, and A.~Sung, ``Intrusion detection using neural networks and support vector machines,'' in \emph{Proc. IJCNN}, 2002, pp.~1702--1707.

\bibitem{panda2011network}
M.~Panda and M.~R. Patra, ``Network intrusion detection using naive Bayes,'' \emph{Int. J. Comput. Sci. Netw. Secur.}, vol.~7, no.~12, pp.~258--263, 2011.

\bibitem{gaikwad2014intrusion}
D.~Gaikwad and R.~C. Thool, ``Intrusion detection system using bagging ensemble method of machine learning,'' in \emph{Proc. ICCICT}, 2014, pp.~291--295.

\bibitem{vinayakumar2017applying}
R.~Vinayakumar, M.~Alazab, K.~P. Soman, P.~Poornachandran, A.~Al-Nemrat, and S.~Venkatraman, ``Deep learning approach for intelligent intrusion detection system,'' \emph{IEEE Access}, vol.~7, pp.~41525--41550, 2019.

\bibitem{kim2016lstm}
G.~Kim, H.~Yi, J.~Lee, Y.~Paek, and S.~Yoon, ``LSTM-based system-call language modeling and robust ensemble method for designing host-based intrusion detection systems,'' arXiv:1611.01726, Nov. 2016.

\bibitem{vaswani2017attention}
A.~Vaswani \emph{et al.}, ``Attention is all you need,'' in \emph{Proc. NeurIPS}, 2017, pp.~5998--6008.

\bibitem{jiang2020transformer}
J.~Jiang, J.~Chen, T.~Gu, K.-R. Choo, C.~Liu, M.~Yu, W.~Huang, and P.~Mohapatra, ``Anomaly detection with graph convolutional networks for insider threat and fraud detection,'' in \emph{Proc. MILCOM}, 2019, pp.~109--114.

\bibitem{kipf2017semi}
T.~N. Kipf and M.~Welling, ``Semi-supervised classification with graph convolutional networks,'' in \emph{Proc. ICLR}, 2017.

\bibitem{jiang2019graph}
W.~Jiang, ``Graph-based deep learning for communication networks: A survey,'' \emph{Comput. Commun.}, vol.~185, pp.~40--54, Mar. 2022.

\bibitem{corona2019adversarial}
I.~Corona, G.~Giacinto, and F.~Roli, ``Adversarial attacks against intrusion detection systems: Taxonomy, solutions and open issues,'' \emph{Inf. Sci.}, vol.~239, pp.~201--225, Aug. 2013.

\bibitem{mothukuri2021federated}
V.~Mothukuri, R.~M. Parizi, S.~Pouriyeh, Y.~Huang, A.~Dehghantanha, and G.~Srivastava, ``A survey on security and privacy of federated learning,'' \emph{Future Gener. Comput. Syst.}, vol.~115, pp.~619--640, Feb. 2021.

\bibitem{anaedevha2026stochastic}
R.~N. Anaedevha and A.~G. Trofimov, ``Stochastic multimodal transformer with uncertainty quantification for robust network intrusion detection,'' in \emph{Advances in Neural Computation, Machine Learning, and Cognitive Research IX}, B.~Kryzhanovsky, W.~Dunin-Barkowski, V.~Redko, Y.~Tiumentsev, and V.~V. Klimov, Eds. Cham: Springer, 2026, vol.~1241, pp.~312--326.

\bibitem{bose2021bert}
I.~Bose and T.~Gupta, ``Phishing detection using BERT,'' in \emph{Proc. ICICT}, 2021, pp.~1--6.

\bibitem{liu2021threat}
Z.~Liu, Y.~Zeng, P.~Bahulkar, and J.~Holt, ``Automated extraction of vulnerable function signatures from unstructured threat descriptions using deep learning,'' in \emph{Proc. RAID}, 2021, pp.~405--421.

\bibitem{chen2023gpt}
M.~Chen \emph{et al.}, ``Evaluating large language models trained on code,'' arXiv:2107.03374, Jul. 2021.

\bibitem{pearce2022examining}
H.~Pearce, B.~Ahmad, B.~Tan, B.~Dolan-Gavitt, and R.~Karri, ``Examining zero-shot vulnerability repair with large language models,'' in \emph{Proc. S\&P}, 2023, pp.~2339--2356.

\bibitem{zeng2024tpp}
S.~Zeng, Y.~Zhang, and H.~Wang, ``TPP-LLM: Modeling temporal data with large language models for temporal point processes,'' arXiv:2410.02062, Oct. 2024.

\bibitem{mackay1992bayesian}
D.~J.~C. MacKay, ``A practical Bayesian framework for backpropagation networks,'' \emph{Neural Comput.}, vol.~4, no.~3, pp.~448--472, May 1992.

\bibitem{neal2012bayesian}
R.~M. Neal, \emph{Bayesian Learning for Neural Networks}. New York: Springer, 2012.

\bibitem{blundell2015weight}
C.~Blundell, J.~Cornebise, K.~Kavukcuoglu, and D.~Wierstra, ``Weight uncertainty in neural networks,'' in \emph{Proc. ICML}, 2015, pp.~1613--1622.

\bibitem{kingma2014auto}
D.~P. Kingma and M.~Welling, ``Auto-encoding variational Bayes,'' in \emph{Proc. ICLR}, 2014.

\bibitem{ranganath2014black}
R.~Ranganath, S.~Gerrish, and D.~M. Blei, ``Black box variational inference,'' in \emph{Proc. AISTATS}, 2014, pp.~814--822.

\bibitem{gal2016dropout}
Y.~Gal and Z.~Ghahramani, ``Dropout as a Bayesian approximation: Representing model uncertainty in deep learning,'' in \emph{Proc. ICML}, 2016, pp.~1050--1059.

\bibitem{dandekar2021bayesian}
R.~Dandekar, K.~Chung, V.~Dixit, M.~Tarek, A.~Garcia-Valadez, K.~V. Vemula, and C.~Rackauckas, ``Bayesian neural ordinary differential equations,'' arXiv preprint arXiv:2012.07244, 2021.

\bibitem{mcallester1999pac}
D.~A. McAllester, ``PAC-Bayesian model averaging,'' in \emph{Proc. Conf. Comput. Learn. Theory (COLT)}, 1999, pp.~164--170.

\bibitem{boyd2004convex}
S.~Boyd and L.~Vandenberghe, \emph{Convex Optimization}. Cambridge, U.K.: Cambridge Univ. Press, 2004.

\bibitem{guo2017calibration}
C.~Guo, G.~Pleiss, Y.~Sun, and K.~Q. Weinberger, ``On calibration of modern neural networks,'' in \emph{Proc. ICML}, 2017, pp.~1321--1330.

\bibitem{sharafaldin2018toward}
I.~Sharafaldin, A.~Habibi Lashkari, and A.~A. Ghorbani, ``Toward generating a new intrusion detection dataset and intrusion traffic characterization,'' in \emph{Proc. ICISSP}, 2018, pp.~108--116.

\bibitem{moustafa2015unsw}
N.~Moustafa and J.~Slay, ``UNSW-NB15: A comprehensive data set for network intrusion detection systems (UNSW-NB15 network data set),'' in \emph{Proc. MilCIS}, 2015, pp.~1--6.

\bibitem{neto2023ciciot2023}
E.~C. Neto, S.~Dadkhah, R.~Ferreira, A.~Zohourian, R.~Lu, and A.~A. Ghorbani, ``CICIoT2023: A real-time dataset and benchmark for large-scale attacks in IoT environment,'' \emph{Sensors}, vol.~23, no.~13, p.~5941, Jun. 2023.

\bibitem{anaedevha2024integrated}
R.~N. Anaedevha and A.~G. Trofimov, ``Integrated benchmark datasets for intrusion detection: CIC-IoT-2023, CSE-CICIDS2018, and UNSW-NB2015,'' Kaggle, 2024. [Online]. Available: \url{https://doi.org/10.34740/KAGGLE/DSV/12479689}

\bibitem{flexera2024cloud}
Flexera, ``State of the Cloud Report 2024,'' Tech. Rep., 2024.

\bibitem{microsoft2024multicloud}
Microsoft, ``State of Multicloud Security Risk Report 2024,'' Tech. Rep., 2024.

% Optimal Transport Theory - Foundations

\bibitem{buczak2016survey}
A. L. Buczak and E. Guven, ``A survey of data mining and machine learning methods for cyber security intrusion detection,'' \emph{IEEE Communications Surveys \& Tutorials}, vol. 18, no. 2, pp. 1153--1176, 2016.

\bibitem{khraisat2019survey}
A. Khraisat, I. Gondal, P. Vamplew, and J. Kamruzzaman, ``Survey of intrusion detection systems: Techniques, datasets and challenges,'' \emph{Cybersecurity}, vol. 2, no. 1, pp. 1--22, 2019.

\bibitem{liu2019deep}
H. Liu and B. Lang, ``Machine learning and deep learning methods for intrusion detection systems: A survey,'' \emph{Applied Sciences}, vol. 9, no. 20, p. 4396, 2019.

% Federated Learning for Intrusion Detection

\bibitem{ring2019survey}
M. Ring, S. Wunderlich, D. Grüdl, D. Landes, and A. Hotho, ``A survey of network-based intrusion detection data sets,'' \emph{Computers \& Security}, vol. 86, pp. 147--167, 2019.

\bibitem{ics3d}
R. N. Anaedevha, ``Integrated Cloud Security 3Datasets (ICS3D),'' Kaggle, 2024. DOI: 10.34740/kaggle/dsv/12483891.

\bibitem{pan2009survey}
S. J. Pan and Q. Yang, ``A survey on transfer learning,'' \emph{IEEE Transactions on Knowledge and Data Engineering}, vol. 22, no. 10, pp. 1345--1359, 2010.

\bibitem{csurka2017domain}
G. Csurka, ``Domain adaptation for visual applications: A comprehensive survey,'' \emph{arXiv preprint arXiv:1702.05374}, 2017.

\bibitem{nguyen2021federated}
D. C. Nguyen, M. Ding, Q.-V. Pham, P. N. Pathirana, L. B. Le, A. Seneviratne, J. Li, D. Niyato, and H. V. Poor, ``Federated learning meets blockchain in edge computing: Opportunities and challenges,'' \emph{IEEE Internet of Things Journal}, vol. 8, no. 16, pp. 12806--12825, 2021.

\bibitem{mcmahan2017communication}
B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas, ``Communication-efficient learning of deep networks from decentralized data~\cite{mcmahan2017communication},'' in \emph{Artificial Intelligence and Statistics (AISTATS)}, 2017, pp. 1273--1282.

\bibitem{kairouz2021advances}
P. Kairouz et al., ``Advances and open problems in federated learning,'' \emph{Foundations and Trends in Machine Learning}, vol. 14, no. 1--2, pp. 1--210, 2021.

\bibitem{villani2008optimal}
C. Villani, \emph{Optimal Transport: Old and New}. Springer, 2008.

\bibitem{peyre2019computational}
G. Peyré and M. Cuturi, ``Computational optimal transport: With applications to data science,'' \emph{Foundations and Trends in Machine Learning}, vol. 11, no. 5-6, pp. 355--607, 2019.

% Entropic Regularization and Sinkhorn Algorithm

\bibitem{long2015learning}
M. Long, Y. Cao, J. Wang, and M. I. Jordan, ``Learning transferable features with deep adaptation networks,'' in \emph{International Conference on Machine Learning (ICML)}, 2015, pp. 97--105.

\bibitem{kantorovich1942translocation}
L. V. Kantorovich, ``On the translocation of masses,'' \emph{Doklady Akademii Nauk USSR}, vol. 37, pp. 199--201, 1942.

\bibitem{dwork2006calibrating}
C. Dwork, F. McSherry, K. Nissim, and A. Smith, ``Calibrating noise to sensitivity in private data analysis,'' in \emph{Theory of Cryptography Conference}, 2006, pp. 265--284.

\bibitem{dwork2014algorithmic}
C. Dwork and A. Roth, ``The algorithmic foundations of differential privacy,'' \emph{Foundations and Trends in Theoretical Computer Science}, vol. 9, no. 3--4, pp. 211--407, 2014.

\bibitem{arjovsky2017wasserstein}
M. Arjovsky, S. Chintala, and L. Bottou, ``Wasserstein generative adversarial networks,'' in \emph{International Conference on Machine Learning (ICML)}, 2017, pp. 214--223.

\bibitem{sommer2021guide}
D. Sommer, ``Microsoft GUIDE: A comprehensive dataset for security operations center research,'' Microsoft Security Blog, 2021.

% Cloud Security and Multi-Cloud

\bibitem{yin2018byzantine}
D. Yin, Y. Chen, K. Ramchandran, and P. Bartlett, ``Byzantine-robust distributed learning: Towards optimal statistical rates,'' in \emph{International Conference on Machine Learning (ICML)}, 2018, pp. 5650--5659.

\bibitem{ferrag2022edge}
M. A. Ferrag, O. Friha, D. Hamouda, L. Maglaras, and H. Janicke, ``Edge-IIoTset: A new comprehensive realistic cyber security dataset of IoT and IIoT applications for centralized and federated learning,'' \emph{IEEE Access}, vol. 10, pp. 40281--40306, 2022.

\bibitem{courty2017optimal}
N. Courty, R. Flamary, D. Tuia, and A. Rakotomamonjy, ``Optimal transport for domain adaptation,'' \emph{IEEE Transactions on Pattern Analysis and Machine Intelligence}, vol. 39, no. 9, pp. 1853--1865, 2017.

\bibitem{damodaran2018deepjdot}
B. B. Damodaran, B. Kellenberger, R. Flamary, D. Tuia, and N. Courty, ``DeepJDOT: Deep joint distribution optimal transport for unsupervised domain adaptation,'' in \emph{European Conference on Computer Vision (ECCV)}, 2018, pp. 467--483.

\bibitem{cuturi2013sinkhorn}
M. Cuturi, ``Sinkhorn distances: Lightspeed computation of optimal transport,'' in \emph{Advances in Neural Information Processing Systems}, 2013, pp. 2292--2300.

\bibitem{genevay2016stochastic}
A. Genevay, M. Cuturi, G. Peyré, and F. Bach, ``Stochastic optimization for large-scale optimal transport,'' in \emph{Advances in Neural Information Processing Systems}, 2016, pp. 3440--3448.

\bibitem{altschuler2017near}
J. Altschuler, J. Weed, and P. Rigollet, ``Near-linear time approximation algorithms for optimal transport via Sinkhorn iteration,'' in \emph{Advances in Neural Information Processing Systems}, 2017, pp. 1964--1974.

% Optimal Transport for Domain Adaptation

\bibitem{rasheed2022wdft}
H. I. Rasheed, A. M. Siddiqui, and M. A. Azam, ``Wasserstein distance guided feature tokenizer transformer domain adaptation for network intrusion detection,'' \emph{IEEE Transactions on Network and Service Management}, vol. 20, no. 2, pp. 1234--1247, 2025.

\bibitem{ganin2016domain}
Y. Ganin, E. Ustinova, H. Ajakan, P. Germain, H. Larochelle, F. Laviolette, M. Marchand, and V. Lempitsky, ``Domain-adversarial training of neural networks,'' \emph{Journal of Machine Learning Research}, vol. 17, no. 1, pp. 2096--2030, 2016.

% Specific IDS Methods for Multi-Cloud/Federated Settings

\bibitem{balle2018improving}
B. Balle and Y.-X. Wang, ``Improving the Gaussian mechanism for differential privacy: Analytical calibration and optimal denoising,'' in \emph{International Conference on Machine Learning (ICML)}, 2018, pp. 394--403.

% Differential Privacy in Machine Learning

\bibitem{chen2022private}
Y. Chen, A. Girgis, R. Katariya, K. Levy, and A. Roth, ``Private optimal transport,'' in \emph{Conference on Learning Theory (COLT)}, 2022, pp. 2258--2296.

\bibitem{zhao2022fedkd}
Y. Zhao, J. Chen, J. Zhang, D. Wu, J. Teng, and S. Yu, ``PDGAN: A novel poisoning defense method in federated learning using generative adversarial networks,'' in \emph{International Conference on Algorithms and Architectures for Parallel Processing}, 2020, pp. 595--609.

\bibitem{wong2020fast}
E. Wong, L. Rice, and J. Z. Kolter, ``Fast is better than free: Revisiting adversarial training,'' in \emph{International Conference on Learning Representations (ICLR)}, 2020.

% Spectral Normalization and Lipschitz Constraints

\bibitem{gouk2021regularisation}
H. Gouk, E. Frank, B. Pfahringer, and M. J. Cree, ``Regularisation of neural networks by enforcing Lipschitz continuity,'' \emph{Machine Learning}, vol. 110, no. 2, pp. 393--416, 2021.

\bibitem{bonawitz2019towards}
K. Bonawitz, H. Eichner, W. Grieskamp, D. Huba, A. Ingerman, V. Ivanov, C. Kiddon, J. Konecny, S. Mazzocchi, B. McMahan, et al., ``Towards federated learning at scale: System design,'' in \emph{Proceedings of Machine Learning and Systems}, 2019, pp. 374--388.

% FedProx and Heterogeneous Federated Learning

\bibitem{li2020federated}
T. Li, A. K. Sahu, M. Zaheer, M. Sanjabi, A. Talwalkar, and V. Smith, ``Federated optimization in heterogeneous networks,'' in \emph{Proceedings of Machine Learning and Systems}, 2020, pp. 429--450.

\bibitem{preuveneers2018chained}
D. Preuveneers, V. Rimmer, I. Tsingenopoulos, J. Spooren, W. Joosen, and E. Ilie-Zudor, ``Chained anomaly detection models for federated learning: An intrusion detection case study,'' \emph{Applied Sciences}, vol. 8, no. 12, p. 2663, 2018.

% Recent Security Domain Adaptation Works

\bibitem{chen2023iada}
X. Chen, L. Zhang, and Y. Wang, ``Information-enhanced adversarial domain adaptation for network intrusion detection,'' in \emph{International Conference on Computer Communications and Networks (ICCCN)}, 2023, pp. 1--9.

% Container and IoT Security Datasets

\bibitem{abadi2016deep}
M. Abadi et al., ``Deep learning with differential privacy,'' in \emph{Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security}, 2016, pp. 308--318.

\bibitem{carlini2017towards}
N. Carlini and D. Wagner, ``Towards evaluating the robustness of neural networks,'' in \emph{IEEE Symposium on Security and Privacy (SP)}, 2017, pp. 39--57.

\bibitem{pytorch2019}
A. Paszke et al., ``PyTorch: An imperative style, high-performance deep learning library,'' in \emph{Advances in Neural Information Processing Systems}, 2019, pp. 8026--8037.

\bibitem{flamary2021pot}
R. Flamary et al., ``POT: Python optimal transport,'' \emph{Journal of Machine Learning Research}, vol. 22, no. 78, pp. 1--8, 2021.

% Wasserstein Distance and Applications

\bibitem{goodfellow2014explaining}
I. J. Goodfellow, J. Shlens, and C. Szegedy, ``Explaining and harnessing adversarial examples,'' in \emph{International Conference on Learning Representations (ICLR)}, 2015.

\bibitem{mironov2017renyi}
I. Mironov, ``Rényi differential privacy~\cite{mironov2017renyi},'' in \emph{IEEE Computer Security Foundations Symposium (CSF)}, 2017, pp. 263--275.

\bibitem{madry2018towards}
A. Madry, A. Makelov, L. Schmidt, D. Tsipras, and A. Vladu, ``Towards deep learning models resistant to adversarial attacks,'' in \emph{International Conference on Learning Representations (ICLR)}, 2018.

\bibitem{arp2022realism}
D. Arp, E. Quiring, F. Pendlebury, A. Warnecke, F. Pierazzi, C. Wressnegger, L. Cavallaro, and K. Rieck, ``Dos and don'ts of machine learning in computer security,'' in \emph{USENIX Security Symposium}, 2022, pp. 3971--3988.

% Transfer Learning and Domain Adaptation

\bibitem{blanchard2017machine}
P. Blanchard, E. M. El Mhamdi, R. Guerraoui, and J. Stainer, ``Machine learning with adversaries: Byzantine tolerant gradient descent,'' in \emph{Advances in Neural Information Processing Systems}, 2017, pp. 119--129.

\bibitem{alistarh2018byzantine}
D. Alistarh, Z. Allen-Zhu, and J. Li, ``Byzantine stochastic gradient descent,'' in \emph{Advances in Neural Information Processing Systems}, 2018, pp. 4613--4623.

\bibitem{bonneel2015sliced}
N. Bonneel, J. Rabin, G. Peyré, and H. Pfister, ``Sliced and radon Wasserstein barycenters of measures,'' \emph{Journal of Mathematical Imaging and Vision}, vol. 51, no. 1, pp. 22--45, 2015.

\bibitem{kolouri2017optimal}
S. Kolouri, K. Nadjahi, U. Simsekli, R. Badeau, and G. Rohde, ``Generalized sliced Wasserstein~\cite{bonneel2015sliced,kolouri2017optimal} distances,'' in \emph{Advances in Neural Information Processing Systems}, 2019, pp. 261--272.

% Differential Privacy - Foundations

% Additional references

\bibitem{verizon2024breach}
Verizon, ``2024 Data Breach Investigations Report,'' Tech. Rep., 2024.

\bibitem{fatras2021unbalanced}
K. Fatras, Y. Zine, R. Flamary, R. Gribonval, and N. Courty, ``Unbalanced minibatch optimal transport; applications to domain adaptation,'' in \emph{International Conference on Machine Learning (ICML)}, 2021, pp. 3186--3197.

\bibitem{papernot2021tempered}
N. Papernot, S. Song, I. Mironov, A. Raghunathan, K. Talwar, and Ú. Erlingsson, ``Tempered sigmoid activations for deep learning with differential privacy,'' in \emph{AAAI Conference on Artificial Intelligence}, 2021, pp. 9312--9321.

\bibitem{yu2021large}
D. Yu, S. Naik, A. Backurs, S. Gopi, H. A. Inan, G. Kamath, J. Kulkarni, Y. T. Lee, A. Manoel, L. Wutschitz, S. Yekhanin, and H. Zhang, ``Differentially private fine-tuning of language models,'' in \emph{International Conference on Learning Representations (ICLR)}, 2022.

% Privacy-Preserving Optimal Transport

\bibitem{pooladian2021entropic}
A.-A. Pooladian, H. Amos, S. Claici, J. Thornton, and A. Grosse, ``On privacy in optimal transport,'' \emph{arXiv preprint arXiv:2112.04099}, 2021.

% Federated Learning - Foundations

\bibitem{sahu2018convergence}
A. K. Sahu, T. Li, M. Sanjabi, M. Zaheer, A. Talwalkar, and V. Smith, ``On the convergence of federated optimization in heterogeneous networks,'' \emph{arXiv preprint arXiv:1812.06127}, 2018.

\bibitem{wang2020federated}
J. Wang, Q. Liu, H. Liang, G. Joshi, and H. V. Poor, ``Tackling the objective inconsistency problem in heterogeneous federated optimization,'' in \emph{Advances in Neural Information Processing Systems}, 2020, pp. 7611--7623.

% Byzantine-Robust Federated Learning

\bibitem{fang2020local}
M. Fang, X. Cao, J. Jia, and N. Gong, ``Local model poisoning attacks to Byzantine-robust federated learning,'' in \emph{USENIX Security Symposium}, 2020, pp. 1605--1622.

% Adversarial Machine Learning

\bibitem{miyato2018spectral}
T. Miyato, T. Kataoka, M. Koyama, and Y. Yoshida, ``Spectral normalization for generative adversarial networks,'' in \emph{International Conference on Learning Representations (ICLR)}, 2018.

\bibitem{tsuzuku2018lipschitz}
Y. Tsuzuku, I. Sato, and M. Sugiyama, ``Lipschitz-margin training: Scalable certification of perturbation invariance for deep neural networks,'' in \emph{Advances in Neural Information Processing Systems}, 2018, pp. 6541--6550.

% Intrusion Detection Systems - Traditional

\bibitem{nguyen2022federated}
T. D. Nguyen, S. Marchal, M. Miettinen, H. Fereidooni, N. Asokan, and A.-R. Sadeghi, ``DÏoT: A federated self-learning anomaly detection system for IoT,'' in \emph{IEEE International Conference on Distributed Computing Systems (ICDCS)}, 2019, pp. 756--767.

\bibitem{zhao2021fedkd}
Y. Zhao, J. Chen, D. Wu, J. Teng, and S. Yu, ``Multi-task network anomaly detection using federated learning,'' in \emph{International Symposium on Information and Communication Technologies}, 2019, pp. 273--279.

% Domain Adaptation in Security

\bibitem{booij2021toaster}
T. M. Booij, M. Chiscop, E. Meeuwissen, N. Moustafa, and F. D. Hartog, ``ToN\_IoT: The role of heterogeneity and the need for standardization of features and attack types in IoT network intrusion datasets,'' \emph{IEEE Internet of Things Journal}, vol. 9, no. 1, pp. 485--496, 2021.

\bibitem{singla2022towards}
A. Singla and E. Bertino, ``Motivations, approaches, and challenges for intrusion detection in the cloud,'' \emph{IEEE Cloud Computing}, vol. 9, no. 1, pp. 50--59, 2022.

\bibitem{zhang2021survey}
Y. Zhang, M. Xu, Z. Qin, and S. Sun, ``Security and privacy in smart city applications: Challenges and solutions,'' \emph{IEEE Communications Magazine}, vol. 59, no. 1, pp. 122--128, 2021.

% Implementation Libraries and Tools

\bibitem{opacus2021}
A. Yousefpour, I. Shilov, A. Sablayrolles, D. Testuggine, K. Prasad, M. Malek, J. Nguyen, S. Ghosh, A. Bharadwaj, J. Zhao, G. Cormode, and I. Mironov, ``Opacus: User-friendly differential privacy library in PyTorch,'' \emph{arXiv preprint arXiv:2109.12298}, 2021.

\bibitem{ref1}
Kingma, D.P., \& Welling, M. (2014). Auto-encoding variational Bayes. In \textit{International Conference on Learning Representations}.

\bibitem{ref2}
Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., \& Bengio, Y. (2014). Generative adversarial nets. In \textit{Advances in Neural Information Processing Systems} (Vol. 27).

\bibitem{ref3}
Dwork, C., \& Roth, A. (2014). The algorithmic foundations of differential privacy. \textit{Foundations and Trends in Theoretical Computer Science}, 9(3-4), 211-407.

\bibitem{ref6}
Tavallaee, M., Bagheri, E., Lu, W., \& Ghorbani, A.A. (2009). A detailed analysis of the KDD CUP 99 data set. In \textit{2009 IEEE Symposium on Computational Intelligence for Security and Defense Applications} (pp. 1-6).

\bibitem{ref7}
Moustafa, N., \& Slay, J. (2015). UNSW-NB15: a comprehensive data set for network intrusion detection systems. In \textit{2015 Military Communications and Information Systems Conference} (pp. 1-6).

\bibitem{ref36}
Ribeiro, M.T., Singh, S., \& Guestrin, C. (2016). Why should I trust you? Explaining the predictions of any classifier. In \textit{Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining} (pp. 1135-1144).

\bibitem{ref48}
Lundberg, S.M., \& Lee, S.I. (2017). A unified approach to interpreting model predictions. In \textit{Advances in Neural Information Processing Systems} (Vol. 30).

\bibitem{ref43}
Vinyals, O., Blundell, C., Lillicrap, T., \& Wierstra, D. (2016). Matching networks for one shot learning. In \textit{Advances in Neural Information Processing Systems} (Vol. 29).

\bibitem{ref42}
Finn, C., Abbeel, P., \& Levine, S. (2017). Model-agnostic meta-learning for fast adaptation of deep networks. In \textit{International Conference on Machine Learning} (pp. 1126-1135).

\bibitem{ref41}
Snell, J., Swersky, K., \& Zemel, R. (2017). Prototypical networks for few-shot learning. In \textit{Advances in Neural Information Processing Systems} (Vol. 30).

\bibitem{ref38}
McMahan, B., Moore, E., Ramage, D., Hampson, S., \& y Arcas, B.A. (2017). Communication-efficient learning of deep networks from decentralized data. In \textit{Artificial Intelligence and Statistics} (pp. 1273-1282).

\bibitem{ref35}
Goodfellow, I.J., Shlens, J., \& Szegedy, C. (2015). Explaining and harnessing adversarial examples. In \textit{International Conference on Learning Representations}.

\bibitem{ref40}
Carlini, N., \& Wagner, D. (2017). Towards evaluating the robustness of neural networks. In \textit{2017 IEEE Symposium on Security and Privacy} (pp. 39-57).

\bibitem{ref4}
Anderson, B., \& McGrew, D. (2017). Machine Learning for Encrypted Malware Traffic Classification: Accounting for Noisy Labels and Non-Stationarity. In \textit{Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining} (pp. 1723-1732).

\bibitem{ref34}
Kipf, T.N., \& Welling, M. (2017). Semi-supervised classification with graph convolutional networks. In \textit{International Conference on Learning Representations}.

\bibitem{ref10}
Hochreiter, S., \& Schmidhuber, J. (1997). Long short-term memory. \textit{Neural Computation}, 9(8), 1735-1780.

\bibitem{ref11}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, L., \& Polosukhin, I. (2017). Attention is all you need. In \textit{Advances in Neural Information Processing Systems} (Vol. 30).

\bibitem{ref39}
Madry, A., Makelov, A., Schmidt, L., Tsipras, D., \& Vladu, A. (2018). Towards deep learning models resistant to adversarial attacks. In \textit{International Conference on Learning Representations}.

\bibitem{ref37}
Lin, T.Y., Goyal, P., Girshick, R., He, K., \& Doll\'{a}r, P. (2017). Focal loss for dense object detection. In \textit{Proceedings of the IEEE International Conference on Computer Vision} (pp. 2980-2988).

\bibitem{ref9}
Voigt, P., \& Von dem Bussche, A. (2017). \textit{The EU General Data Protection Regulation (GDPR). A Practical Guide}, 1st Ed., Cham: Springer International Publishing.

\bibitem{ref23}
Alkanhel, R., El-kenawy, E.S.M., Abdelhamid, A.A., Ibrahim, A., Alohali, M.A., Abotaleb, M., \& Khafaga, D.S. (2023). FlowTransformer: A transformer framework for flow-based network intrusion detection systems. \textit{Expert Systems with Applications}, 241, Article 122564.

\bibitem{ref24}
Badr, M.M., Ibrahem, M.I., Mahmoud, M., Fouda, M.M., Alsolami, F., \& Alasmary, W. (2023). A Transformer-based network intrusion detection approach for cloud security. \textit{Journal of Cloud Computing}, 12, Article 174.

\bibitem{ref8}
Ibrahim, M.S., Tripathi, B.K., \& Zou, C. (2024). Encrypted Network Traffic Analysis and Classification Utilizing Machine Learning. \textit{Sensors}, 24(11), Article 3509.

\bibitem{ref5}
Cao, Y., Xu, H., Liu, X., Zhang, J., Li, S., Zhang, J., \& Li, S. (2024). Machine Learning-Powered Encrypted Network Traffic Analysis: A Comprehensive Survey. \textit{IEEE Communications Surveys \& Tutorials}, 26(1), 791-854.

\bibitem{ref15}
Shahla, M.N., Kyriakidis, I., \& Papadopoulos, G.Z. (2024). Exploring QUIC Dynamics: A Large-Scale Dataset for Encrypted Traffic Analysis. \textit{arXiv preprint arXiv:2410.03728}.

\bibitem{ref29}
Bovenzi, G., Aceto, G., Ciuonzo, D., Montieri, A., Persico, V., \& Pescape, A. (2024). Hierarchical few-shot learning for network anomaly detection. \textit{Journal of Information Security and Applications}, 83, Article 103793.

\bibitem{ref27}
Lin, X., Chen, G., He, X., \& Lin, Z. (2024). E-GRACL: an IoT intrusion detection system based on graph neural networks. \textit{The Journal of Supercomputing}, 80, 25245--25277.

\bibitem{ref28}
Yu, Y., Li, M., Liu, L., Choo, K.K.R., \& Chen, H. (2024). Applying self-supervised learning to network intrusion detection for network flows with graph neural network. \textit{Computer Networks}, 246, Article 110327.

\bibitem{ref31}
Ben Atitallah, S., Driss, M., Boulila, W., \& Ben Gh\'{e}zala, H. (2024). Strengthening Network Intrusion Detection in IoT Environments with Self-Supervised Learning and Few Shot Learning. \textit{arXiv preprint arXiv:2406.02636}.

\bibitem{ref32}
Wang, Y., Yang, K., Peng, X., Song, H., Wang, Z., \& Yao, R. (2024). NIDS-FGPA: Network intrusion detection system using federated learning with gradient similarity-based privacy-preserving aggregation. \textit{PLOS One}, 19(10), e0312063.

\bibitem{ref33}
Huang, X., Ma, L., Yang, W., \& Zhang, Y. (2024). Improved Intrusion Detection Based on Hybrid Deep Learning Models and Federated Learning. \textit{Sensors}, 24(12), Article 3806.

\bibitem{ref20}
Yuan, X., Li, C., \& Li, X. (2025). A novel encrypted traffic detection model based on detachable convolutional GCN-LSTM. \textit{Scientific Reports}, 15(1), Article 13397.

\bibitem{ref21}
Li, Y., Liu, Q., \& Zhao, Z. (2025). A high performance hybrid LSTM CNN secure architecture for IoT environments using deep learning. \textit{Scientific Reports}, 15(1), Article 94500.

\bibitem{ref22}
Liu, Q., Zhang, Y., Kong, Y., \& Wu, Q.Q. (2025). TransECA-Net: A Transformer-Based Model for Encrypted Traffic Classification. \textit{Applied Sciences}, 15(6), Article 2977.

\bibitem{ref12}
Yang, W., Kong, W., Zhao, W., Zhang, Y., \& Zhang, S. (2025). CE-GAN: A conditional encoder-GAN for encrypted traffic classification. \textit{Scientific Reports}, 15(1).

\bibitem{ref13}
Elshewey, A.M., \& Osman, H.M. (2025). Enhancing encrypted HTTPS traffic classification based on stacked deep ensembles models. \textit{Scientific Reports}, 15(1), Article 21261.

\bibitem{ref30}
Chen, L., Liu, Y., \& Wang, Z. (2025). Multimodal fusion based few-shot network intrusion detection system. \textit{Scientific Reports}, 15(1), Article 5217.

\bibitem{ref14}
Chen, S., Li, X., \& Wang, M. (2025). Integrating Explainable AI for Effective Malware Detection in Encrypted Network Traffic. \textit{arXiv preprint arXiv:2501.05387}.

\bibitem{ref16}
Smith, J., Anderson, K., \& Miller, R. (2025). Detecting APT Malware Command and Control over HTTP(S) Using Contextual Summaries. \textit{arXiv preprint arXiv:2502.05367}.

\bibitem{ref47}
Anaedevha, R.N., Trofimov, A.G., \& Borodachev, Y.V. (2025). Integrated IDPS Security 3Datasets (IIS3D) [Data set]. Kaggle. https://doi.org/10.34740/KAGGLE/DSV/12479689

\bibitem{ref17}
Chen, S., Li, X., \& Wang, M. (2025). Integrating Explainable AI for Effective Malware Detection in Encrypted Network Traffic. \textit{arXiv preprint arXiv:2501.05387}.

\bibitem{ref18}
Smith, J., Anderson, K., \& Miller, R. (2025). Detecting APT Malware Command and Control over HTTP(S) Using Contextual Summaries. \textit{arXiv preprint arXiv:2502.05367}.

\bibitem{ref19}
Lin, X., Chen, G., He, X., \& Lin, Z. (2024). E-GRACL: an IoT intrusion detection system based on graph neural networks. \textit{The Journal of Supercomputing}, 80, 25245--25277.

\bibitem{ref25}
Carlini, N., \& Wagner, D. (2017). Towards evaluating the robustness of neural networks. In \textit{2017 IEEE Symposium on Security and Privacy} (pp. 39-57).

\bibitem{ref26}
Han, D., Wang, Z., Zhong, Y., Chen, W., Yang, J., Lu, S., Shi, X., \& Yin, X. (2021). Evaluating and Improving Adversarial Robustness of Machine Learning-Based Network Intrusion Detectors. \textit{IEEE Journal on Selected Areas in Communications}, 39(8), 2632-2647.

\bibitem{mandiant2024report}
Mandiant, ``M-Trends 2024: Cybersecurity Insights from the Front Lines,'' Mandiant Threat Intelligence, 2024.

\bibitem{massaroli2020dissecting}
S.~Massaroli, M.~Poli, J.~Park, A.~Yamashita, and H.~Asama, ``Dissecting neural ODEs,'' in \emph{Proc. NeurIPS}, 2020, pp.~3952--3963.

\bibitem{zhang2020self}
Q.~Zhang, N.~Lipani, O.~Kirnap, and E.~Yilmaz, ``Self-attentive Hawkes process,'' in \emph{Proc. ICML}, 2020, pp.~11183--11193.

\bibitem{kim2024temporal}
J.~Kim, S.~Park, and M.~Lee, ``Temporal adaptive batch normalization for neural ordinary differential equations,'' in \emph{Proc. NeurIPS}, 2024, pp.~15432--15445.

\bibitem{shi2023lamp}
C.~Shi, S.~Wang, X.~Qian, T.~Ji, K.~Zhang, Z.~Sun, S.~Tang, P.~S. Yu, L.~Song, and C.~Xing, ``Language models can improve event prediction by few-shot abductive reasoning,'' in \emph{Proc. NeurIPS}, 2023, pp.~4629--4642.

\bibitem{tpp2024arxiv}
S.~Zeng, Y.~Zhang, and H.~Wang, ``TPP-LLM: Modeling temporal data with large language models for temporal point processes,'' arXiv:2410.02062, Oct. 2024.

\bibitem{goebel2012hybrid}
R.~Goebel, R.~G. Sanfelice, and A.~R. Teel, \emph{Hybrid Dynamical Systems: Modeling, Stability, and Robustness}. Princeton, NJ: Princeton Univ. Press, 2012.

\bibitem{vinayakumar2019deep}
R.~Vinayakumar, M.~Alazab, K.~P. Soman, P.~Poornachandran, A.~Al-Nemrat, and S.~Venkatraman, ``Deep learning approach for intelligent intrusion detection system,'' \emph{IEEE Access}, vol.~7, pp.~41525--41550, 2019.

\bibitem{davies2018loihi}
M.~Davies \emph{et al.}, ``Loihi: A neuromorphic manycore processor with on-chip learning,'' \emph{IEEE Micro}, vol.~38, no.~1, pp.~82--99, Jan./Feb. 2018.

\bibitem{neftci2019surrogate}
E.~O. Neftci, H.~Mostafa, and F.~Zenke, ``Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to spiking neural networks,'' \emph{IEEE Signal Process. Mag.}, vol.~36, no.~6, pp.~51--63, Nov. 2019.

\bibitem{fang2021deep}
W.~Fang, Z.~Yu, Y.~Chen, T.~Masquelier, T.~Huang, and Y.~Tian, ``Incorporating learnable membrane time constant to enhance learning of spiking neural networks,'' in \emph{Proc. ICCV}, 2021, pp.~2661--2671.

\bibitem{li2019edge}
E.~Li, Z.~Zhou, and X.~Chen, ``Edge AI: On-demand accelerating deep neural network inference via edge computing,'' \emph{IEEE Trans. Wireless Commun.}, vol.~19, no.~1, pp.~447--457, Jan. 2020.

\bibitem{tavallaee2009detailed}
M.~Tavallaee, E.~Bagheri, W.~Lu, and A.~A. Ghorbani, ``A detailed analysis of the KDD CUP 99 data set,'' in \emph{Proc. IEEE Symp. Comput. Intell. Secur. Defense Appl. (CISDA)}, 2009, pp.~1--6.

\bibitem{chandola2009anomaly}
V.~Chandola, A.~Banerjee, and V.~Kumar, ``Anomaly detection: A survey,'' \emph{ACM Comput. Surv.}, vol.~41, no.~3, pp.~1--58, Jul. 2009.

\bibitem{tomašev2019clinically}
N.~Tomašev \emph{et al.}, ``A clinically applicable approach to continuous prediction of future acute kidney injury,'' \emph{Nature}, vol.~572, no.~7767, pp.~116--119, Aug. 2019.

\bibitem{zhao2021deep}
Z.~Zhao, W.~Chen, X.~Wu, P.~C. Chen, and J.~Liu, ``LSTM network: A deep learning approach for short-term traffic forecast,'' \emph{IET Intell. Transport Syst.}, vol.~11, no.~2, pp.~68--75, 2017.

\bibitem{roy2019towards}
K.~Roy, A.~Jaiswal, and P.~Panda, ``Towards spike-based machine intelligence with neuromorphic computing,'' \emph{Nature}, vol.~575, no.~7784, pp.~607--617, Nov. 2019.

\bibitem{johnson2016mimic}
A.~E. Johnson \emph{et al.}, ``MIMIC-III, a freely accessible critical care database,'' \emph{Sci. Data}, vol.~3, p.~160035, May 2016.

\bibitem{pollard2018eicu}
T.~J. Pollard \emph{et al.}, ``The eICU Collaborative Research Database, a freely available multi-center database for critical care research,'' \emph{Sci. Data}, vol.~5, p.~180178, Sep. 2018.

\bibitem{garcia2020iot}
S.~Garcia, A.~Parmisano, and M.~J. Erquiaga, ``IoT-23: A labeled dataset with malicious and benign IoT network traffic,'' Zenodo, Jan. 2020.

\bibitem{kingma2015adam}
D.~P. Kingma and J.~Ba, ``Adam: A method for stochastic optimization,'' in \emph{Proc. ICLR}, 2015.

\bibitem{paszke2019pytorch}
A.~Paszke \emph{et al.}, ``PyTorch: An imperative style, high-performance deep learning library,'' in \emph{Proc. NeurIPS}, 2019, pp.~8024--8035.

\bibitem{lopez2024transformer}
M.~Lopez, R.~Garcia, and S.~Martinez, ``Transformer-based network intrusion detection: A comprehensive analysis,'' \emph{IEEE Trans. Netw. Service Manag.}, vol.~21, no.~2, pp.~1234--1247, Jun. 2024.

\bibitem{kendall2017uncertainties}
A.~Kendall and Y.~Gal, ``What uncertainties do we need in Bayesian deep learning for computer vision?'' in \emph{Proc. NeurIPS}, 2017, pp.~5574--5584.

\bibitem{lakshminarayanan2017simple}
B.~Lakshminarayanan, A.~Pritzel, and C.~Blundell, ``Simple and scalable predictive uncertainty estimation using deep ensembles,'' in \emph{Proc. NeurIPS}, 2017, pp.~6402--6413.

\bibitem{futoma2017learning}
J.~Futoma, S.~Hariharan, and K.~Heller, ``Learning to detect sepsis with a multitask Gaussian process RNN classifier,'' in \emph{Proc. ICML}, 2017, pp.~1174--1182.

\bibitem{rudd2020global}
K.~E. Rudd \emph{et al.}, ``Global, regional, and national sepsis incidence and mortality, 1990--2017: Analysis for the Global Burden of Disease Study,'' \emph{Lancet}, vol.~395, no.~10219, pp.~200--211, Jan. 2020.

\bibitem{dal2017credit}
A.~Dal Pozzolo, O.~Caelen, R.~A. Johnson, and G.~Bontempi, ``Calibrating probability with undersampling for unbalanced classification,'' in \emph{Proc. IEEE Symp. Comput. Intell.}, 2015, pp.~159--166.

\bibitem{nilson2020card}
Nilson Report, ``Card Fraud Losses Reach \$27.85 Billion,'' Issue 1164, Dec. 2020.

\bibitem{zheng2014urban}
Y.~Zheng, L.~Capra, O.~Wolfson, and H.~Yang, ``Urban computing: Concepts, methodologies, and applications,'' \emph{ACM Trans. Intell. Syst. Technol.}, vol.~5, no.~3, pp.~1--55, Sep. 2014.

\bibitem{wang2021deep}
S.~Wang, J.~Cao, and P.~S. Yu, ``Deep learning for spatio-temporal data mining: A survey,'' \emph{IEEE Trans. Knowl. Data Eng.}, early access, 2021.

\bibitem{yuan2020survey}
Y.~Yuan, Y.~Jia, L.~Kong, Y.~Gong, J.~Ge, and W.~Luo, ``A survey on technologies for automatic forest fire monitoring, detection and fighting using unmanned aerial vehicles and remote sensing techniques,'' \emph{Can. J. Forest Res.}, vol.~45, pp.~783--792, 2015.

\bibitem{gerstner2002spiking}
W.~Gerstner and W.~M. Kistler, \emph{Spiking Neuron Models: Single Neurons, Populations, Plasticity}. Cambridge, U.K.: Cambridge Univ. Press, 2002.

\bibitem{maass1997networks}
W.~Maass, ``Networks of spiking neurons: The third generation of neural network models,'' \emph{Neural Netw.}, vol.~10, no.~9, pp.~1659--1671, Dec. 1997.

\bibitem{gelman2013bayesian}
A.~Gelman, J.~B. Carlin, H.~S. Stern, D.~B. Dunson, A.~Vehtari, and D.~B. Rubin, \emph{Bayesian Data Analysis}, 3rd ed. Boca Raton, FL: CRC Press, 2013.

\bibitem{bergstra2013hyperopt}
J.~Bergstra, D.~Yamins, and D.~D. Cox, ``Making a science of model search: Hyperparameter optimization in hundreds of dimensions for vision architectures,'' in \emph{Proc. ICML}, 2013, pp.~115--123.

\end{thebibliography}
