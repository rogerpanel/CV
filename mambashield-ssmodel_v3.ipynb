{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12479689,"sourceType":"datasetVersion","datasetId":7874259}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#!/usr/bin/env python\n## coding: utf-8\n\n## MambaShield: Complete Implementation for IEEE TNNLS\n## Temporal-Aware Poisoning-Resilient NIDS with Selective State Space Models\n# \n## This notebook implements the cutting-edge MambaShield architecture optimized for Kaggle P100 GPU.\n\n## Environment Setup and Imports","metadata":{}},{"cell_type":"markdown","source":"## Import Libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.cuda.amp import autocast, GradScaler\nfrom torch.utils.data import DataLoader, TensorDataset, Dataset\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport gc\nimport traceback\nimport random\nimport time\nimport warnings\nfrom typing import Dict, List, Tuple, Optional, Union, Any\nfrom collections import deque, defaultdict\nimport math\nfrom tqdm.notebook import tqdm\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder, RobustScaler\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score,\n    confusion_matrix, roc_auc_score, roc_curve, auc,\n    average_precision_score, matthews_corrcoef, cohen_kappa_score,\n    classification_report, balanced_accuracy_score\n)\nimport json\nfrom datetime import datetime\n\nwarnings.filterwarnings('ignore')\nplt.style.use('seaborn-v0_8-darkgrid')\n\nprint(\"PyTorch Version:\", torch.__version__)\nprint(\"CUDA Available:\", torch.cuda.is_available())\nif torch.cuda.is_available():\n    print(\"GPU:\", torch.cuda.get_device_name(0))\n    print(\"GPU Memory:\", torch.cuda.get_device_properties(0).total_memory / 1e9, \"GB\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n## Advanced Memory Management for P100\n","metadata":{}},{"cell_type":"code","source":"class P100MemoryManager:\n    \"\"\"Advanced memory management for P100 GPU\"\"\"\n    \n    def __init__(self):\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.memory_threshold = 0.8  # 80% memory usage threshold\n        \n    def get_memory_usage(self):\n        \"\"\"Get current GPU memory usage\"\"\"\n        if torch.cuda.is_available():\n            allocated = torch.cuda.memory_allocated() / 1e9\n            cached = torch.cuda.memory_reserved() / 1e9\n            total = torch.cuda.get_device_properties(0).total_memory / 1e9\n            return {\n                'allocated': allocated,\n                'cached': cached,\n                'total': total,\n                'usage_percent': (allocated / total) * 100\n            }\n        return None\n    \n    def optimize_batch_size(self, model, input_shape, initial_batch=64):\n        \"\"\"Find optimal batch size for P100\"\"\"\n        batch_size = initial_batch\n        \n        while batch_size > 1:\n            try:\n                # Test forward pass\n                dummy_input = torch.randn(batch_size, *input_shape).to(self.device)\n                _ = model(dummy_input)\n                \n                # Test backward pass\n                loss = torch.randn(1, requires_grad=True).to(self.device)\n                loss.backward()\n                \n                # Clear\n                del dummy_input, loss\n                self.clear_memory()\n                \n                # Check memory\n                mem = self.get_memory_usage()\n                if mem and mem['usage_percent'] < 70:\n                    return batch_size\n                    \n            except RuntimeError as e:\n                if \"out of memory\" in str(e):\n                    self.clear_memory()\n                    \n            batch_size = batch_size // 2\n            \n        return max(batch_size, 1)\n    \n    def clear_memory(self):\n        \"\"\"Aggressive memory clearing\"\"\"\n        gc.collect()\n        if torch.cuda.is_available():\n            torch.cuda.empty_cache()\n            torch.cuda.synchronize()\n\nmemory_manager = P100MemoryManager()\ndevice = memory_manager.device\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n## Enhanced Mamba Architecture with Fixes\n","metadata":{}},{"cell_type":"code","source":"\nclass ImprovedSelectiveSSM(nn.Module):\n    \"\"\"Improved Selective State Space Model with numerical stability\"\"\"\n    \n    def __init__(self, d_model, d_state=16, d_conv=4, dt_rank=\"auto\"):\n        super().__init__()\n        self.d_model = d_model\n        self.d_state = d_state\n        self.d_conv = d_conv\n        \n        # Compute dt_rank\n        if dt_rank == \"auto\":\n            self.dt_rank = math.ceil(d_model / 16)\n        else:\n            self.dt_rank = dt_rank\n        \n        # Linear projections\n        self.in_proj = nn.Linear(d_model, d_model * 2, bias=False)\n        self.conv1d = nn.Conv1d(\n            d_model, d_model, \n            kernel_size=d_conv,\n            padding=d_conv - 1,\n            groups=d_model\n        )\n        \n        # SSM parameters\n        self.x_proj = nn.Linear(d_model, self.dt_rank + d_state * 2, bias=False)\n        self.dt_proj = nn.Linear(self.dt_rank, d_model, bias=True)\n        \n        # Initialize dt bias specially\n        dt_init_std = self.dt_rank**-0.5 * 1.0\n        nn.init.uniform_(self.dt_proj.bias, -dt_init_std, dt_init_std)\n        \n        # State parameters\n        A = torch.arange(1, d_state + 1).repeat(d_model, 1)\n        self.A_log = nn.Parameter(torch.log(A.float()))\n        self.D = nn.Parameter(torch.ones(d_model))\n        self.out_proj = nn.Linear(d_model, d_model, bias=False)\n        \n    def forward(self, x, inference_params=None):\n        \"\"\"Forward pass with numerical stability improvements\"\"\"\n        batch, seqlen, dim = x.shape\n        \n        # Dual branch\n        xz = self.in_proj(x)  # (B, L, 2*D)\n        x, z = xz.chunk(2, dim=-1)  # Each (B, L, D)\n        \n        # Convolution with proper padding\n        x = x.transpose(1, 2)  # (B, D, L)\n        x = self.conv1d(x)[:, :, :seqlen]  # Ensure correct length\n        x = x.transpose(1, 2)  # (B, L, D)\n        \n        # SSM\n        x = F.silu(x)\n        y = self.ssm(x)\n        \n        # Gating\n        y = y * F.silu(z)\n        output = self.out_proj(y)\n        \n        return output\n    \n    def ssm(self, x):\n        \"\"\"State Space Model computation with numerical stability\"\"\"\n        batch, seqlen, dim = x.shape\n        \n        # Compute dt, B, C\n        x_dbl = self.x_proj(x)  # (B, L, dt_rank + 2*d_state)\n        \n        dt, B, C = torch.split(\n            x_dbl, [self.dt_rank, self.d_state, self.d_state], dim=-1\n        )\n        \n        dt = self.dt_proj(dt)  # (B, L, D)\n        dt = F.softplus(dt)  # Ensure positive\n        \n        # State computation with numerical stability\n        A = -torch.exp(self.A_log.float())  # (D, d_state)\n        \n        # Discretize (ZOH)\n        y = self.selective_scan_simple(x, dt, A, B, C)\n        \n        return y\n    \n    def selective_scan_simple(self, u, dt, A, B, C):\n        \"\"\"Simplified selective scan for stability\"\"\"\n        batch, seqlen, dim = u.shape\n        d_state = A.shape[1]\n        \n        # Initialize output and state\n        y = torch.zeros_like(u)\n        x = torch.zeros(batch, dim, d_state, device=u.device, dtype=u.dtype)\n        \n        # Sequential computation (can be optimized with parallel scan)\n        for i in range(seqlen):\n            # Discretize\n            deltaA = torch.exp(dt[:, i, :, None] * A[None, :, :])  # (B, D, d_state)\n            deltaB = dt[:, i, :, None] * B[:, i, None, :]  # (B, D, d_state)\n            \n            # Update state\n            x = deltaA * x + deltaB * u[:, i, :, None]\n            \n            # Compute output\n            y[:, i] = (x * C[:, i, None, :]).sum(dim=-1)\n        \n        y = y + u * self.D\n        \n        return y\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n## Progressive Adversarial Robustness Distillation\n\n\n\n","metadata":{}},{"cell_type":"code","source":"\nclass ProgressiveARD(nn.Module):\n    \"\"\"Progressive Adversarial Robustness Distillation\"\"\"\n    \n    def __init__(self, student, teachers, temperature=3.0):\n        super().__init__()\n        self.student = student\n        self.teachers = nn.ModuleList(teachers) if teachers else nn.ModuleList()\n        self.temperature = temperature\n        self.alpha_schedule = self.create_schedule()\n        \n    def create_schedule(self):\n        \"\"\"Create progressive weighting schedule\"\"\"\n        # Start with low weight, gradually increase\n        return [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n    \n    def distillation_loss(self, student_logits, teacher_logits):\n        \"\"\"Compute distillation loss\"\"\"\n        student_soft = F.log_softmax(student_logits / self.temperature, dim=-1)\n        teacher_soft = F.softmax(teacher_logits / self.temperature, dim=-1)\n        loss = F.kl_div(student_soft, teacher_soft, reduction='batchmean')\n        return loss * (self.temperature ** 2)\n    \n    def forward(self, x, epoch=0):\n        \"\"\"Forward with progressive distillation\"\"\"\n        student_output = self.student(x)\n        \n        if not self.training or len(self.teachers) == 0:\n            return student_output, torch.tensor(0.0).to(x.device)\n        \n        # Get alpha based on epoch\n        alpha_idx = min(epoch, len(self.alpha_schedule) - 1)\n        alpha = self.alpha_schedule[alpha_idx]\n        \n        # Compute teacher ensemble predictions\n        distill_loss = 0\n        with torch.no_grad():\n            for teacher in self.teachers:\n                teacher.eval()\n                teacher_output = teacher(x)\n                if isinstance(teacher_output, dict):\n                    teacher_logits = teacher_output['logits']\n                else:\n                    teacher_logits = teacher_output\n                    \n                if isinstance(student_output, dict):\n                    student_logits = student_output['logits']\n                else:\n                    student_logits = student_output\n                    \n                distill_loss += self.distillation_loss(student_logits, teacher_logits)\n        \n        distill_loss = alpha * distill_loss / max(len(self.teachers), 1)\n        \n        return student_output, distill_loss\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n## 5. PAC-Bayes Certified Robustness\n","metadata":{}},{"cell_type":"code","source":"class PACBayesRobustness:\n    \"\"\"PAC-Bayes framework for certified robustness\"\"\"\n    \n    def __init__(self, model, prior_std=1.0, delta=0.05):\n        self.model = model\n        self.prior_std = prior_std\n        self.delta = delta\n        \n    def compute_kl_divergence(self):\n        \"\"\"Compute KL divergence between posterior and prior\"\"\"\n        kl = 0.0\n        for param in self.model.parameters():\n            if param.requires_grad:\n                # Assume Gaussian prior centered at 0\n                kl += 0.5 * torch.sum(\n                    (param ** 2) / (self.prior_std ** 2) - \n                    torch.log(torch.ones_like(param)) + \n                    math.log(self.prior_std ** 2)\n                )\n        return kl\n    \n    def pac_bayes_bound(self, empirical_risk, n_samples):\n        \"\"\"Compute PAC-Bayes generalization bound\"\"\"\n        kl = self.compute_kl_divergence()\n        \n        # McAllester's bound\n        complexity = torch.sqrt(\n            (kl + math.log(2 * math.sqrt(n_samples) / self.delta)) / \n            (2 * n_samples)\n        )\n        \n        bound = empirical_risk + complexity\n        \n        return {\n            'empirical_risk': empirical_risk.item(),\n            'kl_divergence': kl.item(),\n            'complexity': complexity.item(),\n            'bound': bound.item()\n        }\n    \n    def randomized_smoothing(self, x, num_samples=100, sigma=0.1):\n        \"\"\"Certify robustness using randomized smoothing\"\"\"\n        predictions = []\n        \n        for _ in range(num_samples):\n            noise = torch.randn_like(x) * sigma\n            noisy_x = x + noise\n            \n            with torch.no_grad():\n                output = self.model(noisy_x)\n                if isinstance(output, dict):\n                    logits = output['logits']\n                else:\n                    logits = output\n                predictions.append(F.softmax(logits, dim=-1))\n        \n        # Aggregate predictions\n        avg_pred = torch.stack(predictions).mean(0)\n        certified_pred = avg_pred.argmax(dim=-1)\n        \n        # Compute certified radius (simplified)\n        top2_probs, _ = avg_pred.topk(2, dim=-1)\n        gap = top2_probs[:, 0] - top2_probs[:, 1]\n        certified_radius = sigma * gap / 2\n        \n        return certified_pred, certified_radius\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n## Comprehensive Evaluation Framework (23 Metrics)\n\n","metadata":{}},{"cell_type":"code","source":"\nclass ComprehensiveEvaluator:\n    \"\"\"23-metric comprehensive evaluation framework\"\"\"\n    \n    def __init__(self):\n        self.metrics = {}\n        \n    def evaluate(self, model, dataloader, device, attack_fn=None):\n        \"\"\"Comprehensive evaluation with 23 metrics\"\"\"\n        model.eval()\n        \n        all_preds = []\n        all_labels = []\n        all_probs = []\n        all_features = []\n        \n        with torch.no_grad():\n            for data, labels in dataloader:\n                data, labels = data.to(device), labels.to(device)\n                \n                outputs = model(data)\n                if isinstance(outputs, dict):\n                    logits = outputs['logits']\n                    if 'features' in outputs:\n                        all_features.append(outputs['features'].cpu())\n                else:\n                    logits = outputs\n                \n                probs = F.softmax(logits, dim=-1)\n                preds = logits.argmax(dim=-1)\n                \n                all_preds.extend(preds.cpu().numpy())\n                all_labels.extend(labels.cpu().numpy())\n                all_probs.extend(probs.cpu().numpy())\n        \n        all_preds = np.array(all_preds)\n        all_labels = np.array(all_labels)\n        all_probs = np.array(all_probs)\n        \n        # 1. Accuracy Metrics\n        self.metrics['accuracy'] = accuracy_score(all_labels, all_preds)\n        self.metrics['balanced_accuracy'] = balanced_accuracy_score(all_labels, all_preds)\n        \n        # 2. Precision, Recall, F1\n        self.metrics['precision'] = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n        self.metrics['recall'] = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n        self.metrics['f1_score'] = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n        \n        # 3. ROC-AUC (if binary or can be computed)\n        try:\n            if len(np.unique(all_labels)) == 2:\n                self.metrics['roc_auc'] = roc_auc_score(all_labels, all_probs[:, 1])\n            else:\n                self.metrics['roc_auc'] = roc_auc_score(all_labels, all_probs, multi_class='ovr')\n        except:\n            self.metrics['roc_auc'] = 0.0\n        \n        # 4. Matthews Correlation Coefficient\n        self.metrics['mcc'] = matthews_corrcoef(all_labels, all_preds)\n        \n        # 5. Cohen's Kappa\n        self.metrics['cohen_kappa'] = cohen_kappa_score(all_labels, all_preds)\n        \n        # 6. Confusion Matrix Metrics\n        cm = confusion_matrix(all_labels, all_preds)\n        \n        # True Positive Rate (Sensitivity/Recall) per class\n        tpr_per_class = np.diag(cm) / cm.sum(axis=1)\n        self.metrics['mean_tpr'] = np.mean(tpr_per_class)\n        \n        # True Negative Rate (Specificity) per class\n        fp = cm.sum(axis=0) - np.diag(cm)\n        fn = cm.sum(axis=1) - np.diag(cm)\n        tp = np.diag(cm)\n        tn = cm.sum() - (fp + fn + tp)\n        tnr_per_class = tn / (tn + fp)\n        self.metrics['mean_tnr'] = np.mean(tnr_per_class)\n        \n        # 7. False Positive Rate\n        fpr_per_class = fp / (fp + tn)\n        self.metrics['mean_fpr'] = np.mean(fpr_per_class)\n        \n        # 8. False Negative Rate\n        fnr_per_class = fn / (fn + tp)\n        self.metrics['mean_fnr'] = np.mean(fnr_per_class)\n        \n        # 9. Uncertainty Metrics (using prediction entropy)\n        pred_entropy = -np.sum(all_probs * np.log(all_probs + 1e-10), axis=1)\n        self.metrics['mean_entropy'] = np.mean(pred_entropy)\n        self.metrics['std_entropy'] = np.std(pred_entropy)\n        \n        # 10. Calibration Metrics\n        self.metrics['brier_score'] = self._compute_brier_score(all_labels, all_probs)\n        self.metrics['ece'] = self._compute_ece(all_labels, all_preds, all_probs)\n        \n        # 11. Detection Latency (simulated)\n        self.metrics['avg_inference_time'] = self._measure_inference_time(model, dataloader, device)\n        \n        # 12. Memory Usage\n        if torch.cuda.is_available():\n            self.metrics['gpu_memory_mb'] = torch.cuda.memory_allocated() / 1e6\n        \n        # 13. Model Complexity\n        self.metrics['num_parameters'] = sum(p.numel() for p in model.parameters())\n        self.metrics['num_trainable_params'] = sum(p.numel() for p in model.parameters() if p.requires_grad)\n        \n        # 14. Attack Robustness (if attack function provided)\n        if attack_fn:\n            self.metrics['attack_success_rate'] = self._evaluate_attack_robustness(\n                model, dataloader, device, attack_fn\n            )\n        \n        # 15. Feature Quality Metrics (if features available)\n        if all_features:\n            features = torch.cat(all_features, dim=0).numpy()\n            self.metrics['feature_variance'] = np.mean(np.var(features, axis=0))\n            self.metrics['feature_sparsity'] = np.mean(features == 0)\n        \n        return self.metrics\n    \n    def _compute_brier_score(self, labels, probs):\n        \"\"\"Compute Brier score for calibration\"\"\"\n        n_classes = probs.shape[1]\n        brier = 0\n        for i in range(len(labels)):\n            label_onehot = np.zeros(n_classes)\n            label_onehot[labels[i]] = 1\n            brier += np.sum((probs[i] - label_onehot) ** 2)\n        return brier / len(labels)\n    \n    def _compute_ece(self, labels, preds, probs, n_bins=10):\n        \"\"\"Expected Calibration Error\"\"\"\n        max_probs = np.max(probs, axis=1)\n        correct = (preds == labels).astype(float)\n        \n        ece = 0\n        for bin_i in range(n_bins):\n            bin_lower = bin_i / n_bins\n            bin_upper = (bin_i + 1) / n_bins\n            \n            in_bin = (max_probs > bin_lower) & (max_probs <= bin_upper)\n            if np.sum(in_bin) > 0:\n                bin_acc = np.mean(correct[in_bin])\n                bin_conf = np.mean(max_probs[in_bin])\n                bin_size = np.sum(in_bin)\n                ece += (bin_size / len(labels)) * abs(bin_acc - bin_conf)\n        \n        return ece\n    \n    def _measure_inference_time(self, model, dataloader, device, n_samples=10):\n        \"\"\"Measure average inference time\"\"\"\n        times = []\n        \n        for i, (data, _) in enumerate(dataloader):\n            if i >= n_samples:\n                break\n                \n            data = data.to(device)\n            \n            start = time.time()\n            with torch.no_grad():\n                _ = model(data)\n            torch.cuda.synchronize() if torch.cuda.is_available() else None\n            times.append(time.time() - start)\n        \n        return np.mean(times) * 1000  # Convert to ms\n    \n    def _evaluate_attack_robustness(self, model, dataloader, device, attack_fn, n_samples=100):\n        \"\"\"Evaluate model robustness against attacks\"\"\"\n        success_count = 0\n        total_count = 0\n        \n        for i, (data, labels) in enumerate(dataloader):\n            if total_count >= n_samples:\n                break\n                \n            data, labels = data.to(device), labels.to(device)\n            \n            # Generate adversarial examples\n            adv_data = attack_fn(model, data, labels)\n            \n            # Evaluate on adversarial examples\n            with torch.no_grad():\n                outputs = model(adv_data)\n                if isinstance(outputs, dict):\n                    logits = outputs['logits']\n                else:\n                    logits = outputs\n                    \n                adv_preds = logits.argmax(dim=-1)\n                success_count += (adv_preds != labels).sum().item()\n                total_count += len(labels)\n        \n        return success_count / max(total_count, 1)\n    \n    def print_metrics(self):\n        \"\"\"Pretty print all metrics\"\"\"\n        print(\"\\n\" + \"=\"*60)\n        print(\"COMPREHENSIVE EVALUATION RESULTS (23 Metrics)\")\n        print(\"=\"*60)\n        \n        categories = {\n            'Accuracy Metrics': ['accuracy', 'balanced_accuracy'],\n            'Classification Metrics': ['precision', 'recall', 'f1_score', 'mcc', 'cohen_kappa'],\n            'ROC/AUC Metrics': ['roc_auc'],\n            'Error Rates': ['mean_fpr', 'mean_fnr', 'mean_tpr', 'mean_tnr'],\n            'Calibration Metrics': ['brier_score', 'ece'],\n            'Uncertainty Metrics': ['mean_entropy', 'std_entropy'],\n            'Performance Metrics': ['avg_inference_time', 'gpu_memory_mb'],\n            'Model Complexity': ['num_parameters', 'num_trainable_params'],\n            'Feature Metrics': ['feature_variance', 'feature_sparsity'],\n            'Robustness': ['attack_success_rate']\n        }\n        \n        for category, metric_names in categories.items():\n            print(f\"\\n{category}:\")\n            print(\"-\" * 40)\n            for metric in metric_names:\n                if metric in self.metrics:\n                    value = self.metrics[metric]\n                    if isinstance(value, float):\n                        print(f\"  {metric:25s}: {value:.4f}\")\n                    else:\n                        print(f\"  {metric:25s}: {value}\")\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n## Complete MambaShield Model\n","metadata":{}},{"cell_type":"code","source":"class MambaShield(nn.Module):\n    \"\"\"Complete MambaShield architecture with all components\"\"\"\n    \n    def __init__(self, input_dim, num_classes, config=None):\n        super().__init__()\n        \n        # Default config\n        if config is None:\n            config = {\n                'hidden_dim': 128,\n                'd_state': 16,\n                'n_layers': 2,\n                'dropout': 0.1,\n                'use_rl': False  # Disable RL by default for stability\n            }\n        \n        self.config = config\n        self.input_dim = input_dim\n        self.num_classes = num_classes\n        \n        # Input projection\n        self.input_proj = nn.Sequential(\n            nn.Linear(input_dim, config['hidden_dim']),\n            nn.LayerNorm(config['hidden_dim']),\n            nn.ReLU()\n        )\n        \n        # Mamba layers\n        self.mamba_layers = nn.ModuleList([\n            ImprovedSelectiveSSM(\n                config['hidden_dim'],\n                d_state=config['d_state']\n            )\n            for _ in range(config['n_layers'])\n        ])\n        \n        # Layer norms\n        self.layer_norms = nn.ModuleList([\n            nn.LayerNorm(config['hidden_dim'])\n            for _ in range(config['n_layers'])\n        ])\n        \n        # Dropout\n        self.dropout = nn.Dropout(config['dropout'])\n        \n        # Classification head\n        self.classifier = nn.Sequential(\n            nn.LayerNorm(config['hidden_dim']),\n            nn.Linear(config['hidden_dim'], config['hidden_dim'] // 2),\n            nn.ReLU(),\n            nn.Dropout(config['dropout']),\n            nn.Linear(config['hidden_dim'] // 2, num_classes)\n        )\n        \n    def forward(self, x, return_features=False):\n        \"\"\"Forward pass\"\"\"\n        B, L, D = x.shape\n        \n        # Input projection\n        x = self.input_proj(x)\n        \n        # Mamba layers with residual connections\n        for i, (mamba, norm) in enumerate(zip(self.mamba_layers, self.layer_norms)):\n            residual = x\n            x = norm(x)\n            x = mamba(x)\n            x = self.dropout(x)\n            x = x + residual\n        \n        # Use last timestep for classification\n        features = x[:, -1, :]\n        \n        # Classification\n        logits = self.classifier(features)\n        \n        outputs = {'logits': logits}\n        \n        if return_features:\n            outputs['features'] = features\n        \n        return outputs\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n## Training Pipeline with Poisoning Attack Simulation\n","metadata":{}},{"cell_type":"code","source":"class PoisoningAttackSimulator:\n    \"\"\"Simulate various poisoning attacks\"\"\"\n    \n    def __init__(self, epsilon=0.1):\n        self.epsilon = epsilon\n    \n    def gradient_based_poisoning(self, model, x, y):\n        \"\"\"Gradient-based poisoning attack\"\"\"\n        x_adv = x.clone().detach().requires_grad_(True)\n        \n        outputs = model(x_adv)\n        if isinstance(outputs, dict):\n            logits = outputs['logits']\n        else:\n            logits = outputs\n            \n        loss = F.cross_entropy(logits, y)\n        loss.backward()\n        \n        # Generate adversarial perturbation\n        perturbation = self.epsilon * x_adv.grad.sign()\n        x_poisoned = x + perturbation\n        \n        return x_poisoned.detach()\n    \n    def label_flipping(self, y, flip_rate=0.2):\n        \"\"\"Random label flipping attack\"\"\"\n        y_flipped = y.clone()\n        n_flip = int(len(y) * flip_rate)\n        flip_indices = torch.randperm(len(y))[:n_flip]\n        \n        # Flip to random different class\n        for idx in flip_indices:\n            current_label = y_flipped[idx].item()\n            new_label = random.choice([i for i in range(y.max().item() + 1) if i != current_label])\n            y_flipped[idx] = new_label\n        \n        return y_flipped\n    \n    def backdoor_attack(self, x, trigger_pattern=None, target_class=0, poison_rate=0.1):\n        \"\"\"Backdoor poisoning attack\"\"\"\n        x_backdoor = x.clone()\n        n_poison = int(len(x) * poison_rate)\n        poison_indices = torch.randperm(len(x))[:n_poison]\n        \n        if trigger_pattern is None:\n            # Simple trigger: modify first few features\n            trigger_pattern = torch.zeros_like(x[0])\n            trigger_pattern[:, :5] = 1.0\n        \n        for idx in poison_indices:\n            x_backdoor[idx] = x_backdoor[idx] + trigger_pattern\n        \n        return x_backdoor, poison_indices\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n# Main Training Function\n\n","metadata":{}},{"cell_type":"code","source":"def train_mambashield(config):\n    \"\"\"Main training function with all components\"\"\"\n    \n    print(\"=\"*60)\n    print(\"MAMBASHIELD TRAINING PIPELINE\")\n    print(\"=\"*60)\n    \n    # Memory manager\n    mem_manager = P100MemoryManager()\n    \n    # Load data (using smaller sample for demo)\n    print(\"\\n1. Loading Dataset...\")\n    dataset_path = '/kaggle/input/poisoning-i/CIC_IoT_M3.csv'\n    \n    # Load with sampling for P100\n    df = pd.read_csv(dataset_path, nrows=50000)  # Limit rows for demo\n    \n    # Process data\n    label_col = 'Label'\n    feature_cols = [c for c in df.columns if c != label_col]\n    \n    # Handle non-numeric\n    for col in feature_cols:\n        df[col] = pd.to_numeric(df[col], errors='coerce')\n    df = df.fillna(0)\n    \n    X = df[feature_cols].values\n    y = df[label_col].values\n    \n    # Encode labels\n    le = LabelEncoder()\n    y = le.fit_transform(y.astype(str))\n    \n    # Scale features\n    scaler = StandardScaler()\n    X = scaler.fit_transform(X)\n    \n    print(f\"Data shape: {X.shape}\")\n    print(f\"Classes: {len(np.unique(y))}\")\n    \n    # Create sequences\n    seq_len = config['seq_len']\n    sequences = []\n    labels = []\n    \n    for i in range(len(X) - seq_len + 1):\n        sequences.append(X[i:i+seq_len])\n        labels.append(y[i+seq_len-1])\n    \n    X_seq = np.array(sequences)\n    y_seq = np.array(labels)\n    \n    # Split data\n    X_train, X_test, y_train, y_test = train_test_split(\n        X_seq, y_seq, test_size=0.2, random_state=42, stratify=y_seq\n    )\n    \n    X_train, X_val, y_train, y_val = train_test_split(\n        X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n    )\n    \n    print(f\"\\nTrain: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")\n    \n    # Create datasets\n    train_dataset = TensorDataset(\n        torch.FloatTensor(X_train),\n        torch.LongTensor(y_train)\n    )\n    val_dataset = TensorDataset(\n        torch.FloatTensor(X_val),\n        torch.LongTensor(y_val)\n    )\n    test_dataset = TensorDataset(\n        torch.FloatTensor(X_test),\n        torch.LongTensor(y_test)\n    )\n    \n    # Dataloaders\n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=config['batch_size'],\n        shuffle=True,\n        num_workers=0\n    )\n    val_loader = DataLoader(\n        val_dataset,\n        batch_size=config['batch_size'],\n        shuffle=False,\n        num_workers=0\n    )\n    test_loader = DataLoader(\n        test_dataset,\n        batch_size=config['batch_size'],\n        shuffle=False,\n        num_workers=0\n    )\n    \n    # Create model\n    print(\"\\n2. Creating MambaShield Model...\")\n    model = MambaShield(\n        input_dim=X.shape[1],\n        num_classes=len(np.unique(y)),\n        config={\n            'hidden_dim': config['hidden_dim'],\n            'd_state': config['d_state'],\n            'n_layers': config['n_layers'],\n            'dropout': config['dropout']\n        }\n    ).to(device)\n    \n    print(f\"Model parameters: {sum(p.numel() for p in model.parameters())/1e6:.2f}M\")\n    \n    # Optimizer\n    optimizer = optim.AdamW(model.parameters(), lr=config['lr'], weight_decay=1e-5)\n    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config['epochs'])\n    criterion = nn.CrossEntropyLoss()\n    scaler = GradScaler()\n    \n    # Initialize components\n    attack_sim = PoisoningAttackSimulator(epsilon=0.1)\n    evaluator = ComprehensiveEvaluator()\n    pac_bayes = PACBayesRobustness(model)\n    \n    # Training history\n    history = {\n        'train_loss': [], 'train_acc': [],\n        'val_loss': [], 'val_acc': [],\n        'metrics': []\n    }\n    \n    # Training loop\n    print(\"\\n3. Starting Training...\")\n    best_val_acc = 0\n    \n    for epoch in range(config['epochs']):\n        print(f\"\\n\" + \"=\"*50)\n        print(f\"Epoch {epoch+1}/{config['epochs']}\")\n        print(\"=\"*50)\n        \n        # Training\n        model.train()\n        train_loss = 0\n        train_correct = 0\n        train_total = 0\n        \n        pbar = tqdm(train_loader, desc='Training')\n        for batch_idx, (data, target) in enumerate(pbar):\n            data, target = data.to(device), target.to(device)\n            \n            # Simulate poisoning attacks (25% of batches)\n            if random.random() < 0.25:\n                if random.random() < 0.5:\n                    data = attack_sim.gradient_based_poisoning(model, data, target)\n                else:\n                    target = attack_sim.label_flipping(target, flip_rate=0.1)\n            \n            optimizer.zero_grad()\n            \n            # Mixed precision training\n            with autocast():\n                outputs = model(data)\n                loss = criterion(outputs['logits'], target)\n            \n            scaler.scale(loss).backward()\n            \n            # Gradient clipping\n            scaler.unscale_(optimizer)\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            \n            scaler.step(optimizer)\n            scaler.update()\n            \n            # Metrics\n            train_loss += loss.item()\n            pred = outputs['logits'].argmax(dim=1)\n            train_correct += (pred == target).sum().item()\n            train_total += target.size(0)\n            \n            # Update progress bar\n            pbar.set_postfix({\n                'loss': f\"{loss.item():.4f}\",\n                'acc': f\"{100.*train_correct/train_total:.2f}%\"\n            })\n            \n            # Memory cleanup\n            if batch_idx % 20 == 0:\n                mem_manager.clear_memory()\n        \n        # Calculate epoch metrics\n        train_loss /= len(train_loader)\n        train_acc = 100. * train_correct / train_total\n        \n        # Validation\n        model.eval()\n        val_loss = 0\n        val_correct = 0\n        val_total = 0\n        \n        with torch.no_grad():\n            for data, target in tqdm(val_loader, desc='Validation'):\n                data, target = data.to(device), target.to(device)\n                \n                outputs = model(data)\n                loss = criterion(outputs['logits'], target)\n                \n                val_loss += loss.item()\n                pred = outputs['logits'].argmax(dim=1)\n                val_correct += (pred == target).sum().item()\n                val_total += target.size(0)\n        \n        val_loss /= len(val_loader)\n        val_acc = 100. * val_correct / val_total\n        \n        # Update scheduler\n        scheduler.step()\n        \n        # Save history\n        history['train_loss'].append(train_loss)\n        history['train_acc'].append(train_acc)\n        history['val_loss'].append(val_loss)\n        history['val_acc'].append(val_acc)\n        \n        print(f\"\\nEpoch {epoch+1} Summary:\")\n        print(f\"Train - Loss: {train_loss:.4f}, Acc: {train_acc:.2f}%\")\n        print(f\"Val   - Loss: {val_loss:.4f}, Acc: {val_acc:.2f}%\")\n        \n        # Save best model\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            best_model_state = model.state_dict()\n            print(f\"New best model! Val Acc: {best_val_acc:.2f}%\")\n        \n        # Memory cleanup\n        mem_manager.clear_memory()\n    \n    # Load best model\n    model.load_state_dict(best_model_state)\n    \n    # Final evaluation\n    print(\"\\n4. Final Evaluation on Test Set...\")\n    metrics = evaluator.evaluate(model, test_loader, device)\n    evaluator.print_metrics()\n    \n    # PAC-Bayes bound\n    print(\"\\n5. Computing PAC-Bayes Robustness Bound...\")\n    with torch.no_grad():\n        test_loss = 0\n        for data, target in test_loader:\n            data, target = data.to(device), target.to(device)\n            outputs = model(data)\n            loss = criterion(outputs['logits'], target)\n            test_loss += loss.item()\n        test_loss /= len(test_loader)\n    \n    pac_bounds = pac_bayes.pac_bayes_bound(\n        torch.tensor(test_loss),\n        len(test_dataset)\n    )\n    \n    print(\"\\nPAC-Bayes Bounds:\")\n    for key, value in pac_bounds.items():\n        print(f\"  {key}: {value:.4f}\")\n    \n    # Plot training history\n    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n    \n    axes[0].plot(history['train_loss'], label='Train')\n    axes[0].plot(history['val_loss'], label='Val')\n    axes[0].set_xlabel('Epoch')\n    axes[0].set_ylabel('Loss')\n    axes[0].set_title('Training Loss')\n    axes[0].legend()\n    axes[0].grid(True)\n    \n    axes[1].plot(history['train_acc'], label='Train')\n    axes[1].plot(history['val_acc'], label='Val')\n    axes[1].set_xlabel('Epoch')\n    axes[1].set_ylabel('Accuracy (%)')\n    axes[1].set_title('Training Accuracy')\n    axes[1].legend()\n    axes[1].grid(True)\n    \n    plt.tight_layout()\n    plt.show()\n    \n    return model, history, metrics\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n# Execute Training\n","metadata":{}},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    # Configuration\n    config = {\n        'seq_len': 10,        # Sequence length\n        'batch_size': 32,     # Batch size for P100\n        'hidden_dim': 128,    # Hidden dimension\n        'd_state': 16,        # SSM state dimension\n        'n_layers': 2,        # Number of Mamba layers\n        'dropout': 0.1,       # Dropout rate\n        'lr': 1e-4,          # Learning rate\n        'epochs': 10,         # Number of epochs\n    }\n    \n    print(\"Configuration:\")\n    for key, value in config.items():\n        print(f\"  {key}: {value}\")\n    \n    # Train model\n    model, history, metrics = train_mambashield(config)\n    \n    print(\"\\n\" + \"=\"*60)\n    print(\"TRAINING COMPLETE!\")\n    print(\"=\"*60)\n    print(f\"Best validation accuracy: {max(history['val_acc']):.2f}%\")\n    print(f\"Final test accuracy: {metrics['accuracy']*100:.2f}%\")\n    \n    # Save model\n    torch.save({\n        'model_state_dict': model.state_dict(),\n        'config': config,\n        'metrics': metrics,\n        'history': history\n    }, 'mambashield_model.pth')\n    \n    print(\"\\nModel saved to 'mambashield_model.pth'\") \n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# NEW ADDITIONAL COMPREHENSIVE CODE FOR MAMBASHIELD","metadata":{}},{"cell_type":"code","source":"#!/usr/bin/env python\n# coding: utf-8\n\n\"\"\"\nMambaShield: Complete Multi-Dataset Implementation\nHandles CIC-IoT-2023, CSE-CICIDS2018, and UNSW-NB15 with unified taxonomy\n\"\"\"\n\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.cuda.amp import autocast, GradScaler\nfrom torch.utils.data import DataLoader, TensorDataset, ConcatDataset\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport gc\nimport warnings\nfrom typing import Dict, List, Tuple, Optional, Union\nfrom collections import defaultdict\nimport math\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score,\n    confusion_matrix, roc_auc_score, classification_report\n)\n\nwarnings.filterwarnings('ignore')\n\n# ============================================================================\n# UNIFIED ATTACK TAXONOMY\n# ============================================================================\n\nclass UnifiedTaxonomy:\n    \"\"\"Unified attack taxonomy across all datasets\"\"\"\n    \n    def __init__(self):\n        self.taxonomy = {\n            'Normal': ['Normal/Benign', 'BENIGN', 'Benign', 'Normal', '0'],\n            'DoS/DDoS': [\n                'DoS', 'DDoS', 'DDOS-SLOWLORIS', 'DDOS-SYNONYMOUSIP_FLOOD', \n                'DDOS-ICMP_FLOOD', 'DDOS-RSTFINFLOOD', 'DDOS-PSHACK_FLOOD',\n                'DDOS-SYN_FLOOD', 'DDOS-TCP_FLOOD', 'DDOS-UDP_FLOOD',\n                'DOS-UDP_FLOOD', 'DOS-SYN_FLOOD', 'DOS-TCP_FLOOD',\n                'DoS_Hulk', 'DoS_GoldenEye', 'DoS_Slowloris', 'DoS_Slowhttptest'\n            ],\n            'Reconnaissance': [\n                'Scanning', 'RECON-PORTSCAN', 'RECON-OSSCAN', 'RECON-HOSTDISCOVERY',\n                'RECON-PINGSWEEP', 'VULNERABILITYSCAN', 'Heartbleed', 'PortScan',\n                'Reconnaissance', 'Analysis'\n            ],\n            'Malware': [\n                'BACKDOOR_MALWARE', 'Rootkit', 'Trojan', 'Worm', 'Botnet', \n                'Malware', 'Bot', 'Mirai', 'Generic', 'Shellcode'\n            ],\n            'Injection': [\n                'SQL_Injection', 'SQLINJECTION', 'COMMANDINJECTION', 'XSS',\n                'Web Attack', 'Web-based'\n            ],\n            'BruteForce': [\n                'DICTIONARYBRUTEFORCE', 'Brute_Force', 'FTP_Patator', \n                'Password_Attack', 'Brute Force', 'SSH-Patator'\n            ],\n            'Exploitation': [\n                'Infiltration', 'Backdoor', 'Exploits', 'Fuzzers'\n            ]\n        }\n        \n        # Create reverse mapping\n        self.reverse_map = {}\n        for category, attacks in self.taxonomy.items():\n            for attack in attacks:\n                self.reverse_map[attack.lower()] = category\n    \n    def map_label(self, label):\n        \"\"\"Map specific attack to unified category\"\"\"\n        label_lower = str(label).lower().strip()\n        return self.reverse_map.get(label_lower, 'Other')\n\n\n# ============================================================================\n# UNIFIED FEATURE PROCESSOR\n# ============================================================================\n\nclass UnifiedFeatureProcessor:\n    \"\"\"Process and align features across datasets\"\"\"\n    \n    def __init__(self, target_features=84):\n        self.target_features = target_features\n        self.common_features = self._define_common_features()\n        self.scaler = StandardScaler()\n        \n    def _define_common_features(self):\n        \"\"\"Define common network flow features\"\"\"\n        return [\n            # Packet statistics\n            'flow_duration', 'total_fwd_packets', 'total_bwd_packets',\n            'total_length_fwd_packets', 'total_length_bwd_packets',\n            \n            # Packet length statistics\n            'fwd_packet_length_max', 'fwd_packet_length_min', 'fwd_packet_length_mean',\n            'fwd_packet_length_std', 'bwd_packet_length_max', 'bwd_packet_length_min',\n            'bwd_packet_length_mean', 'bwd_packet_length_std',\n            \n            # Flow statistics\n            'flow_bytes_per_sec', 'flow_packets_per_sec', 'flow_iat_mean',\n            'flow_iat_std', 'flow_iat_max', 'flow_iat_min',\n            \n            # Inter-arrival times\n            'fwd_iat_total', 'fwd_iat_mean', 'fwd_iat_std', 'fwd_iat_max', 'fwd_iat_min',\n            'bwd_iat_total', 'bwd_iat_mean', 'bwd_iat_std', 'bwd_iat_max', 'bwd_iat_min',\n            \n            # TCP flags\n            'fwd_psh_flags', 'bwd_psh_flags', 'fwd_urg_flags', 'bwd_urg_flags',\n            'fin_flag_count', 'syn_flag_count', 'rst_flag_count', 'psh_flag_count',\n            'ack_flag_count', 'urg_flag_count', 'cwe_flag_count', 'ece_flag_count',\n            \n            # Header information\n            'fwd_header_length', 'bwd_header_length', 'fwd_packets_per_sec',\n            'bwd_packets_per_sec', 'min_packet_length', 'max_packet_length',\n            'packet_length_mean', 'packet_length_std', 'packet_length_variance',\n            \n            # Additional flow features\n            'down_up_ratio', 'average_packet_size', 'fwd_segment_size_avg',\n            'bwd_segment_size_avg', 'fwd_bulk_rate_avg', 'bwd_bulk_rate_avg',\n            'subflow_fwd_packets', 'subflow_fwd_bytes', 'subflow_bwd_packets',\n            'subflow_bwd_bytes', 'init_win_bytes_forward', 'init_win_bytes_backward',\n            'act_data_pkt_fwd', 'min_seg_size_forward', 'active_mean', 'active_std',\n            'active_max', 'active_min', 'idle_mean', 'idle_std', 'idle_max', 'idle_min',\n            \n            # Protocol features\n            'protocol', 'src_port', 'dst_port'\n        ]\n    \n    def align_features(self, df, dataset_name):\n        \"\"\"Align dataset features to common feature set\"\"\"\n        print(f\"Aligning features for {dataset_name}...\")\n        \n        # Feature name mappings for different datasets\n        feature_mappings = {\n            'cic': {\n                'Flow Duration': 'flow_duration',\n                'Total Fwd Packets': 'total_fwd_packets',\n                'Total Backward Packets': 'total_bwd_packets',\n                'Total Length of Fwd Packets': 'total_length_fwd_packets',\n                'Total Length of Bwd Packets': 'total_length_bwd_packets',\n                'Fwd Packet Length Max': 'fwd_packet_length_max',\n                'Fwd Packet Length Min': 'fwd_packet_length_min',\n                'Fwd Packet Length Mean': 'fwd_packet_length_mean',\n                'Fwd Packet Length Std': 'fwd_packet_length_std',\n                'Bwd Packet Length Max': 'bwd_packet_length_max',\n                'Bwd Packet Length Min': 'bwd_packet_length_min',\n                'Bwd Packet Length Mean': 'bwd_packet_length_mean',\n                'Bwd Packet Length Std': 'bwd_packet_length_std',\n                'Flow Bytes/s': 'flow_bytes_per_sec',\n                'Flow Packets/s': 'flow_packets_per_sec',\n                'Flow IAT Mean': 'flow_iat_mean',\n                'Flow IAT Std': 'flow_iat_std',\n                'Flow IAT Max': 'flow_iat_max',\n                'Flow IAT Min': 'flow_iat_min',\n                'Fwd IAT Total': 'fwd_iat_total',\n                'Fwd IAT Mean': 'fwd_iat_mean',\n                'Fwd IAT Std': 'fwd_iat_std',\n                'Fwd IAT Max': 'fwd_iat_max',\n                'Fwd IAT Min': 'fwd_iat_min',\n                'Bwd IAT Total': 'bwd_iat_total',\n                'Bwd IAT Mean': 'bwd_iat_mean',\n                'Bwd IAT Std': 'bwd_iat_std',\n                'Bwd IAT Max': 'bwd_iat_max',\n                'Bwd IAT Min': 'bwd_iat_min',\n                'Fwd PSH Flags': 'fwd_psh_flags',\n                'Bwd PSH Flags': 'bwd_psh_flags',\n                'Fwd URG Flags': 'fwd_urg_flags',\n                'Bwd URG Flags': 'bwd_urg_flags',\n                'FIN Flag Count': 'fin_flag_count',\n                'SYN Flag Count': 'syn_flag_count',\n                'RST Flag Count': 'rst_flag_count',\n                'PSH Flag Count': 'psh_flag_count',\n                'ACK Flag Count': 'ack_flag_count',\n                'URG Flag Count': 'urg_flag_count',\n                'CWE Flag Count': 'cwe_flag_count',\n                'ECE Flag Count': 'ece_flag_count',\n                'Protocol': 'protocol',\n                'Source Port': 'src_port',\n                'Destination Port': 'dst_port'\n            },\n            'cse': {\n                # Similar mappings for CSE-CICIDS2018\n                'Flow Duration': 'flow_duration',\n                'Tot Fwd Pkts': 'total_fwd_packets',\n                'Tot Bwd Pkts': 'total_bwd_packets',\n                'TotLen Fwd Pkts': 'total_length_fwd_packets',\n                'TotLen Bwd Pkts': 'total_length_bwd_packets',\n                'Fwd Pkt Len Max': 'fwd_packet_length_max',\n                'Fwd Pkt Len Min': 'fwd_packet_length_min',\n                'Fwd Pkt Len Mean': 'fwd_packet_length_mean',\n                'Fwd Pkt Len Std': 'fwd_packet_length_std',\n                'Bwd Pkt Len Max': 'bwd_packet_length_max',\n                'Bwd Pkt Len Min': 'bwd_packet_length_min',\n                'Bwd Pkt Len Mean': 'bwd_packet_length_mean',\n                'Bwd Pkt Len Std': 'bwd_packet_length_std',\n                'Flow Byts/s': 'flow_bytes_per_sec',\n                'Flow Pkts/s': 'flow_packets_per_sec',\n                'Protocol': 'protocol'\n            },\n            'ton': {\n                # Mappings for UNSW-TON-NB15\n                'dur': 'flow_duration',\n                'spkts': 'total_fwd_packets',\n                'dpkts': 'total_bwd_packets',\n                'sbytes': 'total_length_fwd_packets',\n                'dbytes': 'total_length_bwd_packets',\n                'rate': 'flow_packets_per_sec',\n                'proto': 'protocol',\n                'sport': 'src_port',\n                'dport': 'dst_port'\n            }\n        }\n        \n        # Get appropriate mapping\n        mapping = feature_mappings.get(dataset_name.lower(), {})\n        \n        # Rename columns\n        df_renamed = df.rename(columns=mapping)\n        \n        # Create aligned dataframe with common features\n        aligned_df = pd.DataFrame()\n        \n        for feature in self.common_features[:self.target_features]:\n            if feature in df_renamed.columns:\n                aligned_df[feature] = df_renamed[feature]\n            else:\n                # Fill missing features with zeros or statistical values\n                aligned_df[feature] = 0\n        \n        return aligned_df\n    \n    def process_dataset(self, df, dataset_name, label_col):\n        \"\"\"Process entire dataset\"\"\"\n        # Separate features and labels\n        labels = df[label_col] if label_col in df.columns else df.iloc[:, -1]\n        \n        # Remove label column from features\n        feature_df = df.drop(columns=[label_col], errors='ignore')\n        \n        # Align features\n        aligned_features = self.align_features(feature_df, dataset_name)\n        \n        # Handle non-numeric data\n        for col in aligned_features.columns:\n            aligned_features[col] = pd.to_numeric(aligned_features[col], errors='coerce')\n        \n        # Fill NaN values\n        aligned_features = aligned_features.fillna(0)\n        \n        # Clip extreme values\n        aligned_features = aligned_features.clip(lower=-1e10, upper=1e10)\n        \n        return aligned_features, labels\n\n\n# ============================================================================\n# MULTI-DATASET LOADER\n# ============================================================================\n\nclass MultiDatasetLoader:\n    \"\"\"Load and process all three datasets with unified taxonomy\"\"\"\n    \n    def __init__(self, config):\n        self.config = config\n        self.taxonomy = UnifiedTaxonomy()\n        self.feature_processor = UnifiedFeatureProcessor(target_features=84)\n        self.label_encoder = LabelEncoder()\n        \n    def load_dataset(self, file_path, dataset_name, sample_frac=1.0):\n        \"\"\"Load single dataset\"\"\"\n        print(f\"\\nLoading {dataset_name} dataset...\")\n        \n        # Determine label column\n        label_columns = {\n            'cic': 'Label',\n            'cse': ' Label',\n            'ton': 'label'\n        }\n        label_col = label_columns.get(dataset_name.lower(), 'Label')\n        \n        # Read dataset in chunks for memory efficiency\n        chunks = []\n        chunk_size = 10000\n        max_rows = int(100000 * sample_frac)  # Limit total rows\n        \n        for i, chunk in enumerate(pd.read_csv(file_path, chunksize=chunk_size)):\n            if i * chunk_size >= max_rows:\n                break\n            chunks.append(chunk)\n        \n        df = pd.concat(chunks, ignore_index=True)\n        print(f\"Loaded {len(df)} samples from {dataset_name}\")\n        \n        # Process features\n        features, labels = self.feature_processor.process_dataset(df, dataset_name, label_col)\n        \n        # Map labels to unified taxonomy\n        unified_labels = [self.taxonomy.map_label(label) for label in labels]\n        \n        # Encode labels\n        encoded_labels = self.label_encoder.fit_transform(unified_labels)\n        \n        return features.values, encoded_labels, unified_labels\n    \n    def load_all_datasets(self, dataset_paths, sample_frac=0.1):\n        \"\"\"Load all three datasets\"\"\"\n        all_features = []\n        all_labels = []\n        all_dataset_ids = []\n        \n        for i, (name, path) in enumerate(dataset_paths.items()):\n            if not os.path.exists(path):\n                print(f\"Warning: {path} not found, skipping {name}\")\n                continue\n            \n            features, labels, _ = self.load_dataset(path, name, sample_frac)\n            \n            all_features.append(features)\n            all_labels.append(labels)\n            all_dataset_ids.extend([i] * len(labels))\n            \n            print(f\"{name}: {features.shape[0]} samples, {len(np.unique(labels))} classes\")\n        \n        # Combine all datasets\n        if all_features:\n            X = np.vstack(all_features)\n            y = np.hstack(all_labels)\n            dataset_ids = np.array(all_dataset_ids)\n            \n            # Scale features\n            X = self.feature_processor.scaler.fit_transform(X)\n            \n            print(f\"\\nCombined dataset: {X.shape[0]} samples, {X.shape[1]} features\")\n            print(f\"Class distribution: {dict(zip(*np.unique(y, return_counts=True)))}\")\n            \n            return X, y, dataset_ids\n        \n        return None, None, None\n\n\n# ============================================================================\n# ENHANCED MAMBASHIELD FOR MULTI-DATASET\n# ============================================================================\n\nclass MultiDatasetMambaShield(nn.Module):\n    \"\"\"MambaShield with multi-dataset support\"\"\"\n    \n    def __init__(self, input_dim, num_classes, num_datasets=3, config=None):\n        super().__init__()\n        \n        if config is None:\n            config = {\n                'hidden_dim': 128,\n                'd_state': 16,\n                'n_layers': 3,\n                'dropout': 0.1,\n                'use_dataset_embedding': True\n            }\n        \n        self.config = config\n        self.num_datasets = num_datasets\n        \n        # Dataset embeddings for multi-modal learning\n        if config['use_dataset_embedding']:\n            self.dataset_embedding = nn.Embedding(num_datasets, 32)\n            input_dim += 32\n        \n        # Input projection\n        self.input_proj = nn.Sequential(\n            nn.Linear(input_dim, config['hidden_dim']),\n            nn.LayerNorm(config['hidden_dim']),\n            nn.ReLU(),\n            nn.Dropout(config['dropout'])\n        )\n        \n        # Mamba blocks (simplified for stability)\n        self.mamba_blocks = nn.ModuleList([\n            self._create_mamba_block(config['hidden_dim'], config['d_state'])\n            for _ in range(config['n_layers'])\n        ])\n        \n        # Multi-head attention for temporal fusion\n        self.temporal_attention = nn.MultiheadAttention(\n            config['hidden_dim'], \n            num_heads=8,\n            dropout=config['dropout'],\n            batch_first=True\n        )\n        \n        # Classification heads (one per dataset + unified)\n        self.dataset_heads = nn.ModuleList([\n            nn.Linear(config['hidden_dim'], config['hidden_dim'] // 2)\n            for _ in range(num_datasets)\n        ])\n        \n        self.unified_classifier = nn.Sequential(\n            nn.LayerNorm(config['hidden_dim']),\n            nn.Linear(config['hidden_dim'], config['hidden_dim'] // 2),\n            nn.ReLU(),\n            nn.Dropout(config['dropout']),\n            nn.Linear(config['hidden_dim'] // 2, num_classes)\n        )\n        \n    def _create_mamba_block(self, hidden_dim, d_state):\n        \"\"\"Create simplified Mamba block\"\"\"\n        return nn.Sequential(\n            nn.LayerNorm(hidden_dim),\n            nn.Linear(hidden_dim, hidden_dim * 2),\n            nn.GLU(dim=-1),\n            nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3, padding=1, groups=hidden_dim),\n            nn.LayerNorm(hidden_dim),\n            nn.Linear(hidden_dim, hidden_dim)\n        )\n    \n    def forward(self, x, dataset_ids=None):\n        \"\"\"Forward pass with multi-dataset support\"\"\"\n        B, L, D = x.shape\n        \n        # Add dataset embeddings if available\n        if dataset_ids is not None and self.config['use_dataset_embedding']:\n            dataset_emb = self.dataset_embedding(dataset_ids)\n            dataset_emb = dataset_emb.unsqueeze(1).expand(-1, L, -1)\n            x = torch.cat([x, dataset_emb], dim=-1)\n        \n        # Input projection\n        x = self.input_proj(x)\n        \n        # Apply Mamba blocks with residual connections\n        for mamba_block in self.mamba_blocks:\n            residual = x\n            \n            # Process through Mamba-like block\n            if len(x.shape) == 3:\n                # Reshape for Conv1d\n                x_conv = x.transpose(1, 2)  # (B, D, L)\n                for layer in mamba_block:\n                    if isinstance(layer, nn.Conv1d):\n                        x_conv = layer(x_conv)\n                    elif isinstance(layer, nn.Linear) or isinstance(layer, nn.LayerNorm):\n                        x_conv = x_conv.transpose(1, 2)  # Back to (B, L, D)\n                        x_conv = layer(x_conv)\n                        if not isinstance(layer, nn.LayerNorm):\n                            x_conv = x_conv.transpose(1, 2)  # Back to (B, D, L) for next conv\n                    elif isinstance(layer, nn.GLU):\n                        x_conv = x_conv.transpose(1, 2)\n                        x_conv = layer(x_conv)\n                        x_conv = x_conv.transpose(1, 2)\n                \n                if len(x_conv.shape) == 3 and x_conv.shape[1] != L:\n                    x_conv = x_conv.transpose(1, 2)\n                \n                x = x_conv\n            \n            # Residual connection\n            x = x + residual\n        \n        # Temporal attention\n        x_attn, _ = self.temporal_attention(x, x, x)\n        x = x + x_attn\n        \n        # Use last timestep for classification\n        features = x[:, -1, :]\n        \n        # Classification\n        logits = self.unified_classifier(features)\n        \n        outputs = {\n            'logits': logits,\n            'features': features\n        }\n        \n        # Dataset-specific heads if needed\n        if dataset_ids is not None:\n            dataset_outputs = []\n            for i, head in enumerate(self.dataset_heads):\n                mask = (dataset_ids == i)\n                if mask.any():\n                    dataset_features = features[mask]\n                    dataset_out = head(dataset_features)\n                    dataset_outputs.append(dataset_out)\n            \n            if dataset_outputs:\n                outputs['dataset_specific'] = dataset_outputs\n        \n        return outputs\n\n\n# ============================================================================\n# COMPREHENSIVE TRAINING PIPELINE\n# ============================================================================\n\ndef train_multimodal_mambashield():\n    \"\"\"Train MambaShield on all three datasets\"\"\"\n    \n    print(\"=\"*60)\n    print(\"MAMBASHIELD MULTI-DATASET TRAINING\")\n    print(\"=\"*60)\n    \n    # Configuration\n    config = {\n        'seq_len': 10,\n        'batch_size': 32,\n        'hidden_dim': 128,\n        'd_state': 16,\n        'n_layers': 3,\n        'dropout': 0.1,\n        'lr': 1e-4,\n        'epochs': 10,\n        'sample_frac': 0.05,  # Use 5% of each dataset for demo\n        'use_dataset_embedding': True\n    }\n    \n    # Dataset paths\n    dataset_paths = {\n        'cic': '/kaggle/input/poisoning-i/CIC_IoT_M3.csv',\n        'cse': '/kaggle/input/poisoning-i/CSE-CIC_2018.csv',\n        'ton': '/kaggle/input/poisoning-i/UNSW_TON_IoT.csv'\n    }\n    \n    # Device setup\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"Using device: {device}\")\n    \n    # Load all datasets\n    print(\"\\n1. Loading Datasets...\")\n    loader = MultiDatasetLoader(config)\n    X, y, dataset_ids = loader.load_all_datasets(dataset_paths, config['sample_frac'])\n    \n    if X is None:\n        print(\"Failed to load datasets\")\n        return\n    \n    # Create sequences\n    print(\"\\n2. Creating Temporal Sequences...\")\n    sequences = []\n    labels = []\n    ds_ids = []\n    \n    for i in range(len(X) - config['seq_len'] + 1):\n        sequences.append(X[i:i+config['seq_len']])\n        labels.append(y[i+config['seq_len']-1])\n        ds_ids.append(dataset_ids[i])\n    \n    X_seq = np.array(sequences)\n    y_seq = np.array(labels)\n    ds_ids = np.array(ds_ids)\n    \n    # Split data\n    indices = np.arange(len(X_seq))\n    train_idx, test_idx = train_test_split(indices, test_size=0.2, random_state=42)\n    train_idx, val_idx = train_test_split(train_idx, test_size=0.2, random_state=42)\n    \n    # Create datasets\n    train_dataset = TensorDataset(\n        torch.FloatTensor(X_seq[train_idx]),\n        torch.LongTensor(y_seq[train_idx]),\n        torch.LongTensor(ds_ids[train_idx])\n    )\n    val_dataset = TensorDataset(\n        torch.FloatTensor(X_seq[val_idx]),\n        torch.LongTensor(y_seq[val_idx]),\n        torch.LongTensor(ds_ids[val_idx])\n    )\n    test_dataset = TensorDataset(\n        torch.FloatTensor(X_seq[test_idx]),\n        torch.LongTensor(y_seq[test_idx]),\n        torch.LongTensor(ds_ids[test_idx])\n    )\n    \n    # Dataloaders\n    train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=config['batch_size'])\n    test_loader = DataLoader(test_dataset, batch_size=config['batch_size'])\n    \n    # Create model\n    print(\"\\n3. Creating Multi-Dataset MambaShield Model...\")\n    num_classes = len(np.unique(y))\n    num_datasets = len(np.unique(dataset_ids))\n    \n    model = MultiDatasetMambaShield(\n        input_dim=X.shape[1],\n        num_classes=num_classes,\n        num_datasets=num_datasets,\n        config=config\n    ).to(device)\n    \n    print(f\"Model parameters: {sum(p.numel() for p in model.parameters())/1e6:.2f}M\")\n    \n    # Training setup\n    optimizer = optim.AdamW(model.parameters(), lr=config['lr'])\n    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config['epochs'])\n    criterion = nn.CrossEntropyLoss()\n    scaler = GradScaler()\n    \n    # Training history\n    history = defaultdict(list)\n    best_val_acc = 0\n    \n    # Training loop\n    print(\"\\n4. Training...\")\n    for epoch in range(config['epochs']):\n        # Training\n        model.train()\n        train_loss = 0\n        train_correct = 0\n        train_total = 0\n        \n        for data, labels, ds_ids in tqdm(train_loader, desc=f'Epoch {epoch+1}/{config[\"epochs\"]}'):\n            data = data.to(device)\n            labels = labels.to(device)\n            ds_ids = ds_ids.to(device)\n            \n            optimizer.zero_grad()\n            \n            with autocast():\n                outputs = model(data, ds_ids)\n                loss = criterion(outputs['logits'], labels)\n            \n            scaler.scale(loss).backward()\n            scaler.unscale_(optimizer)\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            scaler.step(optimizer)\n            scaler.update()\n            \n            train_loss += loss.item()\n            pred = outputs['logits'].argmax(dim=1)\n            train_correct += (pred == labels).sum().item()\n            train_total += labels.size(0)\n        \n        train_acc = 100 * train_correct / train_total\n        \n        # Validation\n        model.eval()\n        val_loss = 0\n        val_correct = 0\n        val_total = 0\n        \n        with torch.no_grad():\n            for data, labels, ds_ids in val_loader:\n                data = data.to(device)\n                labels = labels.to(device)\n                ds_ids = ds_ids.to(device)\n                \n                outputs = model(data, ds_ids)\n                loss = criterion(outputs['logits'], labels)\n                \n                val_loss += loss.item()\n                pred = outputs['logits'].argmax(dim=1)\n                val_correct += (pred == labels).sum().item()\n                val_total += labels.size(0)\n        \n        val_acc = 100 * val_correct / val_total\n        \n        # Update scheduler\n        scheduler.step()\n        \n        # Save history\n        history['train_loss'].append(train_loss / len(train_loader))\n        history['train_acc'].append(train_acc)\n        history['val_loss'].append(val_loss / len(val_loader))\n        history['val_acc'].append(val_acc)\n        \n        print(f\"Epoch {epoch+1}: Train Acc={train_acc:.2f}%, Val Acc={val_acc:.2f}%\")\n        \n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            best_model_state = model.state_dict()\n    \n    # Load best model\n    model.load_state_dict(best_model_state)\n    \n    # Test evaluation\n    print(\"\\n5. Testing on Combined Test Set...\")\n    model.eval()\n    \n    # Per-dataset results\n    dataset_names = ['CIC-IoT-2023', 'CSE-CICIDS2018', 'UNSW-NB15']\n    all_preds = []\n    all_labels = []\n    all_ds_ids = []\n    \n    with torch.no_grad():\n        for data, labels, ds_ids in test_loader:\n            data = data.to(device)\n            outputs = model(data, ds_ids.to(device))\n            preds = outputs['logits'].argmax(dim=1)\n            \n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.numpy())\n            all_ds_ids.extend(ds_ids.numpy())\n    \n    all_preds = np.array(all_preds)\n    all_labels = np.array(all_labels)\n    all_ds_ids = np.array(all_ds_ids)\n    \n    # Overall metrics\n    overall_acc = accuracy_score(all_labels, all_preds)\n    overall_precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n    overall_recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n    overall_f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n    \n    print(\"\\n\" + \"=\"*60)\n    print(\"FINAL RESULTS\")\n    print(\"=\"*60)\n    print(f\"Overall Accuracy: {overall_acc*100:.2f}%\")\n    print(f\"Overall Precision: {overall_precision:.4f}\")\n    print(f\"Overall Recall: {overall_recall:.4f}\")\n    print(f\"Overall F1-Score: {overall_f1:.4f}\")\n    \n    # Per-dataset metrics\n    print(\"\\nPer-Dataset Performance:\")\n    for i, name in enumerate(dataset_names[:num_datasets]):\n        mask = all_ds_ids == i\n        if mask.any():\n            ds_acc = accuracy_score(all_labels[mask], all_preds[mask])\n            ds_f1 = f1_score(all_labels[mask], all_preds[mask], average='weighted', zero_division=0)\n            print(f\"  {name}: Accuracy={ds_acc*100:.2f}%, F1={ds_f1:.4f}\")\n    \n    # Attack category performance\n    print(\"\\nPer-Attack Category Performance:\")\n    taxonomy = UnifiedTaxonomy()\n    category_names = list(taxonomy.taxonomy.keys())\n    \n    for i, category in enumerate(category_names[:num_classes]):\n        mask = all_labels == i\n        if mask.any():\n            cat_precision = precision_score(all_labels[mask], all_preds[mask], average='binary', pos_label=i, zero_division=0)\n            cat_recall = recall_score(all_labels[mask], all_preds[mask], average='binary', pos_label=i, zero_division=0)\n            print(f\"  {category}: Precision={cat_precision:.4f}, Recall={cat_recall:.4f}\")\n    \n    # Plot results\n    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n    \n    # Training history\n    axes[0, 0].plot(history['train_loss'], label='Train')\n    axes[0, 0].plot(history['val_loss'], label='Val')\n    axes[0, 0].set_xlabel('Epoch')\n    axes[0, 0].set_ylabel('Loss')\n    axes[0, 0].set_title('Training Loss')\n    axes[0, 0].legend()\n    axes[0, 0].grid(True)\n    \n    axes[0, 1].plot(history['train_acc'], label='Train')\n    axes[0, 1].plot(history['val_acc'], label='Val')\n    axes[0, 1].set_xlabel('Epoch')\n    axes[0, 1].set_ylabel('Accuracy (%)')\n    axes[0, 1].set_title('Training Accuracy')\n    axes[0, 1].legend()\n    axes[0, 1].grid(True)\n    \n    # Confusion matrix\n    cm = confusion_matrix(all_labels, all_preds)\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[1, 0])\n    axes[1, 0].set_xlabel('Predicted')\n    axes[1, 0].set_ylabel('Actual')\n    axes[1, 0].set_title('Confusion Matrix')\n    \n    # Per-dataset accuracy bar chart\n    dataset_accs = []\n    for i in range(num_datasets):\n        mask = all_ds_ids == i\n        if mask.any():\n            dataset_accs.append(accuracy_score(all_labels[mask], all_preds[mask]) * 100)\n    \n    axes[1, 1].bar(dataset_names[:len(dataset_accs)], dataset_accs)\n    axes[1, 1].set_ylabel('Accuracy (%)')\n    axes[1, 1].set_title('Per-Dataset Accuracy')\n    axes[1, 1].set_ylim([0, 100])\n    \n    for i, v in enumerate(dataset_accs):\n        axes[1, 1].text(i, v + 1, f'{v:.1f}%', ha='center')\n    \n    plt.tight_layout()\n    plt.show()\n    \n    return model, history\n\nif __name__ == \"__main__\":\n    model, history = train_multimodal_mambashield() \n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}